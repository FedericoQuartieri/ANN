# Histopathological Tissue Classification

Deep learning pipeline for multi-class histopathological image classification using ResNet50 with custom preprocessing and ROI-aware training.

## ğŸ¯ Overview

- **Task**: 8-class tissue type classification from histology images
- **Architecture**: ResNet50 with pretrained ImageNet weights
- **Best F1 Score**: 0.3865 (test set)
- **Key Features**: Artifact removal, tile-based processing, k-fold ensemble, Grad-CAM visualization

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run preprocessing + training + inference
jupyter notebook main.ipynb
```

**Configure experiment** by setting `EXP_NAME` in first cell (e.g., `"resnet50_strongaug_384_new_kfold_finale"`).

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.ipynb                    # Main training pipeline
â”œâ”€â”€ includes/
â”‚   â”œâ”€â”€ config.py                 # Experiment configurations
â”‚   â”œâ”€â”€ data_utils.py             # Data loading & augmentation
â”‚   â”œâ”€â”€ model_utils.py            # Model building & training
â”‚   â”œâ”€â”€ inference_utils.py        # Test inference & ensemble
â”‚   â””â”€â”€ cam_utils.py              # Grad-CAM visualization
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ preprocessing.py          # Offline data preprocessing
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_data/               # Raw training images
â”‚   â”œâ”€â”€ test_data/                # Raw test images
â”‚   â”œâ”€â”€ pp_train_data/            # Preprocessed tiles
â”‚   â””â”€â”€ pp_test_data/             # Preprocessed test tiles
â””â”€â”€ out/                          # Submission files & visualizations
```

## ğŸ”§ Key Components

**Preprocessing Pipeline**:
- Shrek artifact removal (green channel corruption)
- Stain normalization & black rectangle removal
- ROI-based square cropping with padding
- Tile splitting (6-8 tiles per image)
- Offline augmentation (rotation, zoom, color jitter)

**Training Strategy**:
- Stratified Group K-Fold (prevents tile leakage)
- Class-weighted loss for imbalance
- Mixed precision training (AMP)
- Cosine annealing LR scheduler
- Early stopping with patience

**Inference**:
- 4-fold ensemble averaging
- Tile-to-image aggregation (softmax averaging)
- Test-time augmentation optional

## ğŸ“Š Results

| Configuration | Val F1 | Test F1 |
|--------------|--------|---------|
| Baseline (no preprocessing) | 0.19 | - |
| + Preprocessing | 0.32 | 0.29 |
| + K-fold ensemble | 0.47 | 0.33 |
| **Final (strong aug + ensemble)** | **0.72** | **0.39** |

## ğŸ¨ Visualization

Grad-CAM heatmaps available in `out/gradcam/` showing model attention on discriminative tissue features.

## âš™ï¸ Requirements

- Python 3.8+
- PyTorch 2.0+
- torchvision, scikit-learn, opencv-python, pandas, matplotlib




*Project developed for AN2DL Challenge 2 (2025)*

---
---
---

# Pirate Pain Time-Series Classification

This repository contains our solution to the **AN2DL First Challenge**: predicting a subjectâ€™s true pain level (no_pain, low_pain, high_pain) from multivariate time-series data collected from both ordinary people and pirates.

The project combines a **modular preprocessing pipeline** with a **Bidirectional GRU-based recurrent neural network** trained via **shuffled K-fold cross-validation** and extensive **grid search** over key hyperparameters. The final main model achieves a macro F1-score of **0.9567** on the test set.

## Repository Structure

### Main Files

- **`preprocessing.py`**  
  Modular preprocessing pipeline with configurable steps. Each preprocessing step can be enabled/disabled via configuration flags at the top of the script.

- **`main.ipynb`**  
  Main notebook with the complete pipeline with GRU: data exploration, preprocessing integration, Bidirectional GRU model training with K-fold cross-validation, and final evaluation.

- **`CNN_BiGRU.ipynb`**  
  Experimental notebook exploring an alternative architecture (CNN + Bidirectional GRU) and additional grid search experiments.

### Analysis

- **`analysis/temporal_features_analysis.py`**  
  Analyzes discriminative power of temporal features (diff, rolling stats, EWM) using ANOVA F-statistics and generates comparison visualizations.

- **`analysis/outliers_analysis.py`**  
  Detects and quantifies outlier impact using multiple methods (Z-score, IQR, MAD) with time-series-aware analysis per sample.

### Data

- **`data/`**  
  Contains input CSV files:
  - `pirate_pain_train.csv` â€“ training time-series data
  - `pirate_pain_train_labels.csv` â€“ ground-truth labels for the training set
  - `pirate_pain_test.csv` â€“ test time-series data

### Output

- **`out/`**  
  Preprocessed data generated by `preprocessing.py`:
  - `preprocessed_train.csv` â€“ processed training data
  - `preprocessed_test.csv` â€“ processed test data
  - `preprocessed_labels.csv` â€“ labels

- **`plots/`**  
  Visualizations generated by analysis scripts

- **`pirate_pain_test_predictions.csv`**  
  Final predictions for submission

### Configuration

- **`requirements.txt`**  
  Python dependencies for CPU environments

- **`requirements_cuda.txt`**  
  Python dependencies for CUDA-enabled GPU environments

---

## How to Run

### 1. Download data

```bash
kaggle competitions download -c an2dl2526c1
```

### 2. Setup Environment

Clone the repository and install dependencies:

```bash
git clone https://github.com/FedericoQuartieri/ANN.git

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt  # For CPU
# OR
pip install -r requirements_cuda.txt  # For GPU with CUDA
```

### 3. Run Preprocessing (Optional)

The preprocessing script is standalone and fully configurable:

```bash
python preprocessing.py
```

This will:
- Load raw data from `data/`
- Apply configured preprocessing steps (feature engineering, outlier handling, scaling)
- Save processed data to `out/preprocessed_*.csv`

You can customize preprocessing by editing the configuration flags at the top of `preprocessing.py`.

### 4. Run Analysis Scripts (Optional)

Explore data insights with the analysis scripts:

```bash
# Analyze temporal features
python analysis/temporal_features_analysis.py

# Analyze outliers
python analysis/outliers_analysis.py
```

These will generate visualizations in the `plots/` directory.

### 5. Train and Evaluate Models

Open and run the Jupyter notebooks:

```bash
jupyter notebook
```

- **`main.ipynb`**: Complete pipeline with Bidirectional GRU model, K-fold cross-validation, and evaluation
- **`CNN_BiGRU.ipynb`**: Alternative CNN+BiGRU architecture with grid search experiments

The notebooks will:
- Load and preprocess data (or use preprocessed data from `out/`)
- Train models with the configured hyperparameters
- Generate predictions in `pirate_pain_test_predictions.csv`

---

## Acknowledgements

This work was developed as part of the **Advanced Neural Networks and Deep Learning (AN2DL)** course at Politecnico di Milano by the composed by:

- Tommaso Marchesini  
- Federico Quartieri  
- Daniele Salvi  
- Giacomo Tessera  

The project is based on the official pirate pain dataset released for the course challenge.
