# Pirate Pain Time-Series Classification

This repository contains our solution to the **AN2DL First Challenge**: predicting a subject’s true pain level (no_pain, low_pain, high_pain) from multivariate time-series data collected from both ordinary people and pirates.

The project combines a **modular preprocessing pipeline** with a **Bidirectional GRU-based recurrent neural network** trained via **shuffled K-fold cross-validation** and extensive **grid search** over key hyperparameters. The final main model achieves a macro F1-score of **0.9567** on the test set.

## Repository Structure

### Main Files

- **`preprocessing.py`**  
  Modular preprocessing pipeline with configurable steps. Each preprocessing step can be enabled/disabled via configuration flags at the top of the script.

- **`main.ipynb`**  
  Main notebook with the complete pipeline with GRU: data exploration, preprocessing integration, Bidirectional GRU model training with K-fold cross-validation, and final evaluation.

- **`CNN_BiGRU.ipynb`**  
  Experimental notebook exploring an alternative architecture (CNN + Bidirectional GRU) and additional grid search experiments.

### Analysis

- **`analysis/temporal_features_analysis.py`**  
  Analyzes discriminative power of temporal features (diff, rolling stats, EWM) using ANOVA F-statistics and generates comparison visualizations.

- **`analysis/outliers_analysis.py`**  
  Detects and quantifies outlier impact using multiple methods (Z-score, IQR, MAD) with time-series-aware analysis per sample.

### Data

- **`data/`**  
  Contains input CSV files:
  - `pirate_pain_train.csv` – training time-series data
  - `pirate_pain_train_labels.csv` – ground-truth labels for the training set
  - `pirate_pain_test.csv` – test time-series data

### Output

- **`out/`**  
  Preprocessed data generated by `preprocessing.py`:
  - `preprocessed_train.csv` – processed training data
  - `preprocessed_test.csv` – processed test data
  - `preprocessed_labels.csv` – labels

- **`plots/`**  
  Visualizations generated by analysis scripts

- **`pirate_pain_test_predictions.csv`**  
  Final predictions for submission

### Configuration

- **`requirements.txt`**  
  Python dependencies for CPU environments

- **`requirements_cuda.txt`**  
  Python dependencies for CUDA-enabled GPU environments

---

## How to Run

### 1. Download data

kaggle competitions download -c an2dl2526c1

### 2. Setup Environment

Clone the repository and install dependencies:

```bash
git clone https://github.com/FedericoQuartieri/ANN.git

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt  # For CPU
# OR
pip install -r requirements_cuda.txt  # For GPU with CUDA
```

### 3. Run Preprocessing (Optional)

The preprocessing script is standalone and fully configurable:

```bash
python preprocessing.py
```

This will:
- Load raw data from `data/`
- Apply configured preprocessing steps (feature engineering, outlier handling, scaling)
- Save processed data to `out/preprocessed_*.csv`

You can customize preprocessing by editing the configuration flags at the top of `preprocessing.py`.

### 4. Run Analysis Scripts (Optional)

Explore data insights with the analysis scripts:

```bash
# Analyze temporal features
python analysis/temporal_features_analysis.py

# Analyze outliers
python analysis/outliers_analysis.py
```

These will generate visualizations in the `plots/` directory.

### 5. Train and Evaluate Models

Open and run the Jupyter notebooks:

```bash
jupyter notebook
```

- **`main.ipynb`**: Complete pipeline with Bidirectional GRU model, K-fold cross-validation, and evaluation
- **`CNN_BiGRU.ipynb`**: Alternative CNN+BiGRU architecture with grid search experiments

The notebooks will:
- Load and preprocess data (or use preprocessed data from `out/`)
- Train models with the configured hyperparameters
- Generate predictions in `pirate_pain_test_predictions.csv`

---

## Acknowledgements

This work was developed as part of the **Advanced Neural Networks and Deep Learning (AN2DL)** course at Politecnico di Milano by the composed by:

- Tommaso Marchesini  
- Federico Quartieri  
- Daniele Salvi  
- Giacomo Tessera  

The project is based on the official pirate pain dataset released for the course challenge.
