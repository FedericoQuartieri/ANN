{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v-in9ArBRwrp"
      },
      "outputs": [],
      "source": [
        "# OPTIMAL HYPERPARAMETERS - Based on empirical results\n",
        "\n",
        "PATIENCE = 40\n",
        "VERBOSE = 10\n",
        "\n",
        "RNN_TYPE = 'GRU'\n",
        "BIDIRECTIONAL = True\n",
        "L1_LAMBDA = 0\n",
        "\n",
        "\n",
        "# Reverse mapping from integers to pain level names\n",
        "label_reverse_mapping = {\n",
        "    0: 'no_pain',\n",
        "    1: 'low_pain',\n",
        "    2: 'high_pain'\n",
        "}\n",
        "\n",
        "# Create mapping dictionary for pain levels\n",
        "pain_mapping = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 1,\n",
        "    'high_pain': 2\n",
        "}\n",
        "\n",
        "labels = ['no_pain', 'low_pain', 'high_pain']\n",
        "\n",
        "num_classes = len(labels)\n",
        "\n",
        "# # Define parameters to search\n",
        "# param_grid = {\n",
        "#     'window_size': [50, 100, 160],\n",
        "#     'stride': [25],\n",
        "#     'n_val_users' : [45],\n",
        "#     'hidden_size': [64, 128],\n",
        "#     'hidden_layers': [1, 2],\n",
        "#     'batch_size': [64, 256],\n",
        "#     'learning_rate' : [1e-3, 3e-4],\n",
        "#     'dropout_rate': [0.0, 0.3, 0.5],\n",
        "#     'l2_lambda': [0, 1e-4, 1e-3],\n",
        "#     'k' : [5],\n",
        "#     'epochs': [400]\n",
        "# }\n",
        "\n",
        "\n",
        "# # Define parameters to search\n",
        "# param_grid = {\n",
        "#     'window_size': [50, 160],\n",
        "#     'stride': [25],\n",
        "#     'n_val_users' : [45],\n",
        "#     'hidden_size': [64, 128],\n",
        "#     'hidden_layers': [1, 2],\n",
        "#     'batch_size': [64, 256],\n",
        "#     'learning_rate' : [1e-3, 3e-4],\n",
        "#     'dropout_rate': [0.0, 0.3],\n",
        "#     'l2_lambda': [0, 1e-4],\n",
        "#     'k' : [5],\n",
        "#     'epochs': [400]\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "# param_grid = {\n",
        "\n",
        "#     'window_size':   [100, 160],      # 2\n",
        "#     'stride':        [25],\n",
        "#     'n_val_users':   [45],\n",
        "\n",
        "#     'hidden_size':   [64, 128],       # 2\n",
        "#     'hidden_layers': [2],\n",
        "\n",
        "#     'batch_size':    [128],\n",
        "#     'learning_rate': [1e-3, 8e-4, 6e-4, 4e-4, 3e-4],  # 5 (log-ish sweep)\n",
        "#     'dropout_rate':  [0.3],\n",
        "#     'l2_lambda':     [1e-4],\n",
        "\n",
        "#     'k':             [5],             # single subject-level split for speed\n",
        "#     'epochs':        [200]            # rely on early stopping\n",
        "# }\n",
        "\n",
        "\n",
        "#test\n",
        "param_grid = {\n",
        "    # split robusto\n",
        "    'n_val_users':   [55],\n",
        "    'k':             [5],\n",
        "    'epochs':        [200],\n",
        "\n",
        "    # CONTEXT – metti qui i TUOI best\n",
        "    'window_size':   [24],   # <-- sostituisci con il tuo best se diverso\n",
        "    'stride':        [4],    # <-- idem\n",
        "\n",
        "    # ARCH – fissiamo la famiglia che va meglio\n",
        "    'hidden_layers': [2],\n",
        "    'hidden_size':   [128],\n",
        "\n",
        "    # OPT / REGULARIZATION – qui facciamo il vero finer tuning\n",
        "    'batch_size':    [256, 512],        # 2  (più o meno rumore di gradiente)\n",
        "    'learning_rate': [1e-3, 8e-4],# 2  (range “alto ma stabile” per te)\n",
        "    'dropout_rate':  [0.3],        # 1  (meno o più reg)\n",
        "    'l2_lambda':     [1e-4, 5e-4],      # 2  (L2 moderato/forte)\n",
        "\n",
        "    # se il runner li richiede:\n",
        "    # 'rnn_type':     ['LSTM'],\n",
        "    # 'bidirectional':[True],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-95VNzsCBdWV",
        "outputId": "3a433880-e734-4515-b0cd-94a106a42b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skip set_num_interop_threads: Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called\n",
            "DEBUG TORCH:\n",
            "  torch.__version__     = 2.9.1+cpu\n",
            "  torch.version.cuda    = None\n",
            "  torch.cuda.is_available() = False\n",
            "  torch.cuda.device_count()  = 0\n",
            "  selected device = cpu\n",
            "PyTorch version: 2.9.1+cpu\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os, random, numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def physical_cores():\n",
        "    try:\n",
        "        import psutil\n",
        "        n = psutil.cpu_count(logical=False)\n",
        "        if n:\n",
        "            return n\n",
        "    except Exception:\n",
        "        pass\n",
        "    n = os.cpu_count() or 2\n",
        "    return max(1, n // 2)  # stima fisici se non disponibile\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "CONVERTIBLE = False\n",
        "\n",
        "\n",
        "# Env PRIMA di import torch\n",
        "CORES = physical_cores()\n",
        "OMP = max(1, CORES - 1)\n",
        "os.environ.setdefault(\"OMP_NUM_THREADS\", str(OMP))\n",
        "os.environ.setdefault(\"MKL_NUM_THREADS\", str(OMP))\n",
        "os.environ.setdefault(\"MKL_DYNAMIC\", \"FALSE\")\n",
        "os.environ.setdefault(\"VECLIB_MAXIMUM_THREADS\", str(OMP))\n",
        "os.environ.setdefault(\"TORCH_NUM_INTEROP_THREADS\", \"1\")\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "torch.set_num_threads(int(os.environ[\"OMP_NUM_THREADS\"]))\n",
        "try:\n",
        "    torch.set_num_interop_threads(int(os.environ[\"TORCH_NUM_INTEROP_THREADS\"]))\n",
        "except RuntimeError as e:\n",
        "    print(\"skip set_num_interop_threads:\", e)\n",
        "\n",
        "\n",
        "\n",
        "# Import necessary libraries\n",
        "import os, subprocess, shlex\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "\n",
        "# Device selection: prefer CUDA when available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "print(\"DEBUG TORCH:\")\n",
        "print(\"  torch.__version__     =\", torch.__version__)\n",
        "print(\"  torch.version.cuda    =\", torch.version.cuda)\n",
        "print(\"  torch.cuda.is_available() =\", torch.cuda.is_available())\n",
        "print(\"  torch.cuda.device_count()  =\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    try:\n",
        "        print(\"  GPU name:\", torch.cuda.get_device_name(0))\n",
        "    except Exception as e:\n",
        "        print(\"  get_device_name error:\", e)\n",
        "print(\"  selected device =\", device)\n",
        "\n",
        "\n",
        "# from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from itertools import product\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not CONVERTIBLE:\n",
        "\n",
        "    # Configure plot display settings\n",
        "    sns.set(font_scale=1.4)\n",
        "    sns.set_style('white')\n",
        "    plt.rc('font', size=14)\n",
        "    %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsV2HL_gD9cl",
        "outputId": "b009f7bb-cb68-4722-e7ed-f6ca47f070ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First few rows of X_train with encoded labels:\n",
            "   sample_index  label\n",
            "0             0      0\n",
            "1             0      0\n",
            "2             0      0\n",
            "3             0      0\n",
            "4             0      0\n",
            "5             0      0\n",
            "6             0      0\n",
            "7             0      0\n",
            "8             0      0\n",
            "9             0      0\n",
            "\n",
            "Label value counts:\n",
            "label\n",
            "0    81760\n",
            "1    15040\n",
            "2     8960\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Check for NaN labels:\n",
            "NaN count: 0\n"
          ]
        }
      ],
      "source": [
        "X_train = pd.read_csv('data/pirate_pain_train.csv')\n",
        "y_train = pd.read_csv('data/pirate_pain_train_labels.csv')\n",
        "\n",
        "\n",
        "# First map the labels in y_train\n",
        "y_train['label_encoded'] = y_train['label'].map(pain_mapping)\n",
        "\n",
        "# Then merge with X_train based on sample_index\n",
        "X_train = X_train.merge(\n",
        "    y_train[['sample_index', 'label_encoded']],\n",
        "    on='sample_index',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Rename the column\n",
        "X_train.rename(columns={'label_encoded': 'label'}, inplace=True)\n",
        "\n",
        "# Verify the mapping worked correctly\n",
        "print(\"\\nFirst few rows of X_train with encoded labels:\")\n",
        "print(X_train[['sample_index', 'label']].head(10))\n",
        "\n",
        "print(\"\\nLabel value counts:\")\n",
        "print(X_train['label'].value_counts())\n",
        "\n",
        "print(\"\\nCheck for NaN labels:\")\n",
        "print(f\"NaN count: {X_train['label'].isna().sum()}\")\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acRv6ssvQQSM",
        "outputId": "31e821a2-81af-46ce-98d7-9efd1777f198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping joint_30 column (all NaN values)...\n",
            "Dropped joint_30 from (105760, 40)\n",
            "\n",
            "Columns after dropping joint_30:\n",
            "X_train columns: 40\n"
          ]
        }
      ],
      "source": [
        "# Drop joint_30 column (contains only NaN values)\n",
        "print(\"Dropping joint_30 column (all NaN values)...\")\n",
        "for df in [X_train]:\n",
        "    if 'joint_30' in df.columns:\n",
        "        df.drop('joint_30', axis=1, inplace=True)\n",
        "        print(f\"Dropped joint_30 from {df.shape}\")\n",
        "\n",
        "print(\"\\nColumns after dropping joint_30:\")\n",
        "print(f\"X_train columns: {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2dx6K_ZQQSN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X-Pan_2kQQSO"
      },
      "outputs": [],
      "source": [
        "# First: Convert categorical variables to binary (two -> 1, others -> 0)\n",
        "binary_cols = ['n_hands', 'n_eyes', 'n_legs']\n",
        "for col in binary_cols:\n",
        "    for df_ in [X_train]:\n",
        "        df_[col] = df_[col].map(lambda x: 1 if str(x).lower().strip() == 'two' else 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9NAklF6FP2G",
        "outputId": "e032216a-e1bf-44c8-9887-6d3ba2f884fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Data structure ---\n",
            "\n",
            "X_train Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 105760 entries, 0 to 105759\n",
            "Data columns (total 40 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   sample_index   105760 non-null  int64  \n",
            " 1   time           105760 non-null  int64  \n",
            " 2   pain_survey_1  105760 non-null  int64  \n",
            " 3   pain_survey_2  105760 non-null  int64  \n",
            " 4   pain_survey_3  105760 non-null  int64  \n",
            " 5   pain_survey_4  105760 non-null  int64  \n",
            " 6   n_legs         105760 non-null  int64  \n",
            " 7   n_hands        105760 non-null  int64  \n",
            " 8   n_eyes         105760 non-null  int64  \n",
            " 9   joint_00       105760 non-null  float64\n",
            " 10  joint_01       105760 non-null  float64\n",
            " 11  joint_02       105760 non-null  float64\n",
            " 12  joint_03       105760 non-null  float64\n",
            " 13  joint_04       105760 non-null  float64\n",
            " 14  joint_05       105760 non-null  float64\n",
            " 15  joint_06       105760 non-null  float64\n",
            " 16  joint_07       105760 non-null  float64\n",
            " 17  joint_08       105760 non-null  float64\n",
            " 18  joint_09       105760 non-null  float64\n",
            " 19  joint_10       105760 non-null  float64\n",
            " 20  joint_11       105760 non-null  float64\n",
            " 21  joint_12       105760 non-null  float64\n",
            " 22  joint_13       105760 non-null  float64\n",
            " 23  joint_14       105760 non-null  float64\n",
            " 24  joint_15       105760 non-null  float64\n",
            " 25  joint_16       105760 non-null  float64\n",
            " 26  joint_17       105760 non-null  float64\n",
            " 27  joint_18       105760 non-null  float64\n",
            " 28  joint_19       105760 non-null  float64\n",
            " 29  joint_20       105760 non-null  float64\n",
            " 30  joint_21       105760 non-null  float64\n",
            " 31  joint_22       105760 non-null  float64\n",
            " 32  joint_23       105760 non-null  float64\n",
            " 33  joint_24       105760 non-null  float64\n",
            " 34  joint_25       105760 non-null  float64\n",
            " 35  joint_26       105760 non-null  float64\n",
            " 36  joint_27       105760 non-null  float64\n",
            " 37  joint_28       105760 non-null  float64\n",
            " 38  joint_29       105760 non-null  float64\n",
            " 39  label          105760 non-null  int64  \n",
            "dtypes: float64(30), int64(10)\n",
            "memory usage: 32.3 MB\n",
            "\n",
            "Missing values in X_train: 0\n",
            "\n",
            "y_train Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 661 entries, 0 to 660\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   sample_index   661 non-null    int64 \n",
            " 1   label          661 non-null    object\n",
            " 2   label_encoded  661 non-null    int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 15.6+ KB\n",
            "\n",
            "Missing values in y_train: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Data structure ---\")\n",
        "print(\"\\nX_train Info:\")\n",
        "X_train.info(verbose=True)\n",
        "print(f\"\\nMissing values in X_train: {X_train.isnull().sum().sum()}\")\n",
        "print(\"\\ny_train Info:\")\n",
        "y_train.info(verbose=True)\n",
        "print(f\"\\nMissing values in y_train: {y_train.isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "NBmYSucNGROn",
        "outputId": "72ce8ce8-90ab-4f41-b4cc-49f658685121"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>330.000000</td>\n",
              "      <td>79.500000</td>\n",
              "      <td>1.633746</td>\n",
              "      <td>1.654851</td>\n",
              "      <td>1.653640</td>\n",
              "      <td>1.663134</td>\n",
              "      <td>0.990923</td>\n",
              "      <td>0.990923</td>\n",
              "      <td>0.990923</td>\n",
              "      <td>0.943095</td>\n",
              "      <td>...</td>\n",
              "      <td>3.972126e-05</td>\n",
              "      <td>4.176794e-05</td>\n",
              "      <td>3.561780e-05</td>\n",
              "      <td>3.138109e-05</td>\n",
              "      <td>1.024604e-04</td>\n",
              "      <td>0.041905</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.049886</td>\n",
              "      <td>0.062273</td>\n",
              "      <td>0.311649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>190.814948</td>\n",
              "      <td>46.187338</td>\n",
              "      <td>0.682423</td>\n",
              "      <td>0.669639</td>\n",
              "      <td>0.666649</td>\n",
              "      <td>0.661994</td>\n",
              "      <td>0.094841</td>\n",
              "      <td>0.094841</td>\n",
              "      <td>0.094841</td>\n",
              "      <td>0.202051</td>\n",
              "      <td>...</td>\n",
              "      <td>4.974496e-03</td>\n",
              "      <td>5.472244e-03</td>\n",
              "      <td>1.235450e-03</td>\n",
              "      <td>4.062914e-04</td>\n",
              "      <td>3.206128e-03</td>\n",
              "      <td>0.060293</td>\n",
              "      <td>0.079819</td>\n",
              "      <td>0.060773</td>\n",
              "      <td>0.072597</td>\n",
              "      <td>0.619651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.510494e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.063144e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>165.000000</td>\n",
              "      <td>39.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.828277</td>\n",
              "      <td>...</td>\n",
              "      <td>6.545878e-08</td>\n",
              "      <td>3.321650e-07</td>\n",
              "      <td>3.275038e-07</td>\n",
              "      <td>2.841805e-07</td>\n",
              "      <td>7.161332e-07</td>\n",
              "      <td>0.009885</td>\n",
              "      <td>0.012652</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>0.019638</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>330.000000</td>\n",
              "      <td>79.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.005126</td>\n",
              "      <td>...</td>\n",
              "      <td>8.302747e-07</td>\n",
              "      <td>1.095971e-06</td>\n",
              "      <td>1.024209e-06</td>\n",
              "      <td>8.746147e-07</td>\n",
              "      <td>3.126723e-06</td>\n",
              "      <td>0.021898</td>\n",
              "      <td>0.031739</td>\n",
              "      <td>0.031843</td>\n",
              "      <td>0.039041</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>495.000000</td>\n",
              "      <td>119.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.081039</td>\n",
              "      <td>...</td>\n",
              "      <td>2.800090e-06</td>\n",
              "      <td>3.079465e-06</td>\n",
              "      <td>3.021830e-06</td>\n",
              "      <td>2.507548e-06</td>\n",
              "      <td>9.946107e-06</td>\n",
              "      <td>0.048579</td>\n",
              "      <td>0.071051</td>\n",
              "      <td>0.058741</td>\n",
              "      <td>0.079518</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>660.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.407968</td>\n",
              "      <td>...</td>\n",
              "      <td>1.442198e+00</td>\n",
              "      <td>1.305001e+00</td>\n",
              "      <td>2.742411e-01</td>\n",
              "      <td>3.643074e-02</td>\n",
              "      <td>9.473540e-01</td>\n",
              "      <td>1.223617</td>\n",
              "      <td>1.187419</td>\n",
              "      <td>1.412037</td>\n",
              "      <td>1.370765</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sample_index           time  pain_survey_1  pain_survey_2  \\\n",
              "count  105760.000000  105760.000000  105760.000000  105760.000000   \n",
              "mean      330.000000      79.500000       1.633746       1.654851   \n",
              "std       190.814948      46.187338       0.682423       0.669639   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%       165.000000      39.750000       2.000000       2.000000   \n",
              "50%       330.000000      79.500000       2.000000       2.000000   \n",
              "75%       495.000000     119.250000       2.000000       2.000000   \n",
              "max       660.000000     159.000000       2.000000       2.000000   \n",
              "\n",
              "       pain_survey_3  pain_survey_4         n_legs        n_hands  \\\n",
              "count  105760.000000  105760.000000  105760.000000  105760.000000   \n",
              "mean        1.653640       1.663134       0.990923       0.990923   \n",
              "std         0.666649       0.661994       0.094841       0.094841   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         2.000000       2.000000       1.000000       1.000000   \n",
              "50%         2.000000       2.000000       1.000000       1.000000   \n",
              "75%         2.000000       2.000000       1.000000       1.000000   \n",
              "max         2.000000       2.000000       1.000000       1.000000   \n",
              "\n",
              "              n_eyes       joint_00  ...      joint_21      joint_22  \\\n",
              "count  105760.000000  105760.000000  ...  1.057600e+05  1.057600e+05   \n",
              "mean        0.990923       0.943095  ...  3.972126e-05  4.176794e-05   \n",
              "std         0.094841       0.202051  ...  4.974496e-03  5.472244e-03   \n",
              "min         0.000000       0.000000  ...  0.000000e+00  1.510494e-07   \n",
              "25%         1.000000       0.828277  ...  6.545878e-08  3.321650e-07   \n",
              "50%         1.000000       1.005126  ...  8.302747e-07  1.095971e-06   \n",
              "75%         1.000000       1.081039  ...  2.800090e-06  3.079465e-06   \n",
              "max         1.000000       1.407968  ...  1.442198e+00  1.305001e+00   \n",
              "\n",
              "           joint_23      joint_24      joint_25       joint_26       joint_27  \\\n",
              "count  1.057600e+05  1.057600e+05  1.057600e+05  105760.000000  105760.000000   \n",
              "mean   3.561780e-05  3.138109e-05  1.024604e-04       0.041905       0.058244   \n",
              "std    1.235450e-03  4.062914e-04  3.206128e-03       0.060293       0.079819   \n",
              "min    0.000000e+00  1.063144e-08  0.000000e+00       0.000203       0.000000   \n",
              "25%    3.275038e-07  2.841805e-07  7.161332e-07       0.009885       0.012652   \n",
              "50%    1.024209e-06  8.746147e-07  3.126723e-06       0.021898       0.031739   \n",
              "75%    3.021830e-06  2.507548e-06  9.946107e-06       0.048579       0.071051   \n",
              "max    2.742411e-01  3.643074e-02  9.473540e-01       1.223617       1.187419   \n",
              "\n",
              "            joint_28       joint_29          label  \n",
              "count  105760.000000  105760.000000  105760.000000  \n",
              "mean        0.049886       0.062273       0.311649  \n",
              "std         0.060773       0.072597       0.619651  \n",
              "min         0.000000       0.000000       0.000000  \n",
              "25%         0.016290       0.019638       0.000000  \n",
              "50%         0.031843       0.039041       0.000000  \n",
              "75%         0.058741       0.079518       0.000000  \n",
              "max         1.412037       1.370765       2.000000  \n",
              "\n",
              "[8 rows x 40 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W3yOX19MQQSR"
      },
      "outputs": [],
      "source": [
        "def build_sequences(df, window=200, stride=50):\n",
        "    \"\"\"\n",
        "    Build sequences from time-series data\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with the data\n",
        "        window: Window size for sequences\n",
        "        stride: Stride for overlapping windows\n",
        "\n",
        "    Returns:\n",
        "        dataset: numpy array of sequences\n",
        "        labels: numpy array of labels\n",
        "    \"\"\"\n",
        "    # Initialise lists to store sequences and their corresponding labels\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over unique IDs in the DataFrame\n",
        "    for sample_id in df['sample_index'].unique():\n",
        "        # Extract sensor data for the current ID\n",
        "        drop_cols = [c for c in ['sample_index', 'time', 'label', 'labels'] if c in df.columns]\n",
        "        temp = df[df['sample_index'] == sample_id].drop(columns=drop_cols).values.astype('float32')\n",
        "\n",
        "        # Retrieve the activity label for the current ID\n",
        "        label_series = df[df['sample_index'] == sample_id]['label']\n",
        "\n",
        "        # Check if label column exists and has values\n",
        "        if label_series.empty:\n",
        "            print(f\"Warning: No label found for sample_id {sample_id}\")\n",
        "            continue\n",
        "\n",
        "        label_value = label_series.values[0]\n",
        "\n",
        "        # Skip samples with NaN labels\n",
        "        if pd.isna(label_value):\n",
        "            print(f\"Warning: NaN label for sample_id {sample_id}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Convert to int and validate\n",
        "        try:\n",
        "            label = int(label_value)\n",
        "            if label < 0 or label > 2:  # Assuming 3 classes: 0, 1, 2\n",
        "                print(f\"Warning: Invalid label {label} for sample_id {sample_id}, skipping...\")\n",
        "                continue\n",
        "        except (ValueError, TypeError) as e:\n",
        "            print(f\"Warning: Cannot convert label {label_value} to int for sample_id {sample_id}: {e}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        # --- NEW: niente padding a multipli di window ---\n",
        "        L = len(temp)\n",
        "\n",
        "        # PADDING SOLO se L < window (così hai almeno 1 finestra)\n",
        "        if L < window:\n",
        "            pad = window - L\n",
        "            temp = np.concatenate([temp, np.zeros((pad, temp.shape[1]), dtype='float32')], axis=0)\n",
        "            L = len(temp)  # ora L == window\n",
        "\n",
        "        # Genera gli start con lo stride, SENZA espandere a multipli di window\n",
        "        starts = list(range(0, max(L - window, 0) + 1, stride))\n",
        "\n",
        "        # (opzionale ma consigliato) ancora l’ultima finestra alla fine se non allineata\n",
        "        last_start = L - window\n",
        "        if last_start >= 0 and (len(starts) == 0 or starts[-1] != last_start):\n",
        "            starts.append(last_start)\n",
        "\n",
        "        for s in starts:\n",
        "            dataset.append(temp[s:s+window])\n",
        "            labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Convert lists to numpy arrays for further processing\n",
        "    dataset = np.array(dataset, dtype='float32')\n",
        "    labels = np.array(labels, dtype='int64')\n",
        "\n",
        "    print(f\"Built {len(dataset)} sequences with {len(labels)} labels\")\n",
        "\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S7SdOdxjQQSS"
      },
      "outputs": [],
      "source": [
        "#BATCH_SIZE = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G0ypRlR4QQST"
      },
      "outputs": [],
      "source": [
        "def make_loader(ds, batch_size, shuffle, drop_last):\n",
        "    # Determine optimal number of worker processes for data loading\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "\n",
        "    # Create DataLoader with performance optimizations\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,  # Load 4 batches ahead\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GpR5aspoQQST"
      },
      "outputs": [],
      "source": [
        "def recurrent_summary(model, input_size):\n",
        "    \"\"\"\n",
        "    Custom summary function that emulates torchinfo's output while correctly\n",
        "    counting parameters for RNN/GRU/LSTM layers.\n",
        "\n",
        "    This function is designed for models whose direct children are\n",
        "    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to analyze.\n",
        "        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n",
        "    \"\"\"\n",
        "\n",
        "    # Dictionary to store output shapes captured by forward hooks\n",
        "    output_shapes = {}\n",
        "    # List to track hook handles for later removal\n",
        "    hooks = []\n",
        "\n",
        "    def get_hook(name):\n",
        "        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n",
        "        def hook(module, input, output):\n",
        "            # Handle RNN layer outputs (returns a tuple)\n",
        "            if isinstance(output, tuple):\n",
        "                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n",
        "                shape1 = list(output[0].shape)\n",
        "                shape1[0] = -1  # Replace batch dimension with -1\n",
        "\n",
        "                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n",
        "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
        "                    shape2 = list(output[1][0].shape)  # Extract h_n only\n",
        "                else:  # RNN/GRU case: h_n only\n",
        "                    shape2 = list(output[1].shape)\n",
        "\n",
        "                # Replace batch dimension (middle position) with -1\n",
        "                shape2[1] = -1\n",
        "\n",
        "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
        "\n",
        "            # Handle standard layer outputs (e.g., Linear)\n",
        "            else:\n",
        "                shape = list(output.shape)\n",
        "                shape[0] = -1  # Replace batch dimension with -1\n",
        "                output_shapes[name] = f\"{shape}\"\n",
        "        return hook\n",
        "\n",
        "    # 1. Determine the device where model parameters reside\n",
        "    try:\n",
        "        device = next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        device = torch.device(\"cpu\")  # Fallback for models without parameters\n",
        "\n",
        "    # 2. Create a dummy input tensor with batch_size=1\n",
        "    dummy_input = torch.randn(1, *input_size).to(device)\n",
        "\n",
        "    # 3. Register forward hooks on target layers\n",
        "    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
        "            # Register the hook and store its handle for cleanup\n",
        "            hook_handle = module.register_forward_hook(get_hook(name))\n",
        "            hooks.append(hook_handle)\n",
        "\n",
        "    # 4. Execute a dummy forward pass in evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            model(dummy_input)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during dummy forward pass: {e}\")\n",
        "            # Clean up hooks even if an error occurs\n",
        "            for h in hooks:\n",
        "                h.remove()\n",
        "            return\n",
        "\n",
        "    # 5. Remove all registered hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    # --- 6. Print the summary table ---\n",
        "\n",
        "    print(\"-\" * 79)\n",
        "    # Column headers\n",
        "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
        "    print(\"=\" * 79)\n",
        "\n",
        "    total_params = 0\n",
        "    total_trainable_params = 0\n",
        "\n",
        "    # Iterate through modules again to collect and display parameter information\n",
        "    for name, module in model.named_children():\n",
        "        if name in output_shapes:\n",
        "            # Count total and trainable parameters for this module\n",
        "            module_params = sum(p.numel() for p in module.parameters())\n",
        "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "            total_params += module_params\n",
        "            total_trainable_params += trainable_params\n",
        "\n",
        "            # Format strings for display\n",
        "            layer_name = f\"{name} ({type(module).__name__})\"\n",
        "            output_shape_str = str(output_shapes[name])\n",
        "            params_str = f\"{trainable_params:,}\"\n",
        "\n",
        "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
        "\n",
        "    print(\"=\" * 79)\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
        "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
        "    print(\"-\" * 79)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKJ48pWqQQST",
        "outputId": "db6cd393-fa0f-4ef1-9202-65f874154cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (RNN)                 [[-1, 128], [2, -1]]         54,912         \n",
            "classifier (Linear)       [-1]                         387            \n",
            "===============================================================================\n",
            "Total params: 55,299\n",
            "Trainable params: 55,299\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class RecurrentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Generic RNN classifier (RNN, LSTM, GRU).\n",
        "    Uses the last hidden state for classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            num_classes,\n",
        "            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n",
        "            bidirectional=False,\n",
        "            dropout_rate=0.2\n",
        "            ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Map string name to PyTorch RNN class\n",
        "        rnn_map = {\n",
        "            'RNN': nn.RNN,\n",
        "            'LSTM': nn.LSTM,\n",
        "            'GRU': nn.GRU\n",
        "        }\n",
        "\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "\n",
        "        # Dropout is only applied between layers (if num_layers > 1)\n",
        "        dropout_val = dropout_rate if num_layers > 1 else 0\n",
        "\n",
        "        # Create the recurrent layer\n",
        "        self.rnn = rnn_module(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout_val\n",
        "        )\n",
        "\n",
        "        # Calculate input size for the final classifier\n",
        "        if self.bidirectional:\n",
        "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
        "        else:\n",
        "            classifier_input_size = hidden_size\n",
        "\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(classifier_input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_length, input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
        "        rnn_out, hidden = self.rnn(x)\n",
        "\n",
        "        # LSTM returns (h_n, c_n), we only need h_n\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            hidden = hidden[0]\n",
        "\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
        "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
        "\n",
        "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
        "            # Final shape: (batch_size, hidden_size * 2)\n",
        "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
        "        else:\n",
        "            # Take the last layer's hidden state\n",
        "            # Final shape: (batch_size, hidden_size)\n",
        "            hidden_to_classify = hidden[-1]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.classifier(hidden_to_classify)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Create model and display architecture with parameter count\n",
        "rnn_model = RecurrentClassifier(\n",
        "    input_size=input_shape[-1], # Pass the number of features\n",
        "    hidden_size=128,\n",
        "    num_layers=2,\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=0.,\n",
        "    rnn_type='RNN'\n",
        "    ).to(device)\n",
        "recurrent_summary(rnn_model, input_size=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "o1HTpkmJQQSU"
      },
      "outputs": [],
      "source": [
        "# Initialize best model tracking variables\n",
        "best_model = None\n",
        "best_performance = float('-inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5S4P5W1AQQSU"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
        "    \"\"\"\n",
        "    Perform one complete training epoch through the entire training dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): Lambda for L1 regularization\n",
        "        l2_lambda (float): Lambda for L2 regularization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Iterate through training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision (if CUDA available)\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            # Add L1 and L2 regularization\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
        "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
        "\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZnCsqUqtQQSU"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform one complete validation epoch through the entire validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        criterion (nn.Module): Loss function used to calculate validation loss\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
        "\n",
        "    Note:\n",
        "        This function automatically sets the model to evaluation mode and disables\n",
        "        gradient computation for efficiency during validation.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision (if CUDA available)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = logits.argmax(dim=1)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_accuracy = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FLYRdcDrQQSU"
      },
      "outputs": [],
      "source": [
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
        "    \"\"\"\n",
        "    Log training metrics and model parameters to TensorBoard for visualization.\n",
        "\n",
        "    Args:\n",
        "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
        "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
        "        train_loss (float): Training loss for this epoch\n",
        "        train_f1 (float): Training f1 score for this epoch\n",
        "        val_loss (float): Validation loss for this epoch\n",
        "        val_f1 (float): Validation f1 score for this epoch\n",
        "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
        "\n",
        "    Note:\n",
        "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
        "        parameters and gradients, which helps monitor training progress and detect\n",
        "        issues like vanishing/exploding gradients.\n",
        "    \"\"\"\n",
        "    # Log scalar metrics\n",
        "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
        "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
        "\n",
        "    # Log model parameters and gradients\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Check if the tensor is not empty before adding a histogram\n",
        "            if param.numel() > 0:\n",
        "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
        "            if param.grad is not None:\n",
        "                # Check if the gradient tensor is not empty before adding a histogram\n",
        "                if param.grad.numel() > 0:\n",
        "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
        "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9ITUJXpAQQSV"
      },
      "outputs": [],
      "source": [
        "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
        "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Train the neural network model on the training data and validate on the validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        epochs (int): Number of training epochs\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
        "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
        "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
        "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
        "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
        "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
        "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
        "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
        "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, training_history) - Trained model and metrics history\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize metrics tracking\n",
        "    training_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Configure early stopping if patience is set\n",
        "    if patience > 0:\n",
        "        patience_counter = 0\n",
        "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
        "        best_epoch = 0\n",
        "\n",
        "    print(f\"Training {epochs} epochs...\")\n",
        "\n",
        "    # Main training loop: iterate through epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        # Forward pass through training data, compute gradients, update weights\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
        "        )\n",
        "\n",
        "        # Evaluate model on validation data without updating weights\n",
        "        val_loss, val_f1 = validate_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Store metrics for plotting and analysis\n",
        "        training_history['train_loss'].append(train_loss)\n",
        "        training_history['val_loss'].append(val_loss)\n",
        "        training_history['train_f1'].append(train_f1)\n",
        "        training_history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Write metrics to TensorBoard for visualization\n",
        "        if writer is not None:\n",
        "            log_metrics_to_tensorboard(\n",
        "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
        "            )\n",
        "\n",
        "        # Print progress every N epochs or on first epoch\n",
        "        if verbose > 0:\n",
        "            if epoch % verbose == 0 or epoch == 1:\n",
        "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
        "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping logic: monitor metric and save best model\n",
        "        if patience > 0:\n",
        "            current_metric = training_history[evaluation_metric][-1]\n",
        "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
        "\n",
        "            if is_improvement:\n",
        "                best_metric = current_metric\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                    break\n",
        "\n",
        "    # Restore best model weights if early stopping was used\n",
        "    if restore_best_weights and patience > 0:\n",
        "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
        "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
        "\n",
        "    # Save final model if no early stopping\n",
        "    if patience == 0:\n",
        "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
        "\n",
        "    # Close TensorBoard writer\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, training_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynGd49opQQSV"
      },
      "source": [
        "# KFOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8T-RUCTFQQSV"
      },
      "outputs": [],
      "source": [
        "def k_shuffle_split_cross_validation_round_rnn(df, epochs, criterion, device,\n",
        "                            k, n_val_users, batch_size, hidden_layers, hidden_size, learning_rate, dropout_rate,\n",
        "                            window_size, stride, rnn_type, bidirectional,\n",
        "                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "                            restore_best_weights=True, writer=None, verbose=10, seed=42, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Perform K-fold shuffle split cross-validation with sample-based splitting for Pirate Pain time series data.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with columns ['sample_index', 'time', 'label', 'pain_survey_*', 'joint_*', 'n_legs', 'n_hands', 'n_eyes']\n",
        "        epochs: Number of training epochs\n",
        "        criterion: Loss function\n",
        "        device: torch.device for computation\n",
        "        k: Number of cross-validation splits\n",
        "        n_val_users: Number of samples for validation set\n",
        "        n_test_users: Number of samples for test set\n",
        "        batch_size: Batch size for training\n",
        "        hidden_layers: Number of recurrent layers\n",
        "        hidden_size: Hidden state dimensionality\n",
        "        learning_rate: Learning rate for optimizer\n",
        "        dropout_rate: Dropout rate\n",
        "        window_size: Length of sliding windows\n",
        "        stride: Step size for sliding windows\n",
        "        rnn_type: Type of RNN ('RNN', 'LSTM', 'GRU')\n",
        "        bidirectional: Whether to use bidirectional RNN\n",
        "        l1_lambda: L1 regularization coefficient (if used)\n",
        "        l2_lambda: L2 regularization coefficient (weight_decay)\n",
        "        patience: Early stopping patience\n",
        "        evaluation_metric: Metric to monitor for early stopping\n",
        "        mode: 'max' or 'min' for evaluation metric\n",
        "        restore_best_weights: Whether to restore best weights after training\n",
        "        writer: TensorBoard writer\n",
        "        verbose: Verbosity level\n",
        "        seed: Random seed\n",
        "        experiment_name: Name for experiment logging\n",
        "\n",
        "    Returns:\n",
        "        fold_losses: Dict with validation losses for each split\n",
        "        fold_metrics: Dict with validation F1 scores for each split\n",
        "        best_scores: Dict with best F1 score for each split plus mean and std\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialise containers for results across all splits\n",
        "    fold_losses = {}\n",
        "    fold_metrics = {}\n",
        "    best_scores = {}\n",
        "\n",
        "\n",
        "    # Define columns to normalize\n",
        "    pain_survey_columns = ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes']\n",
        "    joint_columns = [f'joint_{i:02d}' for i in range(30)]  # joint_00 through joint_29\n",
        "    scale_columns = pain_survey_columns + joint_columns\n",
        "\n",
        "    # Get model architecture parameters\n",
        "    # Count features (excluding sample_index, time, label)\n",
        "    feature_cols = scale_columns  # All features that will be used\n",
        "    in_features = len(feature_cols)\n",
        "    num_classes = 3  # no_pain, low_pain, high_pain\n",
        "\n",
        "    # Initialise model architecture\n",
        "    model = RecurrentClassifier(\n",
        "        input_size=in_features,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=hidden_layers,\n",
        "        num_classes=num_classes,\n",
        "        dropout_rate=dropout_rate,\n",
        "        bidirectional=bidirectional,\n",
        "        rnn_type=rnn_type\n",
        "    ).to(device)\n",
        "\n",
        "    # Store initial weights to reset model for each split\n",
        "    initial_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Iterate through K random splits\n",
        "    for split_idx in range(k):\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"Split {split_idx+1}/{k}\")\n",
        "\n",
        "        # Get unique sample IDs and shuffle them with split-specific seed\n",
        "        unique_samples = df['sample_index'].unique()\n",
        "        random.seed(seed + split_idx)\n",
        "        random.shuffle(unique_samples)\n",
        "\n",
        "        # Calculate the number of samples for the training set\n",
        "        n_train_samples = len(unique_samples) - n_val_users\n",
        "\n",
        "        # Split the shuffled sample IDs into training, validation, and test sets\n",
        "        train_samples = unique_samples[:n_train_samples]\n",
        "        val_samples = unique_samples[n_train_samples:n_train_samples + n_val_users]\n",
        "\n",
        "        # Split the dataset into training, validation, and test sets based on sample IDs\n",
        "        df_train = df[df['sample_index'].isin(train_samples)].copy()\n",
        "        df_val = df[df['sample_index'].isin(val_samples)].copy()\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Training set shape: {df_train.shape}\")\n",
        "            print(f\"  Validation set shape: {df_val.shape}\")\n",
        "\n",
        "        # Map pain labels to integers (if not already mapped)\n",
        "        if df_train['label'].dtype == 'object':\n",
        "            df_train['label'] = df_train['label'].map(pain_mapping)\n",
        "            df_val['label'] = df_val['label'].map(pain_mapping)\n",
        "\n",
        "        # Normalise features using training set statistics\n",
        "        train_max = df_train[scale_columns].max()\n",
        "        train_min = df_train[scale_columns].min()\n",
        "\n",
        "        for column in scale_columns:\n",
        "            df_train[column] = (df_train[column] - train_min[column]) / (train_max[column] - train_min[column] + 1e-8)\n",
        "            df_val[column] = (df_val[column] - train_min[column]) / (train_max[column] - train_min[column] + 1e-8)\n",
        "\n",
        "        # Build sequences using the existing build_sequences function\n",
        "        X_train, y_train = build_sequences(df_train, window=window_size, stride=stride)\n",
        "        X_val, y_val = build_sequences(df_val, window=window_size, stride=stride)\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Training sequences shape: {X_train.shape}\")\n",
        "            print(f\"  Validation sequences shape: {X_val.shape}\")\n",
        "\n",
        "        # Calculate class weights to handle imbalance\n",
        "        class_counts = np.bincount(y_train)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights = total_samples / (num_classes * class_counts)\n",
        "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Class distribution in training: {class_counts}\")\n",
        "            print(f\"  Class weights: {class_weights}\")\n",
        "\n",
        "        # Create weighted loss function for this split\n",
        "        criterion_weighted = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "        # Create PyTorch datasets\n",
        "        train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "        val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "        val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "        # Reset model to initial weights for fair comparison across splits\n",
        "        model.load_state_dict(initial_state)\n",
        "\n",
        "        # Define optimizer with L2 regularization\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
        "\n",
        "        # Enable mixed precision training for GPU acceleration\n",
        "        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "        # Create directory for model checkpoints\n",
        "        os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n",
        "\n",
        "        # Train model on current split with weighted loss\n",
        "        model, training_history = fit(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=epochs,\n",
        "            criterion=criterion_weighted,  # Use weighted criterion\n",
        "            optimizer=optimizer,\n",
        "            scaler=split_scaler,\n",
        "            device=device,\n",
        "            writer=writer,\n",
        "            patience=patience,\n",
        "            verbose=verbose,\n",
        "            l1_lambda=l1_lambda,\n",
        "            evaluation_metric=evaluation_metric,\n",
        "            mode=mode,\n",
        "            restore_best_weights=restore_best_weights,\n",
        "            experiment_name=experiment_name+\"/split_\"+str(split_idx)\n",
        "        )\n",
        "\n",
        "        # Store results for this split\n",
        "        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n",
        "        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n",
        "        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n",
        "\n",
        "    # Compute mean and standard deviation of best scores across splits\n",
        "    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
        "    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"Best score: {best_scores['mean']:.4f}±{best_scores['std']:.4f}\")\n",
        "\n",
        "    return fold_losses, fold_metrics, best_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4yt6vaquQQSV"
      },
      "outputs": [],
      "source": [
        "def grid_search_cv_rnn(df, param_grid, fixed_params, cv_params, verbose=True):\n",
        "    \"\"\"\n",
        "    Execute grid search with K-shuffle-split cross-validation for RNN models on time series data.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n",
        "        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32], 'rnn_type': ['LSTM', 'GRU']}\n",
        "        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, window_size, stride, etc.)\n",
        "        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n",
        "        verbose: Print progress for each configuration\n",
        "\n",
        "    Returns:\n",
        "        results: Dict with scores for each configuration\n",
        "        best_config: Dict with best hyperparameter combination\n",
        "        best_score: Best mean F1 score achieved\n",
        "    \"\"\"\n",
        "    # Generate all parameter combinations\n",
        "    param_names = list(param_grid.keys())\n",
        "    param_values = list(param_grid.values())\n",
        "    combinations = list(product(*param_values))\n",
        "\n",
        "    results = {}\n",
        "    best_score = -np.inf\n",
        "    best_config = None\n",
        "\n",
        "    total = len(combinations)\n",
        "\n",
        "    for idx, combo in enumerate(combinations, 1):\n",
        "        # Create current configuration dict\n",
        "        current_config = dict(zip(param_names, combo))\n",
        "        config_str = \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()])\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\nConfiguration {idx}/{total}:\")\n",
        "            for param, value in current_config.items():\n",
        "                print(f\"  {param}: {value}\")\n",
        "\n",
        "        # Merge current config with fixed parameters\n",
        "        run_params = {**fixed_params, **current_config}\n",
        "\n",
        "        # Execute cross-validation\n",
        "        _, _, fold_scores = k_shuffle_split_cross_validation_round_rnn(\n",
        "            df=df,\n",
        "            experiment_name=config_str,\n",
        "            **run_params,\n",
        "            **cv_params\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        results[config_str] = fold_scores\n",
        "\n",
        "        # Compute combined score: mean - std (risk-averse metric)\n",
        "        current_score = fold_scores[\"mean\"] - fold_scores[\"std\"]\n",
        "        # (optional, per salvare anche nel dict dei risultati)\n",
        "        fold_scores[\"mean_minus_std\"] = current_score\n",
        "\n",
        "        # Track best configuration using mean - std\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_config = current_config.copy()\n",
        "            if verbose:\n",
        "                print(f\"  NEW BEST SCORE! (mean - std = {current_score:.4f})\")\n",
        "\n",
        "        if verbose:\n",
        "            print(\n",
        "                f\"  F1 Score: {fold_scores['mean']:.4f}±{fold_scores['std']:.4f} \"\n",
        "                f\"(mean - std = {current_score:.4f})\"\n",
        "            )\n",
        "\n",
        "    return results, best_config, best_score\n",
        "\n",
        "\n",
        "def plot_top_configurations_rnn(results, k_splits, top_n=5, figsize=(14, 7)):\n",
        "    \"\"\"\n",
        "    Visualise top N RNN configurations with boxplots of F1 scores across CV splits.\n",
        "\n",
        "    Args:\n",
        "        results: Dict of results from grid_search_cv_rnn\n",
        "        k_splits: Number of CV splits used\n",
        "        top_n: Number of top configurations to display\n",
        "        figsize: Figure size tuple\n",
        "    \"\"\"\n",
        "    # Sort by mean score\n",
        "    config_scores = {name: data['mean'] for name, data in results.items()}\n",
        "    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select top N\n",
        "    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n",
        "\n",
        "    # Prepare boxplot data\n",
        "    boxplot_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Define a dictionary for replacements, ordered to handle prefixes correctly\n",
        "    replacements = {\n",
        "        'batch_size_': 'BS=',\n",
        "        'learning_rate_': '\\nLR=',\n",
        "        'hidden_layers_': '\\nHL=',\n",
        "        'hidden_size_': '\\nHS=',\n",
        "        'dropout_rate_': '\\nDR=',\n",
        "        'window_size_': '\\nWS=',\n",
        "        'stride_': '\\nSTR=',\n",
        "        'rnn_type_': '\\nRNN=',\n",
        "        'bidirectional_': '\\nBIDIR=',\n",
        "        'l1_lambda_': '\\nL1=',\n",
        "        'l2_lambda_': '\\nL2='\n",
        "    }\n",
        "\n",
        "    # Replacements for separators\n",
        "    separator_replacements = {\n",
        "        '_learning_rate_': '\\nLR=',\n",
        "        '_hidden_layers_': '\\nHL=',\n",
        "        '_hidden_size_': '\\nHS=',\n",
        "        '_dropout_rate_': '\\nDR=',\n",
        "        '_window_size_': '\\nWS=',\n",
        "        '_stride_': '\\nSTR=',\n",
        "        '_rnn_type_': '\\nRNN=',\n",
        "        '_bidirectional_': '\\nBIDIR=',\n",
        "        '_l1_lambda_': '\\nL1=',\n",
        "        '_l2_lambda_': '\\nL2=',\n",
        "        '_': ''\n",
        "    }\n",
        "\n",
        "    for config_name, mean_score in top_configs:\n",
        "        # Extract best score from each split (auto-detect number of splits)\n",
        "        split_scores = []\n",
        "        for i in range(k_splits):\n",
        "            if f'split_{i}' in results[config_name]:\n",
        "                split_scores.append(results[config_name][f'split_{i}'])\n",
        "        boxplot_data.append(split_scores)\n",
        "\n",
        "        # Verify we have the expected number of splits\n",
        "        if len(split_scores) != k_splits:\n",
        "            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n",
        "\n",
        "        # Create readable label using the replacements dictionary\n",
        "        readable_label = config_name\n",
        "        for old, new in replacements.items():\n",
        "            readable_label = readable_label.replace(old, new)\n",
        "\n",
        "        # Apply separator replacements\n",
        "        for old, new in separator_replacements.items():\n",
        "             readable_label = readable_label.replace(old, new)\n",
        "\n",
        "        labels.append(f\"{readable_label}\\n(μ={mean_score:.3f})\")\n",
        "\n",
        "    # Create plot\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n",
        "                    showmeans=True, meanline=True)\n",
        "\n",
        "    # Styling\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('lightblue')\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    # Highlight best configuration\n",
        "    ax.get_xticklabels()[0].set_fontweight('bold')\n",
        "\n",
        "    ax.set_ylabel('F1 Score')\n",
        "    ax.set_xlabel('Configuration')\n",
        "    ax.set_title(f'Top {len(top_configs)} RNN Configurations - F1 Score Distribution Across {k_splits} Splits')\n",
        "    ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "    plt.xticks(rotation=0, ha='center')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lhgn3M-iQQSW"
      },
      "outputs": [],
      "source": [
        "# Set up loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdF2fIryQQSW",
        "outputId": "d8f73898-786a-478e-a556-56db39c88f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Configuration 1/8:\n",
            "  n_val_users: 55\n",
            "  k: 5\n",
            "  epochs: 200\n",
            "  window_size: 24\n",
            "  stride: 4\n",
            "  hidden_layers: 2\n",
            "  hidden_size: 128\n",
            "  batch_size: 256\n",
            "  learning_rate: 0.001\n",
            "  dropout_rate: 0.3\n",
            "  l2_lambda: 0.0001\n",
            "Built 21210 sequences with 21210 labels\n",
            "Built 1925 sequences with 1925 labels\n",
            "Training 200 epochs...\n",
            "Grid search took 29.74s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     13\u001b[39m fixed_params = {\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33ml1_lambda\u001b[39m\u001b[33m'\u001b[39m: L1_LAMBDA,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrnn_type\u001b[39m\u001b[33m'\u001b[39m: RNN_TYPE,\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbidirectional\u001b[39m\u001b[33m'\u001b[39m: BIDIRECTIONAL,\n\u001b[32m     17\u001b[39m }\n\u001b[32m     18\u001b[39m cv_params = {\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m'\u001b[39m: criterion,\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m: device,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mwriter\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     28\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m results, best_config, best_score = \u001b[43mgrid_search_cv_rnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mgrid_search_cv_rnn\u001b[39m\u001b[34m(df, param_grid, fixed_params, cv_params, verbose)\u001b[39m\n\u001b[32m     39\u001b[39m run_params = {**fixed_params, **current_config}\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Execute cross-validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m _, _, fold_scores = \u001b[43mk_shuffle_split_cross_validation_round_rnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcv_params\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m     50\u001b[39m results[config_str] = fold_scores\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 155\u001b[39m, in \u001b[36mk_shuffle_split_cross_validation_round_rnn\u001b[39m\u001b[34m(df, epochs, criterion, device, k, n_val_users, batch_size, hidden_layers, hidden_size, learning_rate, dropout_rate, window_size, stride, rnn_type, bidirectional, l1_lambda, l2_lambda, patience, evaluation_metric, mode, restore_best_weights, writer, verbose, seed, experiment_name)\u001b[39m\n\u001b[32m    152\u001b[39m os.makedirs(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Train model on current split with weighted loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m model, training_history = \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion_weighted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use weighted criterion\u001b[39;49;00m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/split_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# Store results for this split\u001b[39;00m\n\u001b[32m    175\u001b[39m fold_losses[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msplit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = training_history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device, l1_lambda, l2_lambda, patience, evaluation_metric, mode, restore_best_weights, writer, verbose, experiment_name)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Main training loop: iterate through epochs\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m     46\u001b[39m \n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# Forward pass through training data, compute gradients, update weights\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     train_loss, train_f1 = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_lambda\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Evaluate model on validation data without updating weights\u001b[39;00m\n\u001b[32m     53\u001b[39m     val_loss, val_f1 = validate_one_epoch(\n\u001b[32m     54\u001b[39m         model, val_loader, criterion, device\n\u001b[32m     55\u001b[39m     )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda)\u001b[39m\n\u001b[32m     40\u001b[39m     loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Backward pass with gradient scaling\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m scaler.step(optimizer)\n\u001b[32m     46\u001b[39m scaler.update()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Polimi/ComputerScience/ANN/Challenges/ANN/.venv/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Polimi/ComputerScience/ANN/Challenges/ANN/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Polimi/ComputerScience/ANN/Challenges/ANN/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from time import perf_counter\n",
        "from contextlib import contextmanager\n",
        "\n",
        "@contextmanager\n",
        "def timing(label=\"Block\"):\n",
        "    t0 = perf_counter()\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        print(f\"{label} took {perf_counter() - t0:.2f}s\")\n",
        "\n",
        "with timing(\"Grid search\"):\n",
        "    fixed_params = {\n",
        "        'l1_lambda': L1_LAMBDA,\n",
        "        'rnn_type': RNN_TYPE,\n",
        "        'bidirectional': BIDIRECTIONAL,\n",
        "    }\n",
        "    cv_params = {\n",
        "        'criterion': criterion,\n",
        "        'device': device,\n",
        "        'patience': PATIENCE,\n",
        "        'verbose': 0,\n",
        "        'seed': SEED,\n",
        "        'evaluation_metric': 'val_f1',\n",
        "        'mode': 'max',\n",
        "        'restore_best_weights': True,\n",
        "        'writer': None,\n",
        "    }\n",
        "    results, best_config, best_score = grid_search_cv_rnn(\n",
        "        df=X_train,\n",
        "        param_grid=param_grid,\n",
        "        fixed_params=fixed_params,\n",
        "        cv_params=cv_params,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "705XWZjNQQSW",
        "outputId": "bfd7c05b-a055-4a39-8719-44099e6be2c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_top_configurations_rnn(results, k_splits=param_grid['k'][0], top_n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQkklZJpQQSb"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esv7nvO4QQSb",
        "outputId": "57041b5b-4e3a-4e66-dd53-73708b10ff66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS\n",
            "============================================================\n",
            "\n",
            "Best Configuration Found:\n",
            "  l1_lambda: 0\n",
            "  rnn_type: GRU\n",
            "  bidirectional: True\n",
            "  n_val_users: 55\n",
            "  k: 5\n",
            "  epochs: 200\n",
            "  window_size: 24\n",
            "  stride: 4\n",
            "  hidden_layers: 2\n",
            "  hidden_size: 128\n",
            "  batch_size: 256\n",
            "  learning_rate: 0.0008\n",
            "  dropout_rate: 0.3\n",
            "  l2_lambda: 0.0001\n",
            "\n",
            "Best CV F1 Score: 0.9225\n",
            "\n",
            "============================================================\n",
            "CREATING FINAL TRAIN/VAL SPLIT\n",
            "============================================================\n",
            "Training samples: 606 (96960 timesteps)\n",
            "Validation samples: 55 (8800 timesteps)\n",
            "Training data: 91.7% of total\n",
            "\n",
            "Building sequences...\n",
            "Built 21210 sequences with 21210 labels\n",
            "Built 1925 sequences with 1925 labels\n",
            "Training sequences: (21210, 24, 37)\n",
            "Validation sequences: (1925, 24, 37)\n",
            "\n",
            "Class distribution in final training set: [16275  3150  1785]\n",
            "Class weights: [0.4344086  2.24444444 3.96078431]\n",
            "\n",
            "============================================================\n",
            "INITIALIZING FINAL MODEL\n",
            "============================================================\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (GRU)                 [[-1, 24, 256], [4, -1, 128]] 424,704        \n",
            "classifier (Linear)       [-1, 3]                      771            \n",
            "===============================================================================\n",
            "Total params: 425,475\n",
            "Trainable params: 425,475\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "TRAINING FINAL MODEL\n",
            "============================================================\n",
            "Training for 200 epochs\n",
            "Training 200 epochs...\n",
            "Epoch   1/200 | Train: Loss=0.9863, F1 Score=0.6077 | Val: Loss=0.7848, F1 Score=0.8199\n",
            "Epoch  10/200 | Train: Loss=0.1948, F1 Score=0.9188 | Val: Loss=0.2474, F1 Score=0.9541\n",
            "Epoch  20/200 | Train: Loss=0.0804, F1 Score=0.9601 | Val: Loss=0.4762, F1 Score=0.8936\n",
            "Epoch  30/200 | Train: Loss=0.0669, F1 Score=0.9679 | Val: Loss=0.3975, F1 Score=0.9220\n",
            "Epoch  40/200 | Train: Loss=0.0343, F1 Score=0.9843 | Val: Loss=0.3488, F1 Score=0.9229\n",
            "Epoch  50/200 | Train: Loss=0.0249, F1 Score=0.9865 | Val: Loss=0.3236, F1 Score=0.9526\n",
            "Epoch  60/200 | Train: Loss=0.0301, F1 Score=0.9857 | Val: Loss=0.2329, F1 Score=0.9638\n",
            "Epoch  70/200 | Train: Loss=0.0235, F1 Score=0.9880 | Val: Loss=0.3337, F1 Score=0.9632\n",
            "Epoch  80/200 | Train: Loss=0.0220, F1 Score=0.9884 | Val: Loss=0.4023, F1 Score=0.9261\n",
            "Epoch  90/200 | Train: Loss=0.0054, F1 Score=0.9978 | Val: Loss=0.2843, F1 Score=0.9634\n",
            "Epoch 100/200 | Train: Loss=0.0087, F1 Score=0.9956 | Val: Loss=0.3031, F1 Score=0.9424\n",
            "Epoch 110/200 | Train: Loss=0.0629, F1 Score=0.9848 | Val: Loss=0.2984, F1 Score=0.9344\n",
            "Epoch 120/200 | Train: Loss=0.0230, F1 Score=0.9886 | Val: Loss=0.2626, F1 Score=0.9607\n",
            "Epoch 130/200 | Train: Loss=0.0433, F1 Score=0.9803 | Val: Loss=0.3606, F1 Score=0.9450\n",
            "Epoch 140/200 | Train: Loss=0.0047, F1 Score=0.9977 | Val: Loss=0.3084, F1 Score=0.9623\n",
            "Early stopping triggered after 142 epochs.\n",
            "Best model restored from epoch 102 with val_f1 0.9692\n",
            "\n",
            "✓ Final model trained!\n",
            "Best Validation F1: 0.9692\n",
            "CV F1 Score: 0.9225\n",
            "Improvement: +0.0467\n",
            "\n",
            "============================================================\n",
            "PREPARING TEST DATA\n",
            "============================================================\n",
            "Built 46340 sequences with 46340 labels\n",
            "Test sequences: (46340, 24, 37)\n",
            "\n",
            "============================================================\n",
            "MAKING PREDICTIONS\n",
            "============================================================\n",
            "Total window predictions: 46340\n",
            "\n",
            "Mapping 46340 windows to 1324 samples...\n",
            "\n",
            "============================================================\n",
            "PREDICTIONS SAVED\n",
            "============================================================\n",
            "Output file: pirate_pain_test_predictions.csv\n",
            "Total samples: 1324\n",
            "\n",
            "📊 Performance Comparison:\n",
            "  CV Mean F1: 0.9225\n",
            "  Final Model Val F1: 0.9692\n",
            "  Improvement: +0.0467 (+5.1%)\n",
            "\n",
            "📈 Prediction Distribution:\n",
            "predicted_label\n",
            "no_pain      1018\n",
            "low_pain      181\n",
            "high_pain     125\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentages:\n",
            "  no_pain: 1018 (76.9%)\n",
            "  low_pain: 181 (13.7%)\n",
            "  high_pain: 125 (9.4%)\n",
            "\n",
            "🔍 First 10 predictions:\n",
            "   sample_index  predicted_label_id predicted_label\n",
            "0             0                   0         no_pain\n",
            "1             1                   0         no_pain\n",
            "2             2                   0         no_pain\n",
            "3             3                   0         no_pain\n",
            "4             4                   0         no_pain\n",
            "5             5                   0         no_pain\n",
            "6             6                   0         no_pain\n",
            "7             7                   0         no_pain\n",
            "8             8                   0         no_pain\n",
            "9             9                   0         no_pain\n"
          ]
        }
      ],
      "source": [
        "# filepath: /home/federico/Desktop/ANN/grid_search.ipynb\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: PREPARE FINAL TRAINING\n",
        "# ========================================\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING FINAL MODEL WITH BEST HYPERPARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Merge best config with fixed params\n",
        "final_best_params = {**fixed_params, **best_config}\n",
        "print(\"\\nBest Configuration Found:\")\n",
        "for key, value in final_best_params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(f\"\\nBest CV F1 Score: {best_score:.4f}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 2: CREATE FINAL TRAIN/VAL SPLIT\n",
        "# (Use minimal validation set, maximize training data)\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING FINAL TRAIN/VAL SPLIT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Use MINIMAL validation set (e.g., 10% of n_val_users from grid search)\n",
        "# This maximizes training data while keeping a small val set for early stopping\n",
        "unique_samples = X_train['sample_index'].unique()\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "np.random.shuffle(unique_samples)\n",
        "\n",
        "# Use smaller validation set than CV (e.g., 20-30 samples instead of 45)\n",
        "n_val_users_final = max(20, int(final_best_params['n_val_users']))  # Half of CV val size\n",
        "n_train_samples = len(unique_samples) - n_val_users_final\n",
        "\n",
        "train_samples = unique_samples[:n_train_samples]\n",
        "val_samples = unique_samples[n_train_samples:]\n",
        "\n",
        "df_train_final = X_train[X_train['sample_index'].isin(train_samples)].copy()\n",
        "df_val_final = X_train[X_train['sample_index'].isin(val_samples)].copy()\n",
        "\n",
        "print(f\"Training samples: {len(train_samples)} ({df_train_final.shape[0]} timesteps)\")\n",
        "print(f\"Validation samples: {len(val_samples)} ({df_val_final.shape[0]} timesteps)\")\n",
        "print(f\"Training data: {len(train_samples)/(len(train_samples)+len(val_samples))*100:.1f}% of total\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 3: PREPROCESS DATA\n",
        "# ========================================\n",
        "# Map labels (if needed)\n",
        "if df_train_final['label'].dtype == 'object':\n",
        "    df_train_final['label'] = df_train_final['label'].map(pain_mapping)\n",
        "    df_val_final['label'] = df_val_final['label'].map(pain_mapping)\n",
        "\n",
        "# Normalize features\n",
        "pain_survey_columns = ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', 'n_legs', 'n_hands', 'n_eyes']\n",
        "joint_columns = [f'joint_{i:02d}' for i in range(30)]\n",
        "scale_columns = pain_survey_columns + joint_columns\n",
        "\n",
        "train_max = df_train_final[scale_columns].max()\n",
        "train_min = df_train_final[scale_columns].min()\n",
        "\n",
        "for column in scale_columns:\n",
        "    df_train_final[column] = (df_train_final[column] - train_min[column]) / (train_max[column] - train_min[column] + 1e-8)\n",
        "    df_val_final[column] = (df_val_final[column] - train_min[column]) / (train_max[column] - train_min[column] + 1e-8)\n",
        "\n",
        "# Build sequences\n",
        "print(\"\\nBuilding sequences...\")\n",
        "X_train_final, y_train_final = build_sequences(\n",
        "    df_train_final,\n",
        "    window=final_best_params['window_size'],\n",
        "    stride=final_best_params['stride']\n",
        ")\n",
        "X_val_final, y_val_final = build_sequences(\n",
        "    df_val_final,\n",
        "    window=final_best_params['window_size'],\n",
        "    stride=final_best_params['stride']\n",
        ")\n",
        "\n",
        "print(f\"Training sequences: {X_train_final.shape}\")\n",
        "print(f\"Validation sequences: {X_val_final.shape}\")\n",
        "\n",
        "# Calculate class weights for final training to handle imbalance\n",
        "class_counts_final = np.bincount(y_train_final)\n",
        "total_samples_final = len(y_train_final)\n",
        "class_weights_final = total_samples_final / (num_classes * class_counts_final)\n",
        "class_weights_tensor_final = torch.FloatTensor(class_weights_final).to(device)\n",
        "\n",
        "print(f\"\\nClass distribution in final training set: {class_counts_final}\")\n",
        "print(f\"Class weights: {class_weights_final}\")\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_ds_final = TensorDataset(\n",
        "    torch.from_numpy(X_train_final.astype(np.float32)),\n",
        "    torch.from_numpy(y_train_final.astype(np.int64))\n",
        ")\n",
        "val_ds_final = TensorDataset(\n",
        "    torch.from_numpy(X_val_final.astype(np.float32)),\n",
        "    torch.from_numpy(y_val_final.astype(np.int64))\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader_final = make_loader(\n",
        "    train_ds_final,\n",
        "    batch_size=final_best_params['batch_size'],\n",
        "    shuffle=True,\n",
        "    drop_last=False\n",
        ")\n",
        "val_loader_final = make_loader(\n",
        "    val_ds_final,\n",
        "    batch_size=final_best_params['batch_size'],\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# ========================================\n",
        "# STEP 4: INITIALIZE FINAL MODEL\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INITIALIZING FINAL MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_model = RecurrentClassifier(\n",
        "    input_size=X_train_final.shape[2],\n",
        "    hidden_size=final_best_params['hidden_size'],\n",
        "    num_layers=final_best_params['hidden_layers'],\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=final_best_params['dropout_rate'],\n",
        "    bidirectional=final_best_params['bidirectional'],\n",
        "    rnn_type=final_best_params['rnn_type']\n",
        ").to(device)\n",
        "\n",
        "recurrent_summary(final_model, input_size=(final_best_params['window_size'], X_train_final.shape[2]))\n",
        "\n",
        "# ========================================\n",
        "# STEP 5: TRAIN FINAL MODEL\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING FINAL MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "optimizer_final = torch.optim.AdamW(\n",
        "    final_model.parameters(),\n",
        "    lr=final_best_params['learning_rate'],\n",
        "    weight_decay=final_best_params['l2_lambda']\n",
        ")\n",
        "scaler_final = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "# Create directory for final model\n",
        "os.makedirs(\"models/final_model\", exist_ok=True)\n",
        "\n",
        "# Create weighted loss function for final training\n",
        "criterion_final = nn.CrossEntropyLoss(weight=class_weights_tensor_final)\n",
        "\n",
        "# Train with MORE epochs than CV (since we have more data)\n",
        "final_epochs = int(final_best_params['epochs'])  # 1.5x more epochs\n",
        "final_patience = PATIENCE\n",
        "print(f\"Training for {final_epochs} epochs\")\n",
        "\n",
        "final_model, training_history = fit(\n",
        "    model=final_model,\n",
        "    train_loader=train_loader_final,\n",
        "    val_loader=val_loader_final,\n",
        "    epochs=final_epochs,\n",
        "    criterion=criterion_final,  # Use weighted criterion\n",
        "    optimizer=optimizer_final,\n",
        "    scaler=scaler_final,\n",
        "    device=device,\n",
        "    l1_lambda=final_best_params['l1_lambda'],\n",
        "    l2_lambda=0,  # Already in optimizer weight_decay\n",
        "    patience=final_patience,\n",
        "    evaluation_metric=\"val_f1\",\n",
        "    mode='max',\n",
        "    restore_best_weights=True,\n",
        "    writer=None,\n",
        "    verbose=VERBOSE,\n",
        "    experiment_name=\"final_model/best\"\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Final model trained!\")\n",
        "print(f\"Best Validation F1: {max(training_history['val_f1']):.4f}\")\n",
        "print(f\"CV F1 Score: {best_score:.4f}\")\n",
        "print(f\"Improvement: {max(training_history['val_f1']) - best_score:+.4f}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 6: LOAD TEST DATA\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPARING TEST DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_test = pd.read_csv('datat/pirate_pain_test.csv')\n",
        "\n",
        "# Drop joint_30\n",
        "if 'joint_30' in X_test.columns:\n",
        "    X_test.drop('joint_30', axis=1, inplace=True)\n",
        "\n",
        "# Convert categorical to binary\n",
        "binary_cols = ['n_hands', 'n_eyes', 'n_legs']\n",
        "for col in binary_cols:\n",
        "    X_test[col] = X_test[col].map(lambda x: 1 if str(x).lower().strip() == 'two' else 0)\n",
        "\n",
        "df_test_original = X_test.copy()\n",
        "df_test_processed = X_test.copy()\n",
        "\n",
        "# Normalize test data using TRAINING statistics (from final training set)\n",
        "for column in scale_columns:\n",
        "    df_test_processed[column] = (df_test_processed[column] - train_min[column]) / (train_max[column] - train_min[column] + 1e-8)\n",
        "\n",
        "# Build test sequences\n",
        "df_test_processed['label'] = 0  # Dummy label\n",
        "X_test_sequences, _ = build_sequences(\n",
        "    df_test_processed,\n",
        "    window=final_best_params['window_size'],\n",
        "    stride=final_best_params['stride']\n",
        ")\n",
        "\n",
        "print(f\"Test sequences: {X_test_sequences.shape}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 7: MAKE PREDICTIONS\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MAKING PREDICTIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load the best model weights\n",
        "final_model.load_state_dict(torch.load(\"models/final_model/best_model.pt\", map_location=device))\n",
        "final_model.eval()\n",
        "\n",
        "# Create test loader\n",
        "test_ds = TensorDataset(torch.from_numpy(X_test_sequences.astype(np.float32)))\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=final_best_params['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Get predictions\n",
        "all_predictions = []\n",
        "with torch.no_grad():\n",
        "    for (xb,) in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        logits = final_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        all_predictions.append(preds)\n",
        "\n",
        "all_predictions = np.concatenate(all_predictions)\n",
        "print(f\"Total window predictions: {len(all_predictions)}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 8: MAP PREDICTIONS TO SAMPLES  (coerente con build_sequences)\n",
        "# ========================================\n",
        "sample_predictions = []\n",
        "pred_idx = 0\n",
        "\n",
        "unique_samples = df_test_processed['sample_index'].unique()\n",
        "window = final_best_params['window_size']\n",
        "stride = final_best_params['stride']\n",
        "\n",
        "def n_windows_like_training(n_timestamps: int, window: int, stride: int) -> int:\n",
        "    \"\"\"Conta le finestre esattamente come in build_sequences:\n",
        "       - se L < window: 1 finestra (padding solo fino a window)\n",
        "       - altrimenti sliding con stride\n",
        "       - ancora l’ultima finestra alla fine se non già inclusa\n",
        "    \"\"\"\n",
        "    L = n_timestamps\n",
        "    if L <= 0:\n",
        "        return 0\n",
        "    if L < window:\n",
        "        return 1\n",
        "\n",
        "    starts = list(range(0, max(L - window, 0) + 1, stride))\n",
        "    last_start = L - window\n",
        "    if last_start >= 0 and (len(starts) == 0 or starts[-1] != last_start):\n",
        "        starts.append(last_start)\n",
        "    return len(starts)\n",
        "\n",
        "print(f\"\\nMapping {len(all_predictions)} windows to {len(unique_samples)} samples...\")\n",
        "\n",
        "for sample_id in unique_samples:\n",
        "    L = (df_test_processed['sample_index'] == sample_id).sum()\n",
        "    n_windows = n_windows_like_training(L, window, stride)\n",
        "\n",
        "    end_idx = min(pred_idx + n_windows, len(all_predictions))\n",
        "    sample_window_predictions = all_predictions[pred_idx:end_idx]\n",
        "\n",
        "    if sample_window_predictions.size > 0:\n",
        "        final_prediction = np.bincount(sample_window_predictions).argmax()\n",
        "    else:\n",
        "        final_prediction = 0  # fallback prudente\n",
        "\n",
        "    sample_predictions.append({\n",
        "        'sample_index': sample_id,\n",
        "        'predicted_label_id': final_prediction,\n",
        "        'predicted_label': label_reverse_mapping[final_prediction]\n",
        "    })\n",
        "\n",
        "    pred_idx = end_idx\n",
        "\n",
        "# sicurezza: deve consumare tutte le finestre\n",
        "assert pred_idx == len(all_predictions), \\\n",
        "    f\"Consumed {pred_idx} preds but have {len(all_predictions)}\"\n",
        "# ========================================\n",
        "# STEP 9: SAVE RESULTS\n",
        "# ========================================\n",
        "predictions_df = pd.DataFrame(sample_predictions)\n",
        "\n",
        "output_df = df_test_original[['sample_index']].drop_duplicates().merge(\n",
        "    predictions_df,\n",
        "    on='sample_index',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Handle missing predictions\n",
        "if output_df['predicted_label'].isna().any():\n",
        "    print(f\"WARNING: {output_df['predicted_label'].isna().sum()} samples missing predictions\")\n",
        "    output_df['predicted_label'].fillna('no_pain', inplace=True)\n",
        "\n",
        "# Save CSV\n",
        "output_filename = 'pirate_pain_test_predictions.csv'\n",
        "output_df[['sample_index', 'predicted_label']].to_csv(output_filename, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREDICTIONS SAVED\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Output file: {output_filename}\")\n",
        "print(f\"Total samples: {len(output_df)}\")\n",
        "print(f\"\\n📊 Performance Comparison:\")\n",
        "print(f\"  CV Mean F1: {best_score:.4f}\")\n",
        "print(f\"  Final Model Val F1: {max(training_history['val_f1']):.4f}\")\n",
        "print(f\"  Improvement: {max(training_history['val_f1']) - best_score:+.4f} ({((max(training_history['val_f1'])/best_score - 1)*100):+.1f}%)\")\n",
        "\n",
        "print(\"\\n📈 Prediction Distribution:\")\n",
        "print(output_df['predicted_label'].value_counts())\n",
        "print(\"\\nPercentages:\")\n",
        "for pain_level in ['no_pain', 'low_pain', 'high_pain']:\n",
        "    count = (output_df['predicted_label'] == pain_level).sum()\n",
        "    percentage = (count / len(output_df)) * 100\n",
        "    print(f\"  {pain_level}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\n🔍 First 10 predictions:\")\n",
        "print(output_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-KsexxeUae42",
        "outputId": "b73c5865-94ca-44df-c358-1ff36f56b314"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_03391724-6f4a-497d-a436-4d3baea64860\", \"models.zip\", 64826704)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_path = shutil.make_archive('/content/models', 'zip', '/content', 'models')\n",
        "files.download(zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30ZrMlvpQQSc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
