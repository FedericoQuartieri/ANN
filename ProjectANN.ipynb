{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "current_dir = \"/gdrive/My\\\\ Drive/Gesù/\"\n",
        "%cd $current_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDFhrqIp_7Ov",
        "outputId": "8265cea2-c676-4753-a51d-4211f85ca5c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/Gesù\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8mDbjnp9Xtc",
        "outputId": "9abe7d1e-1001-498e-d086-70929992e96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "[build_sequences] Target T=180 -> ok:0  padded:661  truncated:0\n",
            "[build_sequences] Target T=180 -> ok:0  padded:1324  truncated:0\n",
            "Train sequences: 661  Test sequences: 1324\n",
            "Dynamic channels: 105  Static dims: 3  Classes: ['high_pain', 'low_pain', 'no_pain']\n",
            "\n",
            "========== FOLD 1/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        12\n",
            "    low_pain      0.000     0.000     0.000        18\n",
            "     no_pain      0.774     1.000     0.873       103\n",
            "\n",
            "    accuracy                          0.774       133\n",
            "   macro avg      0.258     0.333     0.291       133\n",
            "weighted avg      0.600     0.774     0.676       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[  0   0  12]\n",
            " [  0   0  18]\n",
            " [  0   0 103]]\n",
            "Epoch 01: train loss 1.9812 f1 0.1791 acc 0.3674 | val loss 1.4339 f1 0.2910 acc 0.7744\n",
            "Epoch 02: train loss 1.7617 f1 0.1791 acc 0.3674 | val loss 1.3110 f1 0.2910 acc 0.7744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      1.000     0.083     0.154        12\n",
            "    low_pain      0.000     0.000     0.000        18\n",
            "     no_pain      0.780     1.000     0.877       103\n",
            "\n",
            "    accuracy                          0.782       133\n",
            "   macro avg      0.593     0.361     0.343       133\n",
            "weighted avg      0.695     0.782     0.693       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[  1   0  11]\n",
            " [  0   0  18]\n",
            " [  0   0 103]]\n",
            "Epoch 03: train loss 1.5212 f1 0.1667 acc 0.3220 | val loss 1.1591 f1 0.3435 acc 0.7820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.214     0.500     0.300        12\n",
            "    low_pain      0.000     0.000     0.000        18\n",
            "     no_pain      0.829     0.845     0.837       103\n",
            "\n",
            "    accuracy                          0.699       133\n",
            "   macro avg      0.348     0.448     0.379       133\n",
            "weighted avg      0.661     0.699     0.675       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  0  6]\n",
            " [ 6  0 12]\n",
            " [16  0 87]]\n",
            "Epoch 04: train loss 1.2109 f1 0.3079 acc 0.4167 | val loss 1.0353 f1 0.3788 acc 0.6992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.098     1.000     0.178        12\n",
            "    low_pain      0.000     0.000     0.000        18\n",
            "     no_pain      1.000     0.097     0.177       103\n",
            "\n",
            "    accuracy                          0.165       133\n",
            "   macro avg      0.366     0.366     0.118       133\n",
            "weighted avg      0.783     0.165     0.153       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[12  0  0]\n",
            " [18  0  0]\n",
            " [93  0 10]]\n",
            "Epoch 05: train loss 0.9377 f1 0.2986 acc 0.3864 | val loss 1.1070 f1 0.1183 acc 0.1654\n",
            "Epoch 06: train loss 0.8305 f1 0.1970 acc 0.3295 | val loss 1.3362 f1 0.0615 acc 0.0902\n",
            "Epoch 07: train loss 0.7557 f1 0.2634 acc 0.3769 | val loss 1.4365 f1 0.1798 acc 0.1654\n",
            "Epoch 08: train loss 0.6636 f1 0.4229 acc 0.5284 | val loss 1.3318 f1 0.2090 acc 0.1955\n",
            "Epoch 09: train loss 0.5833 f1 0.4701 acc 0.5663 | val loss 1.1624 f1 0.2204 acc 0.2030\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.196     0.917     0.324        12\n",
            "    low_pain      0.160     0.667     0.258        18\n",
            "     no_pain      1.000     0.019     0.038       103\n",
            "\n",
            "    accuracy                          0.188       133\n",
            "   macro avg      0.452     0.534     0.207       133\n",
            "weighted avg      0.814     0.188     0.094       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[11  1  0]\n",
            " [ 6 12  0]\n",
            " [39 62  2]]\n",
            "Epoch 10: train loss 0.4713 f1 0.4452 acc 0.5549 | val loss 1.3007 f1 0.2066 acc 0.1880\n",
            "Epoch 11: train loss 0.3700 f1 0.4943 acc 0.6136 | val loss 1.2134 f1 0.2027 acc 0.1880\n",
            "Epoch 12: train loss 0.3250 f1 0.5170 acc 0.6117 | val loss 1.2043 f1 0.2336 acc 0.2180\n",
            "Epoch 13: train loss 0.2570 f1 0.6183 acc 0.6875 | val loss 1.2309 f1 0.3105 acc 0.3083\n",
            "Epoch 14: train loss 0.2320 f1 0.6527 acc 0.7045 | val loss 1.2601 f1 0.3752 acc 0.3835\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 2/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.773     1.000     0.872       102\n",
            "\n",
            "    accuracy                          0.773       132\n",
            "   macro avg      0.258     0.333     0.291       132\n",
            "weighted avg      0.597     0.773     0.674       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  0   0  11]\n",
            " [  0   0  19]\n",
            " [  0   0 102]]\n",
            "Epoch 01: train loss 2.0783 f1 0.1600 acc 0.3157 | val loss 1.4544 f1 0.2906 acc 0.7727\n",
            "Epoch 02: train loss 1.8520 f1 0.1762 acc 0.3592 | val loss 1.3411 f1 0.2906 acc 0.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      1.000     0.105     0.190        19\n",
            "     no_pain      0.785     1.000     0.879       102\n",
            "\n",
            "    accuracy                          0.788       132\n",
            "   macro avg      0.595     0.368     0.357       132\n",
            "weighted avg      0.750     0.788     0.707       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  0   0  11]\n",
            " [  0   2  17]\n",
            " [  0   0 102]]\n",
            "Epoch 03: train loss 1.6550 f1 0.1709 acc 0.3346 | val loss 1.2149 f1 0.3566 acc 0.7879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      0.348     0.421     0.381        19\n",
            "     no_pain      0.817     0.873     0.844       102\n",
            "\n",
            "    accuracy                          0.735       132\n",
            "   macro avg      0.388     0.431     0.408       132\n",
            "weighted avg      0.681     0.735     0.707       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 0  2  9]\n",
            " [ 0  8 11]\n",
            " [ 0 13 89]]\n",
            "Epoch 04: train loss 1.3590 f1 0.2953 acc 0.4253 | val loss 1.0851 f1 0.4082 acc 0.7348\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.200     0.182     0.190        11\n",
            "    low_pain      0.111     0.684     0.191        19\n",
            "     no_pain      1.000     0.049     0.093       102\n",
            "\n",
            "    accuracy                          0.152       132\n",
            "   macro avg      0.437     0.305     0.158       132\n",
            "weighted avg      0.805     0.152     0.116       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 2  9  0]\n",
            " [ 6 13  0]\n",
            " [ 2 95  5]]\n",
            "Epoch 05: train loss 1.0990 f1 0.3481 acc 0.4197 | val loss 1.0674 f1 0.1584 acc 0.1515\n",
            "Epoch 06: train loss 0.8437 f1 0.3019 acc 0.3819 | val loss 1.3569 f1 0.0560 acc 0.0833\n",
            "Epoch 07: train loss 0.7524 f1 0.3073 acc 0.4121 | val loss 1.5524 f1 0.1101 acc 0.1061\n",
            "Epoch 08: train loss 0.6147 f1 0.4323 acc 0.5501 | val loss 1.3869 f1 0.1342 acc 0.1288\n",
            "Epoch 09: train loss 0.5661 f1 0.4506 acc 0.5425 | val loss 1.1320 f1 0.2017 acc 0.1894\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.191     0.818     0.310        11\n",
            "    low_pain      0.165     0.684     0.265        19\n",
            "     no_pain      1.000     0.059     0.111       102\n",
            "\n",
            "    accuracy                          0.212       132\n",
            "   macro avg      0.452     0.520     0.229       132\n",
            "weighted avg      0.812     0.212     0.150       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  0]\n",
            " [ 6 13  0]\n",
            " [32 64  6]]\n",
            "Epoch 10: train loss 0.4167 f1 0.5055 acc 0.6314 | val loss 1.0785 f1 0.2289 acc 0.2121\n",
            "Epoch 11: train loss 0.4297 f1 0.4848 acc 0.5803 | val loss 1.0528 f1 0.2755 acc 0.2576\n",
            "Epoch 12: train loss 0.2830 f1 0.5724 acc 0.6730 | val loss 1.2803 f1 0.3022 acc 0.3106\n",
            "Epoch 13: train loss 0.2189 f1 0.6122 acc 0.6994 | val loss 1.3832 f1 0.3344 acc 0.3561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.205     0.727     0.320        11\n",
            "    low_pain      0.283     0.684     0.400        19\n",
            "     no_pain      0.957     0.441     0.604       102\n",
            "\n",
            "    accuracy                          0.500       132\n",
            "   macro avg      0.482     0.618     0.441       132\n",
            "weighted avg      0.798     0.500     0.551       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 4 13  2]\n",
            " [27 30 45]]\n",
            "Epoch 14: train loss 0.1682 f1 0.6704 acc 0.7410 | val loss 1.2368 f1 0.4413 acc 0.5000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.308     0.727     0.432        11\n",
            "    low_pain      0.357     0.789     0.492        19\n",
            "     no_pain      0.984     0.618     0.759       102\n",
            "\n",
            "    accuracy                          0.652       132\n",
            "   macro avg      0.550     0.711     0.561       132\n",
            "weighted avg      0.838     0.652     0.693       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 3 15  1]\n",
            " [15 24 63]]\n",
            "Epoch 15: train loss 0.1259 f1 0.7518 acc 0.7864 | val loss 1.2567 f1 0.5611 acc 0.6515\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.258     0.727     0.381        11\n",
            "    low_pain      0.464     0.684     0.553        19\n",
            "     no_pain      0.973     0.696     0.811       102\n",
            "\n",
            "    accuracy                          0.697       132\n",
            "   macro avg      0.565     0.703     0.582       132\n",
            "weighted avg      0.840     0.697     0.738       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  1]\n",
            " [ 5 13  1]\n",
            " [18 13 71]]\n",
            "Epoch 16: train loss 0.1095 f1 0.8607 acc 0.8696 | val loss 1.2297 f1 0.5819 acc 0.6970\n",
            "Epoch 17: train loss 0.1332 f1 0.9030 acc 0.9036 | val loss 1.6358 f1 0.5367 acc 0.6515\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.308     0.727     0.432        11\n",
            "    low_pain      0.609     0.737     0.667        19\n",
            "     no_pain      0.952     0.775     0.854       102\n",
            "\n",
            "    accuracy                          0.765       132\n",
            "   macro avg      0.623     0.746     0.651       132\n",
            "weighted avg      0.849     0.765     0.792       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 1 14  4]\n",
            " [17  6 79]]\n",
            "Epoch 18: train loss 0.1407 f1 0.8995 acc 0.8998 | val loss 1.0750 f1 0.6511 acc 0.7652\n",
            "Epoch 19: train loss 0.1523 f1 0.8832 acc 0.8904 | val loss 1.6799 f1 0.6023 acc 0.7576\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.600     0.545     0.571        11\n",
            "    low_pain      0.500     0.947     0.655        19\n",
            "     no_pain      0.965     0.814     0.883       102\n",
            "\n",
            "    accuracy                          0.811       132\n",
            "   macro avg      0.688     0.769     0.703       132\n",
            "weighted avg      0.868     0.811     0.824       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  3  2]\n",
            " [ 0 18  1]\n",
            " [ 4 15 83]]\n",
            "Epoch 20: train loss 0.0906 f1 0.9252 acc 0.9263 | val loss 1.2962 f1 0.7030 acc 0.8106\n",
            "Epoch 21: train loss 0.1554 f1 0.9066 acc 0.9093 | val loss 1.3903 f1 0.6009 acc 0.7424\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.545     0.545     0.545        11\n",
            "    low_pain      0.615     0.842     0.711        19\n",
            "     no_pain      0.947     0.882     0.914       102\n",
            "\n",
            "    accuracy                          0.848       132\n",
            "   macro avg      0.703     0.757     0.723       132\n",
            "weighted avg      0.866     0.848     0.854       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  3  2]\n",
            " [ 0 16  3]\n",
            " [ 5  7 90]]\n",
            "Epoch 22: train loss 0.1269 f1 0.9252 acc 0.9263 | val loss 0.9777 f1 0.7234 acc 0.8485\n",
            "Epoch 23: train loss 0.0934 f1 0.9309 acc 0.9319 | val loss 1.6463 f1 0.5235 acc 0.6364\n",
            "Epoch 24: train loss 0.0970 f1 0.9025 acc 0.9055 | val loss 1.3881 f1 0.5901 acc 0.7803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.350     0.636     0.452        11\n",
            "    low_pain      0.481     0.684     0.565        19\n",
            "     no_pain      0.976     0.814     0.888       102\n",
            "\n",
            "    accuracy                          0.780       132\n",
            "   macro avg      0.603     0.711     0.635       132\n",
            "weighted avg      0.853     0.780     0.805       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  3  1]\n",
            " [ 5 13  1]\n",
            " [ 8 11 83]]\n",
            "Epoch 25: train loss 0.0740 f1 0.9555 acc 0.9565 | val loss 0.9802 f1 0.6348 acc 0.7803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.615     0.727     0.667        11\n",
            "    low_pain      0.667     0.842     0.744        19\n",
            "     no_pain      0.979     0.912     0.944       102\n",
            "\n",
            "    accuracy                          0.886       132\n",
            "   macro avg      0.754     0.827     0.785       132\n",
            "weighted avg      0.904     0.886     0.892       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 1 16  2]\n",
            " [ 4  5 93]]\n",
            "Epoch 26: train loss 0.0474 f1 0.9458 acc 0.9471 | val loss 0.9666 f1 0.7850 acc 0.8864\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.583     0.636     0.609        11\n",
            "    low_pain      0.762     0.842     0.800        19\n",
            "     no_pain      0.980     0.951     0.965       102\n",
            "\n",
            "    accuracy                          0.909       132\n",
            "   macro avg      0.775     0.810     0.791       132\n",
            "weighted avg      0.915     0.909     0.912       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  3  1]\n",
            " [ 2 16  1]\n",
            " [ 3  2 97]]\n",
            "Epoch 27: train loss 0.0419 f1 0.9625 acc 0.9622 | val loss 1.0862 f1 0.7913 acc 0.9091\n",
            "Epoch 28: train loss 0.0259 f1 0.9787 acc 0.9792 | val loss 1.3031 f1 0.7482 acc 0.8712\n",
            "Epoch 29: train loss 0.0523 f1 0.9534 acc 0.9527 | val loss 1.2747 f1 0.7484 acc 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.353     0.545     0.429        11\n",
            "    low_pain      0.526     0.526     0.526        19\n",
            "     no_pain      0.948     0.892     0.919       102\n",
            "\n",
            "    accuracy                          0.811       132\n",
            "   macro avg      0.609     0.655     0.625       132\n",
            "weighted avg      0.838     0.811     0.822       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  2  3]\n",
            " [ 7 10  2]\n",
            " [ 4  7 91]]\n",
            "Epoch 30: train loss 0.0295 f1 0.9710 acc 0.9716 | val loss 1.6295 f1 0.6247 acc 0.8106\n",
            "Epoch 31: train loss 0.0252 f1 0.9808 acc 0.9811 | val loss 1.3986 f1 0.7141 acc 0.8485\n",
            "Epoch 32: train loss 0.0170 f1 0.9753 acc 0.9754 | val loss 1.5163 f1 0.7173 acc 0.8712\n",
            "Epoch 33: train loss 0.0195 f1 0.9847 acc 0.9849 | val loss 1.5776 f1 0.7652 acc 0.9015\n",
            "Epoch 34: train loss 0.0147 f1 0.9807 acc 0.9811 | val loss 1.5988 f1 0.7751 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.636     0.560        11\n",
            "    low_pain      0.696     0.842     0.762        19\n",
            "     no_pain      0.979     0.912     0.944       102\n",
            "\n",
            "    accuracy                          0.879       132\n",
            "   macro avg      0.725     0.797     0.755       132\n",
            "weighted avg      0.898     0.879     0.886       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  3  1]\n",
            " [ 2 16  1]\n",
            " [ 5  4 93]]\n",
            "Epoch 35: train loss 0.0166 f1 0.9925 acc 0.9924 | val loss 1.3142 f1 0.7554 acc 0.8788\n",
            "Epoch 36: train loss 0.0196 f1 0.9752 acc 0.9754 | val loss 1.7227 f1 0.7017 acc 0.8712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.750     0.545     0.632        11\n",
            "    low_pain      0.762     0.842     0.800        19\n",
            "     no_pain      0.961     0.971     0.966       102\n",
            "\n",
            "    accuracy                          0.917       132\n",
            "   macro avg      0.824     0.786     0.799       132\n",
            "weighted avg      0.915     0.917     0.914       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  3  2]\n",
            " [ 1 16  2]\n",
            " [ 1  2 99]]\n",
            "Epoch 37: train loss 0.0206 f1 0.9808 acc 0.9811 | val loss 1.3468 f1 0.7991 acc 0.9167\n",
            "Epoch 38: train loss 0.0193 f1 0.9811 acc 0.9811 | val loss 1.6519 f1 0.6397 acc 0.8561\n",
            "Epoch 39: train loss 0.0246 f1 0.9825 acc 0.9830 | val loss 1.3692 f1 0.6952 acc 0.8561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.385     0.455     0.417        11\n",
            "    low_pain      0.667     0.632     0.649        19\n",
            "     no_pain      0.950     0.941     0.946       102\n",
            "\n",
            "    accuracy                          0.856       132\n",
            "   macro avg      0.667     0.676     0.670       132\n",
            "weighted avg      0.862     0.856     0.859       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 6 12  1]\n",
            " [ 2  4 96]]\n",
            "Epoch 40: train loss 0.0083 f1 0.9905 acc 0.9905 | val loss 1.6338 f1 0.6704 acc 0.8561\n",
            "Epoch 41: train loss 0.0165 f1 0.9910 acc 0.9905 | val loss 1.6923 f1 0.6852 acc 0.8561\n",
            "Epoch 42: train loss 0.0059 f1 0.9942 acc 0.9943 | val loss 1.5384 f1 0.6517 acc 0.8485\n",
            "Epoch 43: train loss 0.0205 f1 0.9776 acc 0.9773 | val loss 1.7489 f1 0.7226 acc 0.8864\n",
            "Epoch 44: train loss 0.0239 f1 0.9866 acc 0.9868 | val loss 1.8025 f1 0.7464 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.455     0.455     0.455        11\n",
            "    low_pain      0.737     0.737     0.737        19\n",
            "     no_pain      0.941     0.941     0.941       102\n",
            "\n",
            "    accuracy                          0.871       132\n",
            "   macro avg      0.711     0.711     0.711       132\n",
            "weighted avg      0.871     0.871     0.871       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 3 14  2]\n",
            " [ 3  3 96]]\n",
            "Epoch 45: train loss 0.0109 f1 0.9961 acc 0.9962 | val loss 1.6051 f1 0.7109 acc 0.8712\n",
            "Epoch 46: train loss 0.0099 f1 0.9866 acc 0.9868 | val loss 1.7678 f1 0.7118 acc 0.8712\n",
            "Epoch 47: train loss 0.0202 f1 0.9757 acc 0.9754 | val loss 1.8909 f1 0.7345 acc 0.8864\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 3/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.773     1.000     0.872       102\n",
            "\n",
            "    accuracy                          0.773       132\n",
            "   macro avg      0.258     0.333     0.291       132\n",
            "weighted avg      0.597     0.773     0.674       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  0   0  11]\n",
            " [  0   0  19]\n",
            " [  0   0 102]]\n",
            "Epoch 01: train loss 1.9607 f1 0.1775 acc 0.3629 | val loss 1.3903 f1 0.2906 acc 0.7727\n",
            "Epoch 02: train loss 1.7102 f1 0.1727 acc 0.3497 | val loss 1.2158 f1 0.2906 acc 0.7727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.750     0.273     0.400        11\n",
            "    low_pain      0.250     0.053     0.087        19\n",
            "     no_pain      0.806     0.980     0.885       102\n",
            "\n",
            "    accuracy                          0.788       132\n",
            "   macro avg      0.602     0.435     0.457       132\n",
            "weighted avg      0.722     0.788     0.730       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  3   1   7]\n",
            " [  1   1  17]\n",
            " [  0   2 100]]\n",
            "Epoch 03: train loss 1.4063 f1 0.2038 acc 0.3705 | val loss 1.0529 f1 0.4573 acc 0.7879\n",
            "Epoch 04: train loss 1.0972 f1 0.4242 acc 0.4575 | val loss 1.0050 f1 0.3940 acc 0.5530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.092     1.000     0.169        11\n",
            "    low_pain      0.077     0.053     0.062        19\n",
            "     no_pain      0.000     0.000     0.000       102\n",
            "\n",
            "    accuracy                          0.091       132\n",
            "   macro avg      0.056     0.351     0.077       132\n",
            "weighted avg      0.019     0.091     0.023       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[11  0  0]\n",
            " [18  1  0]\n",
            " [90 12  0]]\n",
            "Epoch 05: train loss 0.8848 f1 0.3071 acc 0.3611 | val loss 1.2457 f1 0.0772 acc 0.0909\n",
            "Epoch 06: train loss 0.7944 f1 0.2188 acc 0.3629 | val loss 1.5577 f1 0.0781 acc 0.0909\n",
            "Epoch 07: train loss 0.7620 f1 0.2322 acc 0.3781 | val loss 1.4710 f1 0.1394 acc 0.1439\n",
            "Epoch 08: train loss 0.6783 f1 0.4806 acc 0.5331 | val loss 1.1783 f1 0.3587 acc 0.3788\n",
            "Epoch 09: train loss 0.6168 f1 0.5802 acc 0.6181 | val loss 1.1364 f1 0.3179 acc 0.3258\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.214     0.545     0.308        11\n",
            "    low_pain      0.157     0.842     0.264        19\n",
            "     no_pain      1.000     0.020     0.038       102\n",
            "\n",
            "    accuracy                          0.182       132\n",
            "   macro avg      0.457     0.469     0.204       132\n",
            "weighted avg      0.813     0.182     0.093       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  5  0]\n",
            " [ 3 16  0]\n",
            " [19 81  2]]\n",
            "Epoch 10: train loss 0.5266 f1 0.4714 acc 0.5520 | val loss 1.0685 f1 0.2035 acc 0.1818\n",
            "Epoch 11: train loss 0.4331 f1 0.5080 acc 0.5974 | val loss 0.9781 f1 0.3106 acc 0.2803\n",
            "Epoch 12: train loss 0.3744 f1 0.5851 acc 0.6635 | val loss 1.0508 f1 0.3481 acc 0.3258\n",
            "Epoch 13: train loss 0.2098 f1 0.6835 acc 0.7448 | val loss 1.0483 f1 0.4020 acc 0.4015\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 4/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.773     1.000     0.872       102\n",
            "\n",
            "    accuracy                          0.773       132\n",
            "   macro avg      0.258     0.333     0.291       132\n",
            "weighted avg      0.597     0.773     0.674       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  0   0  11]\n",
            " [  0   0  19]\n",
            " [  0   0 102]]\n",
            "Epoch 01: train loss 2.0161 f1 0.1563 acc 0.3062 | val loss 1.4545 f1 0.2906 acc 0.7727\n",
            "Epoch 02: train loss 1.8154 f1 0.1762 acc 0.3592 | val loss 1.3505 f1 0.2906 acc 0.7727\n",
            "Epoch 03: train loss 1.6140 f1 0.1486 acc 0.2798 | val loss 1.2061 f1 0.2906 acc 0.7727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.091     0.154        11\n",
            "    low_pain      0.500     0.105     0.174        19\n",
            "     no_pain      0.794     0.980     0.877       102\n",
            "\n",
            "    accuracy                          0.780       132\n",
            "   macro avg      0.598     0.392     0.402       132\n",
            "weighted avg      0.727     0.780     0.716       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  1   1   9]\n",
            " [  0   2  17]\n",
            " [  1   1 100]]\n",
            "Epoch 04: train loss 1.2850 f1 0.2723 acc 0.3667 | val loss 1.0686 f1 0.4017 acc 0.7803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.106     0.818     0.188        11\n",
            "    low_pain      0.061     0.105     0.077        19\n",
            "     no_pain      1.000     0.137     0.241       102\n",
            "\n",
            "    accuracy                          0.189       132\n",
            "   macro avg      0.389     0.354     0.169       132\n",
            "weighted avg      0.790     0.189     0.213       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  0]\n",
            " [17  2  0]\n",
            " [59 29 14]]\n",
            "Epoch 05: train loss 0.9924 f1 0.4063 acc 0.4102 | val loss 1.0738 f1 0.1686 acc 0.1894\n",
            "Epoch 06: train loss 0.8012 f1 0.2058 acc 0.3648 | val loss 1.4534 f1 0.0513 acc 0.0833\n",
            "Epoch 07: train loss 0.7527 f1 0.2283 acc 0.3800 | val loss 1.5094 f1 0.1051 acc 0.1061\n",
            "Epoch 08: train loss 0.7106 f1 0.3507 acc 0.4405 | val loss 1.2262 f1 0.1935 acc 0.1818\n",
            "Epoch 09: train loss 0.5952 f1 0.5131 acc 0.5614 | val loss 1.0110 f1 0.2694 acc 0.2576\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.167     0.818     0.277        11\n",
            "    low_pain      0.203     0.789     0.323        19\n",
            "     no_pain      1.000     0.039     0.075       102\n",
            "\n",
            "    accuracy                          0.212       132\n",
            "   macro avg      0.456     0.549     0.225       132\n",
            "weighted avg      0.816     0.212     0.128       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  0]\n",
            " [ 4 15  0]\n",
            " [41 57  4]]\n",
            "Epoch 10: train loss 0.4976 f1 0.4701 acc 0.5860 | val loss 1.0635 f1 0.2250 acc 0.2121\n",
            "Epoch 11: train loss 0.4308 f1 0.4745 acc 0.5879 | val loss 0.9502 f1 0.2329 acc 0.2121\n",
            "Epoch 12: train loss 0.3148 f1 0.5238 acc 0.6484 | val loss 0.9525 f1 0.2423 acc 0.2273\n",
            "Epoch 13: train loss 0.2979 f1 0.5574 acc 0.6654 | val loss 0.8737 f1 0.2876 acc 0.2652\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.267     0.727     0.390        11\n",
            "    low_pain      0.279     1.000     0.437        19\n",
            "     no_pain      1.000     0.333     0.500       102\n",
            "\n",
            "    accuracy                          0.462       132\n",
            "   macro avg      0.515     0.687     0.442       132\n",
            "weighted avg      0.835     0.462     0.482       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 0 19  0]\n",
            " [22 46 34]]\n",
            "Epoch 14: train loss 0.2508 f1 0.6690 acc 0.7108 | val loss 0.6377 f1 0.4423 acc 0.4621\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.200     0.636     0.304        11\n",
            "    low_pain      0.306     1.000     0.469        19\n",
            "     no_pain      1.000     0.343     0.511       102\n",
            "\n",
            "    accuracy                          0.462       132\n",
            "   macro avg      0.502     0.660     0.428       132\n",
            "weighted avg      0.834     0.462     0.488       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 0 19  0]\n",
            " [28 39 35]]\n",
            "Epoch 15: train loss 0.1850 f1 0.6769 acc 0.7259 | val loss 0.8054 f1 0.4281 acc 0.4621\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.292     0.636     0.400        11\n",
            "    low_pain      0.442     1.000     0.613        19\n",
            "     no_pain      1.000     0.637     0.778       102\n",
            "\n",
            "    accuracy                          0.689       132\n",
            "   macro avg      0.578     0.758     0.597       132\n",
            "weighted avg      0.861     0.689     0.723       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 0 19  0]\n",
            " [17 20 65]]\n",
            "Epoch 16: train loss 0.1571 f1 0.7987 acc 0.8166 | val loss 0.7418 f1 0.5971 acc 0.6894\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.304     0.636     0.412        11\n",
            "    low_pain      0.436     0.895     0.586        19\n",
            "     no_pain      1.000     0.686     0.814       102\n",
            "\n",
            "    accuracy                          0.712       132\n",
            "   macro avg      0.580     0.739     0.604       132\n",
            "weighted avg      0.861     0.712     0.748       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 2 17  0]\n",
            " [14 18 70]]\n",
            "Epoch 17: train loss 0.1743 f1 0.7804 acc 0.8015 | val loss 1.0689 f1 0.6040 acc 0.7121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.256     0.909     0.400        11\n",
            "    low_pain      0.750     0.789     0.769        19\n",
            "     no_pain      1.000     0.716     0.834       102\n",
            "\n",
            "    accuracy                          0.742       132\n",
            "   macro avg      0.669     0.805     0.668       132\n",
            "weighted avg      0.902     0.742     0.789       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[10  1  0]\n",
            " [ 4 15  0]\n",
            " [25  4 73]]\n",
            "Epoch 18: train loss 0.1429 f1 0.8856 acc 0.8866 | val loss 0.8471 f1 0.6678 acc 0.7424\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.467     0.636     0.538        11\n",
            "    low_pain      0.679     1.000     0.809        19\n",
            "     no_pain      1.000     0.873     0.932       102\n",
            "\n",
            "    accuracy                          0.871       132\n",
            "   macro avg      0.715     0.836     0.760       132\n",
            "weighted avg      0.909     0.871     0.881       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 0 19  0]\n",
            " [ 8  5 89]]\n",
            "Epoch 19: train loss 0.1510 f1 0.8171 acc 0.8261 | val loss 0.6693 f1 0.7596 acc 0.8712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.220     0.818     0.346        11\n",
            "    low_pain      0.773     0.895     0.829        19\n",
            "     no_pain      1.000     0.676     0.807       102\n",
            "\n",
            "    accuracy                          0.720       132\n",
            "   macro avg      0.664     0.796     0.661       132\n",
            "weighted avg      0.902     0.720     0.772       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  0]\n",
            " [ 2 17  0]\n",
            " [30  3 69]]\n",
            "Epoch 20: train loss 0.1486 f1 0.9259 acc 0.9263 | val loss 0.8095 f1 0.6608 acc 0.7197\n",
            "Epoch 21: train loss 0.0878 f1 0.8778 acc 0.8790 | val loss 0.7597 f1 0.7557 acc 0.8864\n",
            "Epoch 22: train loss 0.0684 f1 0.9473 acc 0.9490 | val loss 0.6347 f1 0.6828 acc 0.7652\n",
            "Epoch 23: train loss 0.0761 f1 0.9155 acc 0.9187 | val loss 0.6352 f1 0.7436 acc 0.8485\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.467     0.636     0.538        11\n",
            "    low_pain      0.818     0.947     0.878        19\n",
            "     no_pain      0.989     0.922     0.954       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.758     0.835     0.790       132\n",
            "weighted avg      0.921     0.902     0.909       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  3  1]\n",
            " [ 1 18  0]\n",
            " [ 7  1 94]]\n",
            "Epoch 24: train loss 0.0797 f1 0.9338 acc 0.9338 | val loss 0.6859 f1 0.7903 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.615     0.727     0.667        11\n",
            "    low_pain      0.692     0.947     0.800        19\n",
            "     no_pain      0.989     0.902     0.944       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.766     0.859     0.803       132\n",
            "weighted avg      0.915     0.894     0.900       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  1]\n",
            " [ 1 18  0]\n",
            " [ 4  6 92]]\n",
            "Epoch 25: train loss 0.0450 f1 0.9549 acc 0.9546 | val loss 0.5719 f1 0.8034 acc 0.8939\n",
            "Epoch 26: train loss 0.0513 f1 0.9546 acc 0.9546 | val loss 0.8150 f1 0.7737 acc 0.8561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.727     0.593        11\n",
            "    low_pain      0.818     0.947     0.878        19\n",
            "     no_pain      1.000     0.922     0.959       102\n",
            "\n",
            "    accuracy                          0.909       132\n",
            "   macro avg      0.773     0.865     0.810       132\n",
            "weighted avg      0.932     0.909     0.917       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 1 18  0]\n",
            " [ 7  1 94]]\n",
            "Epoch 27: train loss 0.0614 f1 0.9437 acc 0.9452 | val loss 0.6640 f1 0.8099 acc 0.9091\n",
            "Epoch 28: train loss 0.0324 f1 0.9733 acc 0.9735 | val loss 0.7376 f1 0.8099 acc 0.9091\n",
            "Epoch 29: train loss 0.0369 f1 0.9661 acc 0.9660 | val loss 0.6237 f1 0.7924 acc 0.8864\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.438     0.636     0.519        11\n",
            "    low_pain      0.773     0.895     0.829        19\n",
            "     no_pain      0.989     0.912     0.949       102\n",
            "\n",
            "    accuracy                          0.886       132\n",
            "   macro avg      0.733     0.814     0.766       132\n",
            "weighted avg      0.912     0.886     0.896       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 1 17  1]\n",
            " [ 8  1 93]]\n",
            "Epoch 30: train loss 0.0368 f1 0.9537 acc 0.9546 | val loss 0.6063 f1 0.7656 acc 0.8864\n",
            "Epoch 31: train loss 0.0381 f1 0.9846 acc 0.9849 | val loss 0.6281 f1 0.7814 acc 0.8864\n",
            "Epoch 32: train loss 0.0173 f1 0.9752 acc 0.9754 | val loss 0.6186 f1 0.8085 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.818     0.621        11\n",
            "    low_pain      0.889     0.842     0.865        19\n",
            "     no_pain      0.979     0.922     0.949       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.789     0.861     0.812       132\n",
            "weighted avg      0.926     0.902     0.910       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  1  1]\n",
            " [ 2 16  1]\n",
            " [ 7  1 94]]\n",
            "Epoch 33: train loss 0.0339 f1 0.9738 acc 0.9735 | val loss 0.8599 f1 0.8117 acc 0.9015\n",
            "Epoch 34: train loss 0.0384 f1 0.9753 acc 0.9754 | val loss 0.9137 f1 0.7527 acc 0.8636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.400     0.727     0.516        11\n",
            "    low_pain      0.773     0.895     0.829        19\n",
            "     no_pain      1.000     0.882     0.938       102\n",
            "\n",
            "    accuracy                          0.871       132\n",
            "   macro avg      0.724     0.835     0.761       132\n",
            "weighted avg      0.917     0.871     0.887       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 2 17  0]\n",
            " [10  2 90]]\n",
            "Epoch 35: train loss 0.0349 f1 0.9722 acc 0.9716 | val loss 0.9260 f1 0.7610 acc 0.8712\n",
            "Epoch 36: train loss 0.0179 f1 0.9749 acc 0.9754 | val loss 0.8322 f1 0.7849 acc 0.8939\n",
            "Epoch 37: train loss 0.0469 f1 0.9701 acc 0.9698 | val loss 0.8584 f1 0.7858 acc 0.8864\n",
            "Epoch 38: train loss 0.0109 f1 0.9904 acc 0.9905 | val loss 0.9535 f1 0.7425 acc 0.8409\n",
            "Epoch 39: train loss 0.0163 f1 0.9828 acc 0.9830 | val loss 0.9600 f1 0.7845 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.583     0.636     0.609        11\n",
            "    low_pain      0.857     0.947     0.900        19\n",
            "     no_pain      0.970     0.941     0.955       102\n",
            "\n",
            "    accuracy                          0.917       132\n",
            "   macro avg      0.803     0.842     0.821       132\n",
            "weighted avg      0.921     0.917     0.918       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 0 18  1]\n",
            " [ 5  1 96]]\n",
            "Epoch 40: train loss 0.0183 f1 0.9792 acc 0.9792 | val loss 0.8221 f1 0.8213 acc 0.9167\n",
            "Epoch 41: train loss 0.0228 f1 0.9791 acc 0.9792 | val loss 0.6254 f1 0.8200 acc 0.9091\n",
            "Epoch 42: train loss 0.0053 f1 0.9943 acc 0.9943 | val loss 0.7167 f1 0.8085 acc 0.9015\n",
            "Epoch 43: train loss 0.0289 f1 0.9804 acc 0.9811 | val loss 0.7395 f1 0.8200 acc 0.9091\n",
            "Epoch 44: train loss 0.0114 f1 0.9852 acc 0.9849 | val loss 0.8478 f1 0.8140 acc 0.9091\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.533     0.727     0.615        11\n",
            "    low_pain      0.842     0.842     0.842        19\n",
            "     no_pain      0.969     0.931     0.950       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.782     0.834     0.802       132\n",
            "weighted avg      0.915     0.902     0.907       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  1]\n",
            " [ 1 16  2]\n",
            " [ 6  1 95]]\n",
            "Epoch 45: train loss 0.0048 f1 0.9945 acc 0.9943 | val loss 0.8417 f1 0.8025 acc 0.9015\n",
            "Epoch 46: train loss 0.0104 f1 0.9888 acc 0.9887 | val loss 0.8596 f1 0.8085 acc 0.9015\n",
            "Epoch 47: train loss 0.0051 f1 1.0000 acc 1.0000 | val loss 0.8843 f1 0.7764 acc 0.8864\n",
            "Epoch 48: train loss 0.0041 f1 0.9980 acc 0.9981 | val loss 0.8598 f1 0.7964 acc 0.8939\n",
            "Epoch 49: train loss 0.0097 f1 0.9890 acc 0.9887 | val loss 0.8906 f1 0.7964 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.533     0.727     0.615        11\n",
            "    low_pain      0.889     0.842     0.865        19\n",
            "     no_pain      0.960     0.931     0.945       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.794     0.834     0.809       132\n",
            "weighted avg      0.914     0.902     0.906       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  1  2]\n",
            " [ 1 16  2]\n",
            " [ 6  1 95]]\n",
            "Epoch 50: train loss 0.0047 f1 0.9981 acc 0.9981 | val loss 0.9042 f1 0.8085 acc 0.9015\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 5/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.773     1.000     0.872       102\n",
            "\n",
            "    accuracy                          0.773       132\n",
            "   macro avg      0.258     0.333     0.291       132\n",
            "weighted avg      0.597     0.773     0.674       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  0   0  11]\n",
            " [  0   0  19]\n",
            " [  0   0 102]]\n",
            "Epoch 01: train loss 2.1894 f1 0.1693 acc 0.3403 | val loss 1.4966 f1 0.2906 acc 0.7727\n",
            "Epoch 02: train loss 1.9662 f1 0.1671 acc 0.3346 | val loss 1.3907 f1 0.2906 acc 0.7727\n",
            "Epoch 03: train loss 1.7240 f1 0.1762 acc 0.3592 | val loss 1.2458 f1 0.2906 acc 0.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.000     0.000     0.000        11\n",
            "    low_pain      0.167     0.053     0.080        19\n",
            "     no_pain      0.786     0.971     0.868       102\n",
            "\n",
            "    accuracy                          0.758       132\n",
            "   macro avg      0.317     0.341     0.316       132\n",
            "weighted avg      0.631     0.758     0.683       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 0  2  9]\n",
            " [ 0  1 18]\n",
            " [ 0  3 99]]\n",
            "Epoch 04: train loss 1.4867 f1 0.1927 acc 0.3554 | val loss 1.0931 f1 0.3161 acc 0.7576\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.308     0.727     0.432        11\n",
            "    low_pain      0.179     0.789     0.291        19\n",
            "     no_pain      1.000     0.216     0.355       102\n",
            "\n",
            "    accuracy                          0.341       132\n",
            "   macro avg      0.495     0.577     0.360       132\n",
            "weighted avg      0.824     0.341     0.352       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 4 15  0]\n",
            " [14 66 22]]\n",
            "Epoch 05: train loss 1.1149 f1 0.4208 acc 0.4461 | val loss 1.0406 f1 0.3595 acc 0.3409\n",
            "Epoch 06: train loss 0.8885 f1 0.2449 acc 0.3422 | val loss 1.3765 f1 0.0513 acc 0.0833\n",
            "Epoch 07: train loss 0.8387 f1 0.1798 acc 0.3327 | val loss 1.5438 f1 0.0524 acc 0.0833\n",
            "Epoch 08: train loss 0.7923 f1 0.3474 acc 0.4329 | val loss 1.3079 f1 0.2196 acc 0.1970\n",
            "Epoch 09: train loss 0.6798 f1 0.4629 acc 0.5161 | val loss 1.1231 f1 0.2843 acc 0.2727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.170     0.818     0.281        11\n",
            "    low_pain      0.222     0.737     0.341        19\n",
            "     no_pain      0.938     0.147     0.254       102\n",
            "\n",
            "    accuracy                          0.288       132\n",
            "   macro avg      0.443     0.567     0.292       132\n",
            "weighted avg      0.771     0.288     0.269       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  0]\n",
            " [ 4 14  1]\n",
            " [40 47 15]]\n",
            "Epoch 10: train loss 0.5729 f1 0.5368 acc 0.5992 | val loss 0.9837 f1 0.2923 acc 0.2879\n",
            "Epoch 11: train loss 0.4346 f1 0.5613 acc 0.6635 | val loss 1.1384 f1 0.2856 acc 0.2803\n",
            "Epoch 12: train loss 0.3473 f1 0.5925 acc 0.6522 | val loss 1.1870 f1 0.2994 acc 0.3030\n",
            "Epoch 13: train loss 0.2949 f1 0.6609 acc 0.7051 | val loss 1.0568 f1 0.3116 acc 0.3182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.212     0.636     0.318        11\n",
            "    low_pain      0.232     0.842     0.364        19\n",
            "     no_pain      0.933     0.275     0.424       102\n",
            "\n",
            "    accuracy                          0.386       132\n",
            "   macro avg      0.459     0.584     0.369       132\n",
            "weighted avg      0.772     0.386     0.407       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 1 16  2]\n",
            " [25 49 28]]\n",
            "Epoch 14: train loss 0.2316 f1 0.7023 acc 0.7410 | val loss 0.9218 f1 0.3687 acc 0.3864\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.154     0.545     0.240        11\n",
            "    low_pain      0.359     0.737     0.483        19\n",
            "     no_pain      0.944     0.500     0.654       102\n",
            "\n",
            "    accuracy                          0.538       132\n",
            "   macro avg      0.486     0.594     0.459       132\n",
            "weighted avg      0.794     0.538     0.595       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  4  1]\n",
            " [ 3 14  2]\n",
            " [30 21 51]]\n",
            "Epoch 15: train loss 0.2290 f1 0.6858 acc 0.7353 | val loss 1.1279 f1 0.4589 acc 0.5379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.312     0.455     0.370        11\n",
            "    low_pain      0.314     0.842     0.457        19\n",
            "     no_pain      0.923     0.588     0.719       102\n",
            "\n",
            "    accuracy                          0.614       132\n",
            "   macro avg      0.516     0.628     0.515       132\n",
            "weighted avg      0.784     0.614     0.652       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  4  2]\n",
            " [ 0 16  3]\n",
            " [11 31 60]]\n",
            "Epoch 16: train loss 0.1664 f1 0.8366 acc 0.8469 | val loss 0.9889 f1 0.5154 acc 0.6136\n",
            "Epoch 17: train loss 0.1272 f1 0.8678 acc 0.8733 | val loss 1.1249 f1 0.5115 acc 0.6439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.333     0.727     0.457        11\n",
            "    low_pain      0.462     0.632     0.533        19\n",
            "     no_pain      0.915     0.735     0.815       102\n",
            "\n",
            "    accuracy                          0.720       132\n",
            "   macro avg      0.570     0.698     0.602       132\n",
            "weighted avg      0.801     0.720     0.745       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  1]\n",
            " [ 1 12  6]\n",
            " [15 12 75]]\n",
            "Epoch 18: train loss 0.1280 f1 0.8616 acc 0.8696 | val loss 0.8171 f1 0.6019 acc 0.7197\n",
            "Epoch 19: train loss 0.0565 f1 0.9433 acc 0.9433 | val loss 0.8774 f1 0.5637 acc 0.6439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.545     0.545     0.545        11\n",
            "    low_pain      0.700     0.737     0.718        19\n",
            "     no_pain      0.921     0.912     0.916       102\n",
            "\n",
            "    accuracy                          0.856       132\n",
            "   macro avg      0.722     0.731     0.727       132\n",
            "weighted avg      0.858     0.856     0.857       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  2  3]\n",
            " [ 0 14  5]\n",
            " [ 5  4 93]]\n",
            "Epoch 20: train loss 0.0979 f1 0.8856 acc 0.8885 | val loss 1.0478 f1 0.7266 acc 0.8561\n",
            "Epoch 21: train loss 0.0847 f1 0.9126 acc 0.9168 | val loss 0.6516 f1 0.6219 acc 0.7197\n",
            "Epoch 22: train loss 0.1382 f1 0.9059 acc 0.9074 | val loss 0.9576 f1 0.6606 acc 0.8030\n",
            "Epoch 23: train loss 0.0578 f1 0.9515 acc 0.9527 | val loss 0.9705 f1 0.6431 acc 0.7727\n",
            "Epoch 24: train loss 0.0742 f1 0.9393 acc 0.9395 | val loss 1.4864 f1 0.6376 acc 0.8030\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.625     0.455     0.526        11\n",
            "    low_pain      0.552     0.842     0.667        19\n",
            "     no_pain      0.926     0.863     0.893       102\n",
            "\n",
            "    accuracy                          0.826       132\n",
            "   macro avg      0.701     0.720     0.695       132\n",
            "weighted avg      0.847     0.826     0.830       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 0 16  3]\n",
            " [ 3 11 88]]\n",
            "Epoch 25: train loss 0.0438 f1 0.9570 acc 0.9584 | val loss 0.9289 f1 0.6955 acc 0.8258\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.471     0.727     0.571        11\n",
            "    low_pain      0.789     0.789     0.789        19\n",
            "     no_pain      0.948     0.892     0.919       102\n",
            "\n",
            "    accuracy                          0.864       132\n",
            "   macro avg      0.736     0.803     0.760       132\n",
            "weighted avg      0.885     0.864     0.872       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  1]\n",
            " [ 0 15  4]\n",
            " [ 9  2 91]]\n",
            "Epoch 26: train loss 0.0256 f1 0.9710 acc 0.9716 | val loss 0.7347 f1 0.7600 acc 0.8636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.818     0.621        11\n",
            "    low_pain      0.778     0.737     0.757        19\n",
            "     no_pain      0.938     0.882     0.909       102\n",
            "\n",
            "    accuracy                          0.856       132\n",
            "   macro avg      0.738     0.812     0.762       132\n",
            "weighted avg      0.878     0.856     0.863       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  0  2]\n",
            " [ 1 14  4]\n",
            " [ 8  4 90]]\n",
            "Epoch 27: train loss 0.0428 f1 0.9693 acc 0.9698 | val loss 0.7231 f1 0.7622 acc 0.8561\n",
            "Epoch 28: train loss 0.0409 f1 0.9550 acc 0.9546 | val loss 0.9558 f1 0.6692 acc 0.7955\n",
            "Epoch 29: train loss 0.0475 f1 0.9643 acc 0.9641 | val loss 0.9847 f1 0.7109 acc 0.8409\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.438     0.636     0.519        11\n",
            "    low_pain      0.636     0.737     0.683        19\n",
            "     no_pain      0.926     0.853     0.888       102\n",
            "\n",
            "    accuracy                          0.818       132\n",
            "   macro avg      0.666     0.742     0.696       132\n",
            "weighted avg      0.843     0.818     0.828       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  1  3]\n",
            " [ 1 14  4]\n",
            " [ 8  7 87]]\n",
            "Epoch 30: train loss 0.0392 f1 0.9738 acc 0.9754 | val loss 0.8647 f1 0.6964 acc 0.8182\n",
            "Epoch 31: train loss 0.0260 f1 0.9739 acc 0.9735 | val loss 1.4286 f1 0.6705 acc 0.8561\n",
            "Epoch 32: train loss 0.0325 f1 0.9701 acc 0.9698 | val loss 1.2239 f1 0.6759 acc 0.8333\n",
            "Epoch 33: train loss 0.0188 f1 0.9812 acc 0.9811 | val loss 1.5536 f1 0.6881 acc 0.8485\n",
            "Epoch 34: train loss 0.0216 f1 0.9906 acc 0.9905 | val loss 1.5923 f1 0.6995 acc 0.8561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.714     0.455     0.556        11\n",
            "    low_pain      0.750     0.789     0.769        19\n",
            "     no_pain      0.933     0.961     0.947       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.799     0.735     0.757       132\n",
            "weighted avg      0.889     0.894     0.889       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  3  3]\n",
            " [ 0 15  4]\n",
            " [ 2  2 98]]\n",
            "Epoch 35: train loss 0.0328 f1 0.9696 acc 0.9698 | val loss 1.3871 f1 0.7572 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.875     0.636     0.737        11\n",
            "    low_pain      0.682     0.789     0.732        19\n",
            "     no_pain      0.941     0.941     0.941       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.833     0.789     0.803       132\n",
            "weighted avg      0.898     0.894     0.894       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 0 15  4]\n",
            " [ 1  5 96]]\n",
            "Epoch 36: train loss 0.0162 f1 0.9829 acc 0.9830 | val loss 1.2588 f1 0.8032 acc 0.8939\n",
            "Epoch 37: train loss 0.0228 f1 0.9814 acc 0.9811 | val loss 0.8047 f1 0.7842 acc 0.8864\n",
            "Epoch 38: train loss 0.0137 f1 0.9963 acc 0.9962 | val loss 1.2812 f1 0.7149 acc 0.8636\n"
          ]
        }
      ],
      "source": [
        "# pirate_pain_baseline.py\n",
        "# Train-from-scratch baseline for Pirate Pain (multivariate time-series classification)\n",
        "# Requires: pandas, numpy, scikit-learn, torch, tqdm\n",
        "# Tested on CPU/MPS (Apple Silicon) and CUDA if available.\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# ---------------------------\n",
        "# Utils\n",
        "# ---------------------------\n",
        "def seed_everything(seed=42):\n",
        "    import random, os\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_device():\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "# ---------------------------\n",
        "# Data shaping\n",
        "# ---------------------------\n",
        "def infer_columns(df):\n",
        "    id_col = \"sample_index\"\n",
        "    time_col = \"time\" if \"time\" in df.columns else None\n",
        "    static_candidates = [\"n_legs\",\"n_hands\",\"n_eyes\"]\n",
        "    static_cols = [c for c in static_candidates if c in df.columns]\n",
        "    ignore = set([id_col] + ([time_col] if time_col else []) + static_cols)\n",
        "    feature_cols = [c for c in df.columns if c not in ignore]\n",
        "    return id_col, time_col, static_cols, feature_cols\n",
        "\n",
        "def _numericize_features(df, cols):\n",
        "    \"\"\"Return a numeric version of df[cols], mapping common words to numbers and dropping all-NaN cols.\"\"\"\n",
        "    mapping = {\n",
        "        \"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4,\n",
        "        \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
        "        \"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0,\n",
        "        \"none\": None, \"null\": None, \"nan\": None, \"\": None\n",
        "    }\n",
        "    out = df[cols].copy()\n",
        "    for c in out.columns:\n",
        "        if out[c].dtype == object:\n",
        "            s = out[c].astype(str).str.strip().str.lower().replace(mapping)\n",
        "            out[c] = pd.to_numeric(s, errors=\"coerce\")\n",
        "        else:\n",
        "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
        "    keep = out.columns[out.notna().any()].tolist()\n",
        "    dropped = [c for c in out.columns if c not in keep]\n",
        "    if dropped:\n",
        "        print(f\"[build_sequences] Dropping non-numeric/all-NaN features: {dropped[:15]}\" + (\" ...\" if len(dropped) > 15 else \"\"))\n",
        "    return out[keep], keep\n",
        "\n",
        "def build_sequences(X_df, y_df=None, expect_T=180):\n",
        "    id_col = \"sample_index\"\n",
        "    time_col = \"time\" if \"time\" in X_df.columns else None\n",
        "    static_candidates = [\"n_legs\",\"n_hands\",\"n_eyes\"]\n",
        "    static_cols = [c for c in static_candidates if c in X_df.columns]\n",
        "    ignore = set([id_col] + ([time_col] if time_col else []) + static_cols)\n",
        "    ignore |= {\"label\",\"target\",\"class\"}\n",
        "    raw_dyn_cols = [c for c in X_df.columns if c not in ignore]\n",
        "\n",
        "    if time_col is not None:\n",
        "        X_df = X_df.sort_values([id_col, time_col])\n",
        "    else:\n",
        "        X_df = X_df.sort_values([id_col])\n",
        "\n",
        "    dyn_numeric, dyn_cols = _numericize_features(X_df, raw_dyn_cols)\n",
        "    for c in dyn_cols:\n",
        "        X_df[c] = dyn_numeric[c].values\n",
        "\n",
        "    groups = X_df.groupby(id_col)\n",
        "    sample_ids = []\n",
        "    lengths = []                     # <--- NEW\n",
        "    X_dyn_list, X_static_list = [], []\n",
        "\n",
        "    def fix_len(arr, T):\n",
        "        n = arr.shape[0]\n",
        "        if n == T: return arr, \"ok\"\n",
        "        if n > T:  return arr[-T:, :], \"trunc\"\n",
        "        pad = np.repeat(arr[-1:, :], T - n, axis=0)\n",
        "        return np.concatenate([arr, pad], axis=0), \"pad\"\n",
        "\n",
        "    n_ok = n_pad = n_trunc = 0\n",
        "\n",
        "    for s_id, g in groups:\n",
        "        g_dyn = g[dyn_cols].ffill().bfill().fillna(0.0)\n",
        "        arr0 = g_dyn.to_numpy(dtype=np.float32)\n",
        "        true_len = arr0.shape[0]           # <--- NEW (pre padding)\n",
        "        arr, tag = fix_len(arr0, expect_T)\n",
        "        if tag == \"ok\": n_ok += 1\n",
        "        elif tag == \"pad\": n_pad += 1\n",
        "        else: n_trunc += 1\n",
        "\n",
        "        if len(static_cols) > 0:\n",
        "            s0 = g[static_cols].iloc[0]\n",
        "            s0 = s0.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "            s = s0.to_numpy(dtype=np.float32)\n",
        "        else:\n",
        "            s = np.zeros(0, dtype=np.float32)\n",
        "\n",
        "        sample_ids.append(s_id)\n",
        "        lengths.append(min(true_len, expect_T))   # cap to T\n",
        "        X_dyn_list.append(arr)\n",
        "        X_static_list.append(s)\n",
        "\n",
        "    if len(X_dyn_list) == 0:\n",
        "        raise ValueError(\"No sequences assembled. Check 'sample_index' and that each sample has rows.\")\n",
        "\n",
        "    X_dyn = np.stack(X_dyn_list, axis=0)\n",
        "    X_static = np.stack(X_static_list, axis=0)\n",
        "    sample_ids = np.array(sample_ids)\n",
        "    lengths = np.array(lengths, dtype=np.int64)   # <--- NEW\n",
        "\n",
        "    print(f\"[build_sequences] Target T={expect_T} -> ok:{n_ok}  padded:{n_pad}  truncated:{n_trunc}\")\n",
        "\n",
        "    y = None\n",
        "    classes = None\n",
        "    if y_df is not None:\n",
        "        label_cols = [c for c in y_df.columns if c != \"sample_index\"]\n",
        "        assert len(label_cols) == 1, \"y_train must have one target column besides sample_index\"\n",
        "        target_col = label_cols[0]\n",
        "        y_map = y_df.set_index(\"sample_index\")[target_col].to_dict()\n",
        "        y_raw = [y_map[s] for s in sample_ids]\n",
        "        classes = sorted(list(set(y_raw)))\n",
        "        class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "        y = np.array([class_to_idx[v] for v in y_raw], dtype=np.int64)\n",
        "\n",
        "    return X_dyn, X_static, sample_ids, lengths, y, classes, dyn_cols, static_cols\n",
        "\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X_dyn, X_static, lengths, y=None, train=False, aug_p=0.0):\n",
        "        self.X_dyn = X_dyn\n",
        "        self.X_static = X_static\n",
        "        self.lengths = lengths\n",
        "        self.y = y\n",
        "        self.train = train\n",
        "        self.aug_p = aug_p\n",
        "\n",
        "    def _augment(self, x):  # x: [T,C]\n",
        "        # light, safe defaults\n",
        "        import numpy as np\n",
        "        T, C = x.shape\n",
        "        if np.random.rand() < self.aug_p:\n",
        "            x = x + np.random.normal(0, 0.01, size=x.shape)        # jitter\n",
        "        if np.random.rand() < self.aug_p:\n",
        "            scale = 1.0 + np.random.normal(0, 0.05, size=(1, C))   # channel scaling\n",
        "            x = x * scale\n",
        "        if np.random.rand() < self.aug_p:\n",
        "            w = np.random.randint(5, 20)\n",
        "            s = np.random.randint(0, T - w)\n",
        "            x[s:s+w, :] = 0                                        # time mask\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X_dyn.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_dyn = self.X_dyn[idx]      # np array [T,C]\n",
        "        if self.train and self.aug_p > 0:\n",
        "            x_dyn = self._augment(x_dyn.copy()).astype(np.float32)\n",
        "        x_dyn = torch.from_numpy(x_dyn)\n",
        "        x_static = torch.from_numpy(self.X_static[idx])\n",
        "        length = int(self.lengths[idx])\n",
        "        if self.y is None:\n",
        "            return x_dyn, x_static, length\n",
        "        return x_dyn, x_static, length, int(self.y[idx])\n",
        "\n",
        "class AttnPool(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(nn.LayerNorm(d), nn.Linear(d, d//2), nn.Tanh(), nn.Linear(d//2, 1))\n",
        "    def forward(self, x, mask):                 # x:[B,T,D], mask:[B,T] bool\n",
        "        a = self.proj(x).squeeze(-1)            # [B,T]\n",
        "        a = a.masked_fill(~mask, float('-inf'))\n",
        "        w = a.softmax(dim=1)                    # [B,T]\n",
        "        return (x * w.unsqueeze(-1)).sum(1)     # [B,D]\n",
        "\n",
        "# ---------------------------\n",
        "# Model (CNN + BiGRU head)\n",
        "# ---------------------------\n",
        "class PirateNet(nn.Module):\n",
        "    def __init__(self, c_dyn, c_static, hidden=64, rnn_layers=1, num_classes=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(c_dyn, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv1d(64, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.rnn = nn.GRU(input_size=64, hidden_size=hidden, num_layers=rnn_layers,\n",
        "                          batch_first=True, bidirectional=True)\n",
        "        self.attn = AttnPool(2*hidden)\n",
        "\n",
        "        static_out = 32 if c_static > 0 else 0\n",
        "        if c_static > 0:\n",
        "            self.static_mlp = nn.Sequential(\n",
        "                nn.LayerNorm(c_static),\n",
        "                nn.Linear(c_static, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(64, static_out),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "\n",
        "        head_in = (2*hidden)*3 + static_out  # mean + max + attn\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(head_in, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dyn, x_static, lengths):\n",
        "        # x_dyn: [B,T,C] -> conv -> [B,T,64] -> BiGRU -> [B,T,2H]\n",
        "        x = self.conv(x_dyn.transpose(1,2)).transpose(1,2)\n",
        "        out, _ = self.rnn(x)\n",
        "\n",
        "        B, T, D = out.shape\n",
        "        device = out.device\n",
        "        # mask: True on real steps, False on padding\n",
        "        lens = lengths.to(device)\n",
        "        ar = torch.arange(T, device=device).unsqueeze(0).expand(B, T)\n",
        "        mask = ar < lens.unsqueeze(1)                         # [B,T] bool\n",
        "\n",
        "        # masked pools\n",
        "        h_mean = (out * mask.unsqueeze(-1)).sum(1) / torch.clamp(lens.unsqueeze(1), min=1).to(out.dtype)\n",
        "        out_masked = out.masked_fill(~mask.unsqueeze(-1), float('-inf'))\n",
        "        h_max = out_masked.max(1).values\n",
        "        h_attn = self.attn(out, mask)\n",
        "\n",
        "        feat = torch.cat([h_mean, h_max, h_attn], dim=1)\n",
        "        if x_static is not None and x_static.shape[1] > 0:\n",
        "            s = self.static_mlp(x_static)\n",
        "            feat = torch.cat([feat, s], dim=1)\n",
        "        return self.head(feat)\n",
        "\n",
        "# ---------------------------\n",
        "# Training / Evaluation\n",
        "# ---------------------------\n",
        "def train_one_epoch(model, loader, optimizer, device, criterion, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    preds, trues = [], []\n",
        "    for batch in loader:\n",
        "        xb_dyn, xb_static, xlens, yb = batch\n",
        "        xb_dyn = xb_dyn.to(device)\n",
        "        xb_static = xb_static.to(device)\n",
        "        xlens = torch.as_tensor(xlens, device=device)\n",
        "        yb = torch.as_tensor(yb, device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb_dyn, xb_static, xlens)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item() * yb.size(0)\n",
        "        preds.append(logits.detach().softmax(dim=1).cpu().numpy())\n",
        "        trues.append(yb.detach().cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds); trues = np.concatenate(trues)\n",
        "    f1 = f1_score(trues, preds.argmax(1), average=\"macro\")\n",
        "    acc = accuracy_score(trues, preds.argmax(1))\n",
        "    return total_loss / len(loader.dataset), f1, acc\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds, trues = [], []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 3:     # test loader\n",
        "            xb_dyn, xb_static, xlens = batch\n",
        "            yb = None\n",
        "        else:\n",
        "            xb_dyn, xb_static, xlens, yb = batch\n",
        "            yb = torch.as_tensor(yb, device=device)\n",
        "        xb_dyn = xb_dyn.to(device)\n",
        "        xb_static = xb_static.to(device)\n",
        "        xlens = torch.as_tensor(xlens, device=device)\n",
        "\n",
        "        logits = model(xb_dyn, xb_static, xlens)\n",
        "        if yb is not None:\n",
        "            loss = criterion(logits, yb)\n",
        "            total_loss += loss.item() * yb.size(0)\n",
        "            trues.append(yb.detach().cpu().numpy())\n",
        "        preds.append(logits.detach().softmax(dim=1).cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    if trues:\n",
        "        trues = np.concatenate(trues)\n",
        "        f1 = f1_score(trues, preds.argmax(1), average=\"macro\")\n",
        "        acc = accuracy_score(trues, preds.argmax(1))\n",
        "        return total_loss / len(loader.dataset), f1, acc, preds\n",
        "    return None, None, None, preds\n",
        "\n",
        "\n",
        "def add_deltas(X):  # X: [N,T,C]\n",
        "    d1 = np.diff(X, axis=1, prepend=X[:, :1, :])\n",
        "    d2 = np.diff(d1, axis=1, prepend=d1[:, :1, :])\n",
        "    return np.concatenate([X, d1, d2], axis=2)\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, targets):\n",
        "        ce = nn.functional.cross_entropy(logits, targets, weight=self.alpha, reduction='none')\n",
        "        pt = torch.softmax(logits, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
        "        loss = ((1 - pt).clamp_min(1e-6) ** self.gamma) * ce\n",
        "        return loss.mean() if self.reduction=='mean' else loss.sum()\n",
        "\n",
        "# ---------------------------\n",
        "# Main\n",
        "# ---------------------------\n",
        "def main(args):\n",
        "    seed_everything(args.seed)\n",
        "    device = get_device()\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load data\n",
        "    X_train = pd.read_csv(\"pirate_pain_train.csv\")\n",
        "    y_train = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
        "    X_test  = pd.read_csv(\"pirate_pain_test.csv\")\n",
        "\n",
        "    # Build sequences\n",
        "    Xdyn_tr, Xsta_tr, ids_tr, len_tr, y, classes, dyn_cols, static_cols = build_sequences(X_train, y_train, expect_T=180)\n",
        "    Xdyn_te, Xsta_te, ids_te, len_te, _, _, _, _ = build_sequences(X_test, None, expect_T=180)\n",
        "    num_classes = len(classes)\n",
        "    Xdyn_tr = add_deltas(Xdyn_tr)\n",
        "    Xdyn_te = add_deltas(Xdyn_te)\n",
        "    print(f\"Train sequences: {len(ids_tr)}  Test sequences: {len(ids_te)}\")\n",
        "    print(f\"Dynamic channels: {Xdyn_tr.shape[-1]}  Static dims: {Xsta_tr.shape[-1]}  Classes: {classes}\")\n",
        "\n",
        "    # CV setup\n",
        "    skf = StratifiedKFold(n_splits=args.folds, shuffle=True, random_state=args.seed)\n",
        "\n",
        "    # OOF storage\n",
        "    oof_pred = np.zeros((len(ids_tr), num_classes), dtype=np.float32)\n",
        "    test_pred_folds = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(ids_tr, y), start=1):\n",
        "        print(f\"\\n========== FOLD {fold}/{args.folds} ==========\")\n",
        "        # Fit scalers on train fold ONLY (flatten over time for per-feature scaling)\n",
        "        T, C = Xdyn_tr.shape[1], Xdyn_tr.shape[2]\n",
        "        dyn_scaler = StandardScaler()\n",
        "        dyn_scaler.fit(Xdyn_tr[tr_idx].reshape(-1, C))\n",
        "        Xdyn_tr_scaled = dyn_scaler.transform(Xdyn_tr.reshape(-1, C)).reshape(-1, T, C)\n",
        "        Xdyn_te_scaled = dyn_scaler.transform(Xdyn_te.reshape(-1, C)).reshape(-1, T, C)\n",
        "\n",
        "        if Xsta_tr.shape[1] > 0:\n",
        "            sta_scaler = StandardScaler()\n",
        "            sta_scaler.fit(Xsta_tr[tr_idx])\n",
        "            Xsta_tr_scaled = sta_scaler.transform(Xsta_tr)\n",
        "            Xsta_te_scaled = sta_scaler.transform(Xsta_te)\n",
        "        else:\n",
        "            Xsta_tr_scaled = Xsta_tr\n",
        "            Xsta_te_scaled = Xsta_te\n",
        "\n",
        "\n",
        "        # Loss (class weights if imbalance)\n",
        "        class_counts = np.bincount(y[tr_idx], minlength=num_classes) + 1\n",
        "        sample_w = (1.0 / class_counts)[y[tr_idx]]   # per-sample weight by inverse class freq\n",
        "        sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Datasets & loaders\n",
        "        ds_tr = SequenceDataset(Xdyn_tr_scaled[tr_idx], Xsta_tr_scaled[tr_idx], len_tr[tr_idx], y[tr_idx], train=True, aug_p=0.5)\n",
        "        ds_va = SequenceDataset(Xdyn_tr_scaled[va_idx], Xsta_tr_scaled[va_idx], len_tr[va_idx], y[va_idx], train=False)\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=args.batch_size, sampler=sampler, num_workers=0, drop_last=False)\n",
        "        dl_va = DataLoader(ds_va, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
        "\n",
        "        # Model\n",
        "        model = PirateNet(c_dyn=C, c_static=Xsta_tr.shape[1], hidden=args.hidden, rnn_layers=1,\n",
        "                          num_classes=num_classes, dropout=args.dropout).to(device)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "          last = model.head[-1]  # final Linear\n",
        "          priors = torch.tensor(class_counts / class_counts.sum(), dtype=torch.float32, device=device)\n",
        "          last.bias.copy_(priors.log())  # log-prior init helps avoid early collapse\n",
        "\n",
        "\n",
        "        # normalize to mean=1 so loss scale stays reasonable\n",
        "        inv = class_counts.sum() / class_counts\n",
        "        inv = inv / inv.mean()\n",
        "        class_weights = torch.tensor(inv, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "        #criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device))\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.0)  # fallback to 0 if your torch is old  (otherwise 0.05)\n",
        "        #criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, epochs=args.epochs, steps_per_epoch=len(dl_tr))\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, epochs=args.epochs, steps_per_epoch=len(dl_tr),\n",
        "                                                        pct_start=0.3, div_factor=10.0, final_div_factor=100.0)\n",
        "\n",
        "        # Training loop with early stopping on macro-F1\n",
        "        best_f1, patience_left = -1.0, args.patience\n",
        "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}  # init in case no improvement\n",
        "\n",
        "\n",
        "        for epoch in range(1, args.epochs+1):\n",
        "          tr_loss, tr_f1, tr_acc = train_one_epoch(model, dl_tr, optimizer, device, criterion, scheduler)\n",
        "          va_loss, va_f1, va_acc, va_pred = evaluate(model, dl_va, device, criterion)\n",
        "\n",
        "          if (epoch % 5 == 0) or (va_f1 > best_f1 + 1e-5):\n",
        "              y_true = y[va_idx]\n",
        "              y_hat  = va_pred.argmax(1)\n",
        "              print(classification_report(y_true, y_hat, target_names=classes, digits=3))\n",
        "              print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_hat))\n",
        "\n",
        "          print(f\"Epoch {epoch:02d}: \"\n",
        "                f\"train loss {tr_loss:.4f} f1 {tr_f1:.4f} acc {tr_acc:.4f} | \"\n",
        "                f\"val loss {va_loss:.4f} f1 {va_f1:.4f} acc {va_acc:.4f}\")\n",
        "\n",
        "          if va_f1 > best_f1 + 1e-5:\n",
        "              best_f1 = va_f1\n",
        "              best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "              patience_left = args.patience\n",
        "          else:\n",
        "              patience_left -= 1\n",
        "              if patience_left <= 0:\n",
        "                  print(\"Early stopping.\")\n",
        "                  break\n",
        "\n",
        "        # Load best\n",
        "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
        "\n",
        "        # Store OOF predictions\n",
        "        _, _, _, va_pred = evaluate(model, dl_va, device, criterion)\n",
        "        oof_pred[va_idx] = va_pred\n",
        "\n",
        "        # Predict test for this fold\n",
        "        dl_te = DataLoader(SequenceDataset(Xdyn_te_scaled, Xsta_te_scaled, len_te, None), batch_size=args.batch_size, shuffle=False)\n",
        "        _, _, _, te_pred = evaluate(model, dl_te, device, criterion)\n",
        "        test_pred_folds.append(te_pred)\n",
        "\n",
        "    # Report OOF score\n",
        "    oof_labels = y\n",
        "    oof_f1 = f1_score(oof_labels, oof_pred.argmax(1), average=\"macro\")\n",
        "    oof_acc = accuracy_score(oof_labels, oof_pred.argmax(1))\n",
        "    print(f\"\\nOOF macro-F1: {oof_f1:.4f} | OOF Acc: {oof_acc:.4f}\")\n",
        "\n",
        "    # Average test predictions across folds\n",
        "    test_pred = np.mean(np.stack(test_pred_folds, axis=0), axis=0)  # [N_test, K]\n",
        "\n",
        "    # Write OOF preds (optional)\n",
        "    pd.DataFrame({\n",
        "        \"sample_index\": ids_tr,\n",
        "        **{f\"prob_{cls}\": oof_pred[:, i] for i, cls in enumerate(classes)},\n",
        "        \"oof_pred\": [classes[i] for i in oof_pred.argmax(1)],\n",
        "        \"target\": [classes[i] for i in oof_labels]\n",
        "    }).to_csv(\"oof_predictions.csv\", index=False)\n",
        "\n",
        "    # Submission: match sample_submission columns if available\n",
        "    submit_col_id = \"sample_index\"\n",
        "    # Try to read sample submission for correct column names/order\n",
        "    label_col_name = \"label\"\n",
        "    if os.path.exists(\"sample_submission.csv\"):\n",
        "        sub_template = pd.read_csv(\"sample_submission.csv\")\n",
        "        submit_col_id = [c for c in sub_template.columns if c != label_col_name][0] if label_col_name in sub_template.columns else \"sample_index\"\n",
        "        if label_col_name not in sub_template.columns:\n",
        "            # try to detect\n",
        "            non_id = [c for c in sub_template.columns if c != submit_col_id]\n",
        "            if len(non_id) == 1:\n",
        "                label_col_name = non_id[0]\n",
        "    test_pred_labels = [classes[i] for i in test_pred.argmax(1)]\n",
        "    submission = pd.DataFrame({submit_col_id: ids_te, label_col_name: test_pred_labels})\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"Wrote submission.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--epochs\", type=int, default=60)\n",
        "    p.add_argument(\"--batch_size\", type=int, default=64)\n",
        "    p.add_argument(\"--folds\", type=int, default=5)\n",
        "    p.add_argument(\"--hidden\", type=int, default=64)\n",
        "    p.add_argument(\"--dropout\", type=float, default=0.2)\n",
        "    p.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    p.add_argument(\"--weight_decay\", type=float, default=1e-2)\n",
        "    p.add_argument(\"--patience\", type=int, default=10)\n",
        "    p.add_argument(\"--seed\", type=int, default=42)\n",
        "    args, _ = p.parse_known_args()  # ignores Jupyter/Colab's extra -f argument\n",
        "    main(args)"
      ]
    }
  ]
}