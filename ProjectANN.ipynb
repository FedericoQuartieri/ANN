{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "current_dir = \"/gdrive/My\\\\ Drive/Gesù/\"\n",
        "%cd $current_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDFhrqIp_7Ov",
        "outputId": "0a06c619-8ecc-4d49-ca10-5071597ca74c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/Gesù\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8mDbjnp9Xtc",
        "outputId": "ac06820a-2d4f-4567-db87-f06b2d9ab91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "[build_sequences] Target T=180 -> ok:0  padded:661  truncated:0\n",
            "[build_sequences] Target T=180 -> ok:0  padded:1324  truncated:0\n",
            "Train sequences: 661  Test sequences: 1324\n",
            "Dynamic channels: 105  Static dims: 3  Classes: ['high_pain', 'low_pain', 'no_pain']\n",
            "\n",
            "========== FOLD 1/5 ==========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.222     0.167     0.190        12\n",
            "    low_pain      0.148     1.000     0.257        18\n",
            "     no_pain      1.000     0.019     0.038       103\n",
            "\n",
            "    accuracy                          0.165       133\n",
            "   macro avg      0.457     0.395     0.162       133\n",
            "weighted avg      0.814     0.165     0.081       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 2 10  0]\n",
            " [ 0 18  0]\n",
            " [ 7 94  2]]\n",
            "Epoch 01: train loss 0.4886 f1 0.2897 acc 0.3220 | val loss 0.4814 f1 0.1619 acc 0.1654\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.250     0.167     0.200        12\n",
            "    low_pain      0.240     0.333     0.279        18\n",
            "     no_pain      0.840     0.816     0.828       103\n",
            "\n",
            "    accuracy                          0.692       133\n",
            "   macro avg      0.443     0.439     0.436       133\n",
            "weighted avg      0.706     0.692     0.697       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 2  6  4]\n",
            " [ 0  6 12]\n",
            " [ 6 13 84]]\n",
            "Epoch 02: train loss 0.4745 f1 0.4136 acc 0.4489 | val loss 0.4586 f1 0.4356 acc 0.6917\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.273     0.250     0.261        12\n",
            "    low_pain      0.208     0.278     0.238        18\n",
            "     no_pain      0.847     0.806     0.826       103\n",
            "\n",
            "    accuracy                          0.684       133\n",
            "   macro avg      0.443     0.445     0.442       133\n",
            "weighted avg      0.709     0.684     0.695       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 3  5  4]\n",
            " [ 2  5 11]\n",
            " [ 6 14 83]]\n",
            "Epoch 03: train loss 0.4682 f1 0.4274 acc 0.4678 | val loss 0.4492 f1 0.4416 acc 0.6842\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.294     0.417     0.345        12\n",
            "    low_pain      0.267     0.444     0.333        18\n",
            "     no_pain      0.860     0.718     0.783       103\n",
            "\n",
            "    accuracy                          0.654       133\n",
            "   macro avg      0.474     0.527     0.487       133\n",
            "weighted avg      0.729     0.654     0.683       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  3  4]\n",
            " [ 2  8  8]\n",
            " [10 19 74]]\n",
            "Epoch 04: train loss 0.4551 f1 0.4900 acc 0.5152 | val loss 0.4441 f1 0.4871 acc 0.6541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.263     0.417     0.323        12\n",
            "    low_pain      0.200     0.389     0.264        18\n",
            "     no_pain      0.886     0.680     0.769       103\n",
            "\n",
            "    accuracy                          0.617       133\n",
            "   macro avg      0.450     0.495     0.452       133\n",
            "weighted avg      0.737     0.617     0.661       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  5  2]\n",
            " [ 4  7  7]\n",
            " [10 23 70]]\n",
            "Epoch 05: train loss 0.4254 f1 0.5644 acc 0.5758 | val loss 0.4345 f1 0.4520 acc 0.6165\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.364     0.667     0.471        12\n",
            "    low_pain      0.188     0.333     0.240        18\n",
            "     no_pain      0.886     0.680     0.769       103\n",
            "\n",
            "    accuracy                          0.632       133\n",
            "   macro avg      0.479     0.560     0.493       133\n",
            "weighted avg      0.744     0.632     0.671       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  2]\n",
            " [ 5  6  7]\n",
            " [ 9 24 70]]\n",
            "Epoch 06: train loss 0.4100 f1 0.5779 acc 0.5814 | val loss 0.4098 f1 0.4933 acc 0.6316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.267     0.667     0.381        12\n",
            "    low_pain      0.300     0.333     0.316        18\n",
            "     no_pain      0.880     0.709     0.785       103\n",
            "\n",
            "    accuracy                          0.654       133\n",
            "   macro avg      0.482     0.570     0.494       133\n",
            "weighted avg      0.746     0.654     0.685       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  2]\n",
            " [ 4  6  8]\n",
            " [18 12 73]]\n",
            "Epoch 07: train loss 0.3520 f1 0.6450 acc 0.6496 | val loss 0.3665 f1 0.4939 acc 0.6541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.267     0.667     0.381        12\n",
            "    low_pain      0.391     0.500     0.439        18\n",
            "     no_pain      0.912     0.709     0.798       103\n",
            "\n",
            "    accuracy                          0.677       133\n",
            "   macro avg      0.523     0.625     0.539       133\n",
            "weighted avg      0.784     0.677     0.712       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  2]\n",
            " [ 4  9  5]\n",
            " [18 12 73]]\n",
            "Epoch 08: train loss 0.2871 f1 0.6857 acc 0.6856 | val loss 0.3306 f1 0.5393 acc 0.6767\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.750     0.600        12\n",
            "    low_pain      0.769     0.556     0.645        18\n",
            "     no_pain      0.941     0.932     0.937       103\n",
            "\n",
            "    accuracy                          0.865       133\n",
            "   macro avg      0.737     0.746     0.727       133\n",
            "weighted avg      0.878     0.865     0.867       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  1  2]\n",
            " [ 4 10  4]\n",
            " [ 5  2 96]]\n",
            "Epoch 09: train loss 0.2441 f1 0.7348 acc 0.7348 | val loss 0.1857 f1 0.7272 acc 0.8647\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.278     0.833     0.417        12\n",
            "    low_pain      0.688     0.611     0.647        18\n",
            "     no_pain      0.963     0.757     0.848       103\n",
            "\n",
            "    accuracy                          0.744       133\n",
            "   macro avg      0.643     0.734     0.637       133\n",
            "weighted avg      0.864     0.744     0.782       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[10  1  1]\n",
            " [ 5 11  2]\n",
            " [21  4 78]]\n",
            "Epoch 10: train loss 0.1603 f1 0.8118 acc 0.8144 | val loss 0.2884 f1 0.6372 acc 0.7444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.615     0.667     0.640        12\n",
            "    low_pain      0.786     0.611     0.688        18\n",
            "     no_pain      0.925     0.951     0.938       103\n",
            "\n",
            "    accuracy                          0.880       133\n",
            "   macro avg      0.775     0.743     0.755       133\n",
            "weighted avg      0.878     0.880     0.877       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  1  3]\n",
            " [ 2 11  5]\n",
            " [ 3  2 98]]\n",
            "Epoch 11: train loss 0.1617 f1 0.8790 acc 0.8788 | val loss 0.1433 f1 0.7551 acc 0.8797\n",
            "Epoch 12: train loss 0.1295 f1 0.8945 acc 0.8939 | val loss 0.1370 f1 0.7398 acc 0.8722\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.600     0.750     0.667        12\n",
            "    low_pain      0.652     0.833     0.732        18\n",
            "     no_pain      0.979     0.903     0.939       103\n",
            "\n",
            "    accuracy                          0.880       133\n",
            "   macro avg      0.744     0.829     0.779       133\n",
            "weighted avg      0.901     0.880     0.887       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  1]\n",
            " [ 2 15  1]\n",
            " [ 4  6 93]]\n",
            "Epoch 13: train loss 0.1001 f1 0.8934 acc 0.8939 | val loss 0.1433 f1 0.7793 acc 0.8797\n",
            "Epoch 14: train loss 0.0908 f1 0.8996 acc 0.8996 | val loss 0.1452 f1 0.7597 acc 0.8571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.333     0.750     0.462        12\n",
            "    low_pain      0.800     0.667     0.727        18\n",
            "     no_pain      0.956     0.845     0.897       103\n",
            "\n",
            "    accuracy                          0.812       133\n",
            "   macro avg      0.696     0.754     0.695       133\n",
            "weighted avg      0.879     0.812     0.835       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  1  2]\n",
            " [ 4 12  2]\n",
            " [14  2 87]]\n",
            "Epoch 15: train loss 0.0684 f1 0.9260 acc 0.9261 | val loss 0.1643 f1 0.6952 acc 0.8120\n",
            "Epoch 16: train loss 0.0613 f1 0.9427 acc 0.9413 | val loss 0.1060 f1 0.7755 acc 0.9023\n",
            "Epoch 17: train loss 0.0400 f1 0.9547 acc 0.9527 | val loss 0.1048 f1 0.7717 acc 0.8947\n",
            "Epoch 18: train loss 0.0612 f1 0.9264 acc 0.9261 | val loss 0.1730 f1 0.6373 acc 0.7744\n",
            "Epoch 19: train loss 0.1023 f1 0.8939 acc 0.8939 | val loss 0.1243 f1 0.7636 acc 0.9023\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.471     0.667     0.552        12\n",
            "    low_pain      0.652     0.833     0.732        18\n",
            "     no_pain      0.989     0.893     0.939       103\n",
            "\n",
            "    accuracy                          0.865       133\n",
            "   macro avg      0.704     0.798     0.741       133\n",
            "weighted avg      0.897     0.865     0.876       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  1]\n",
            " [ 3 15  0]\n",
            " [ 6  5 92]]\n",
            "Epoch 20: train loss 0.0389 f1 0.9604 acc 0.9602 | val loss 0.1671 f1 0.7407 acc 0.8647\n",
            "Epoch 21: train loss 0.0422 f1 0.9602 acc 0.9602 | val loss 0.1400 f1 0.7648 acc 0.8947\n",
            "Epoch 22: train loss 0.0226 f1 0.9777 acc 0.9773 | val loss 0.1966 f1 0.7375 acc 0.8496\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.615     0.667     0.640        12\n",
            "    low_pain      0.765     0.722     0.743        18\n",
            "     no_pain      0.961     0.961     0.961       103\n",
            "\n",
            "    accuracy                          0.902       133\n",
            "   macro avg      0.780     0.783     0.781       133\n",
            "weighted avg      0.903     0.902     0.903       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  2]\n",
            " [ 3 13  2]\n",
            " [ 2  2 99]]\n",
            "Epoch 23: train loss 0.0446 f1 0.9593 acc 0.9602 | val loss 0.1561 f1 0.7813 acc 0.9023\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.667     0.667     0.667        12\n",
            "    low_pain      0.750     0.833     0.789        18\n",
            "     no_pain      0.970     0.951     0.961       103\n",
            "\n",
            "    accuracy                          0.910       133\n",
            "   macro avg      0.796     0.817     0.806       133\n",
            "weighted avg      0.913     0.910     0.911       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  2  2]\n",
            " [ 2 15  1]\n",
            " [ 2  3 98]]\n",
            "Epoch 24: train loss 0.0308 f1 0.9602 acc 0.9602 | val loss 0.1199 f1 0.8056 acc 0.9098\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.526     0.833     0.645        12\n",
            "    low_pain      0.824     0.778     0.800        18\n",
            "     no_pain      0.969     0.913     0.940       103\n",
            "\n",
            "    accuracy                          0.887       133\n",
            "   macro avg      0.773     0.841     0.795       133\n",
            "weighted avg      0.909     0.887     0.894       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[10  1  1]\n",
            " [ 2 14  2]\n",
            " [ 7  2 94]]\n",
            "Epoch 25: train loss 0.0218 f1 0.9755 acc 0.9754 | val loss 0.1249 f1 0.7951 acc 0.8872\n",
            "Epoch 26: train loss 0.0216 f1 0.9831 acc 0.9830 | val loss 0.1535 f1 0.7621 acc 0.8947\n",
            "Epoch 27: train loss 0.0192 f1 0.9773 acc 0.9773 | val loss 0.1096 f1 0.8055 acc 0.9098\n",
            "Epoch 28: train loss 0.0113 f1 0.9905 acc 0.9905 | val loss 0.1036 f1 0.7757 acc 0.9098\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.800     0.667     0.727        12\n",
            "    low_pain      0.944     0.944     0.944        18\n",
            "     no_pain      0.971     0.990     0.981       103\n",
            "\n",
            "    accuracy                          0.955       133\n",
            "   macro avg      0.905     0.867     0.884       133\n",
            "weighted avg      0.952     0.955     0.953       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[  8   1   3]\n",
            " [  1  17   0]\n",
            " [  1   0 102]]\n",
            "Epoch 29: train loss 0.0274 f1 0.9735 acc 0.9735 | val loss 0.0894 f1 0.8842 acc 0.9549\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.636     0.583     0.609        12\n",
            "    low_pain      0.850     0.944     0.895        18\n",
            "     no_pain      0.971     0.961     0.966       103\n",
            "\n",
            "    accuracy                          0.925       133\n",
            "   macro avg      0.819     0.830     0.823       133\n",
            "weighted avg      0.924     0.925     0.924       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  3]\n",
            " [ 1 17  0]\n",
            " [ 3  1 99]]\n",
            "Epoch 30: train loss 0.0242 f1 0.9759 acc 0.9754 | val loss 0.0952 f1 0.8231 acc 0.9248\n",
            "Epoch 31: train loss 0.0144 f1 0.9887 acc 0.9886 | val loss 0.0868 f1 0.8417 acc 0.9323\n",
            "Epoch 32: train loss 0.0132 f1 0.9925 acc 0.9924 | val loss 0.0913 f1 0.8334 acc 0.9248\n",
            "Epoch 33: train loss 0.0177 f1 0.9850 acc 0.9848 | val loss 0.0885 f1 0.8439 acc 0.9398\n",
            "Epoch 34: train loss 0.0133 f1 0.9852 acc 0.9848 | val loss 0.0888 f1 0.8430 acc 0.9323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.818     0.750     0.783        12\n",
            "    low_pain      0.842     0.889     0.865        18\n",
            "     no_pain      0.971     0.971     0.971       103\n",
            "\n",
            "    accuracy                          0.940       133\n",
            "   macro avg      0.877     0.870     0.873       133\n",
            "weighted avg      0.940     0.940     0.940       133\n",
            "\n",
            "Confusion matrix:\n",
            " [[  9   1   2]\n",
            " [  1  16   1]\n",
            " [  1   2 100]]\n",
            "Epoch 35: train loss 0.0266 f1 0.9773 acc 0.9773 | val loss 0.0985 f1 0.8728 acc 0.9398\n",
            "Epoch 36: train loss 0.0086 f1 0.9884 acc 0.9886 | val loss 0.1053 f1 0.8161 acc 0.9173\n",
            "Epoch 37: train loss 0.0112 f1 0.9927 acc 0.9924 | val loss 0.1057 f1 0.8560 acc 0.9398\n",
            "Epoch 38: train loss 0.0086 f1 0.9906 acc 0.9905 | val loss 0.1087 f1 0.8438 acc 0.9323\n",
            "Epoch 39: train loss 0.0153 f1 0.9869 acc 0.9867 | val loss 0.1086 f1 0.8282 acc 0.9323\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 2/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.076     0.909     0.141        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.000     0.000     0.000       102\n",
            "\n",
            "    accuracy                          0.076       132\n",
            "   macro avg      0.025     0.303     0.047       132\n",
            "weighted avg      0.006     0.076     0.012       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 10   1   0]\n",
            " [ 19   0   0]\n",
            " [102   0   0]]\n",
            "Epoch 01: train loss 0.4922 f1 0.2204 acc 0.3535 | val loss 0.5334 f1 0.0469 acc 0.0758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.082     0.727     0.147        11\n",
            "    low_pain      0.118     0.211     0.151        19\n",
            "     no_pain      0.000     0.000     0.000       102\n",
            "\n",
            "    accuracy                          0.091       132\n",
            "   macro avg      0.066     0.313     0.099       132\n",
            "weighted avg      0.024     0.091     0.034       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [15  4  0]\n",
            " [75 27  0]]\n",
            "Epoch 02: train loss 0.4818 f1 0.3003 acc 0.3516 | val loss 0.5014 f1 0.0992 acc 0.0909\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.098     0.545     0.167        11\n",
            "    low_pain      0.154     0.105     0.125        19\n",
            "     no_pain      0.845     0.480     0.613       102\n",
            "\n",
            "    accuracy                          0.432       132\n",
            "   macro avg      0.366     0.377     0.301       132\n",
            "weighted avg      0.683     0.432     0.505       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  1  4]\n",
            " [12  2  5]\n",
            " [43 10 49]]\n",
            "Epoch 03: train loss 0.4654 f1 0.4624 acc 0.4783 | val loss 0.4868 f1 0.3014 acc 0.4318\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.140     0.545     0.222        11\n",
            "    low_pain      0.176     0.158     0.167        19\n",
            "     no_pain      0.847     0.598     0.701       102\n",
            "\n",
            "    accuracy                          0.530       132\n",
            "   macro avg      0.388     0.434     0.363       132\n",
            "weighted avg      0.692     0.530     0.584       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  1  4]\n",
            " [ 9  3  7]\n",
            " [28 13 61]]\n",
            "Epoch 04: train loss 0.4526 f1 0.4905 acc 0.5142 | val loss 0.4693 f1 0.3633 acc 0.5303\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.167     0.273     0.207        11\n",
            "    low_pain      0.143     0.263     0.185        19\n",
            "     no_pain      0.861     0.667     0.751       102\n",
            "\n",
            "    accuracy                          0.576       132\n",
            "   macro avg      0.390     0.401     0.381       132\n",
            "weighted avg      0.700     0.576     0.625       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 3  4  4]\n",
            " [ 7  5  7]\n",
            " [ 8 26 68]]\n",
            "Epoch 05: train loss 0.4297 f1 0.5417 acc 0.5444 | val loss 0.4181 f1 0.3812 acc 0.5758\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.154     0.364     0.216        11\n",
            "    low_pain      0.174     0.211     0.190        19\n",
            "     no_pain      0.867     0.706     0.778       102\n",
            "\n",
            "    accuracy                          0.606       132\n",
            "   macro avg      0.398     0.427     0.395       132\n",
            "weighted avg      0.708     0.606     0.647       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 4  3  4]\n",
            " [ 8  4  7]\n",
            " [14 16 72]]\n",
            "Epoch 06: train loss 0.3785 f1 0.5595 acc 0.5652 | val loss 0.3871 f1 0.3950 acc 0.6061\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.174     0.364     0.235        11\n",
            "    low_pain      0.385     0.263     0.312        19\n",
            "     no_pain      0.896     0.843     0.869       102\n",
            "\n",
            "    accuracy                          0.720       132\n",
            "   macro avg      0.485     0.490     0.472       132\n",
            "weighted avg      0.762     0.720     0.736       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 4  3  4]\n",
            " [ 8  5  6]\n",
            " [11  5 86]]\n",
            "Epoch 07: train loss 0.3332 f1 0.6627 acc 0.6692 | val loss 0.2968 f1 0.4722 acc 0.7197\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.400     0.364     0.381        11\n",
            "    low_pain      0.474     0.474     0.474        19\n",
            "     no_pain      0.932     0.941     0.937       102\n",
            "\n",
            "    accuracy                          0.826       132\n",
            "   macro avg      0.602     0.593     0.597       132\n",
            "weighted avg      0.822     0.826     0.824       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 4  5  2]\n",
            " [ 5  9  5]\n",
            " [ 1  5 96]]\n",
            "Epoch 08: train loss 0.2812 f1 0.7081 acc 0.7089 | val loss 0.2208 f1 0.5971 acc 0.8258\n",
            "Epoch 09: train loss 0.2245 f1 0.7603 acc 0.7599 | val loss 0.2278 f1 0.5403 acc 0.7803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.375     0.545     0.444        11\n",
            "    low_pain      0.529     0.474     0.500        19\n",
            "     no_pain      0.929     0.902     0.915       102\n",
            "\n",
            "    accuracy                          0.811       132\n",
            "   macro avg      0.611     0.640     0.620       132\n",
            "weighted avg      0.826     0.811     0.816       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  3  2]\n",
            " [ 5  9  5]\n",
            " [ 5  5 92]]\n",
            "Epoch 10: train loss 0.1681 f1 0.8245 acc 0.8261 | val loss 0.1962 f1 0.6200 acc 0.8106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.438     0.636     0.519        11\n",
            "    low_pain      0.714     0.526     0.606        19\n",
            "     no_pain      0.941     0.941     0.941       102\n",
            "\n",
            "    accuracy                          0.856       132\n",
            "   macro avg      0.698     0.701     0.689       132\n",
            "weighted avg      0.867     0.856     0.858       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  3  1]\n",
            " [ 4 10  5]\n",
            " [ 5  1 96]]\n",
            "Epoch 11: train loss 0.1280 f1 0.8772 acc 0.8771 | val loss 0.1563 f1 0.6886 acc 0.8561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.400     0.727     0.516        11\n",
            "    low_pain      0.552     0.842     0.667        19\n",
            "     no_pain      0.988     0.804     0.886       102\n",
            "\n",
            "    accuracy                          0.803       132\n",
            "   macro avg      0.647     0.791     0.690       132\n",
            "weighted avg      0.876     0.803     0.824       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  3  0]\n",
            " [ 2 16  1]\n",
            " [10 10 82]]\n",
            "Epoch 12: train loss 0.0887 f1 0.9066 acc 0.9074 | val loss 0.2016 f1 0.6898 acc 0.8030\n",
            "Epoch 13: train loss 0.1027 f1 0.9084 acc 0.9074 | val loss 0.2129 f1 0.6324 acc 0.8106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.625     0.455     0.526        11\n",
            "    low_pain      0.615     0.842     0.711        19\n",
            "     no_pain      0.949     0.912     0.930       102\n",
            "\n",
            "    accuracy                          0.864       132\n",
            "   macro avg      0.730     0.736     0.722       132\n",
            "weighted avg      0.874     0.864     0.865       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  3  3]\n",
            " [ 1 16  2]\n",
            " [ 2  7 93]]\n",
            "Epoch 14: train loss 0.0633 f1 0.9373 acc 0.9376 | val loss 0.1743 f1 0.7225 acc 0.8636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.636     0.560        11\n",
            "    low_pain      0.700     0.737     0.718        19\n",
            "     no_pain      0.949     0.912     0.930       102\n",
            "\n",
            "    accuracy                          0.864       132\n",
            "   macro avg      0.716     0.762     0.736       132\n",
            "weighted avg      0.876     0.864     0.869       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 2 14  3]\n",
            " [ 5  4 93]]\n",
            "Epoch 15: train loss 0.0511 f1 0.9421 acc 0.9414 | val loss 0.1696 f1 0.7360 acc 0.8636\n",
            "Epoch 16: train loss 0.0344 f1 0.9478 acc 0.9471 | val loss 0.1605 f1 0.6909 acc 0.8561\n",
            "Epoch 17: train loss 0.0272 f1 0.9504 acc 0.9509 | val loss 0.3047 f1 0.6422 acc 0.8182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.714     0.455     0.556        11\n",
            "    low_pain      0.875     0.737     0.800        19\n",
            "     no_pain      0.917     0.980     0.948       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.836     0.724     0.768       132\n",
            "weighted avg      0.894     0.902     0.894       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  5   2   4]\n",
            " [  0  14   5]\n",
            " [  2   0 100]]\n",
            "Epoch 18: train loss 0.0557 f1 0.9473 acc 0.9471 | val loss 0.1646 f1 0.7678 acc 0.9015\n",
            "Epoch 19: train loss 0.0413 f1 0.9569 acc 0.9565 | val loss 0.2249 f1 0.6980 acc 0.8182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.714     0.455     0.556        11\n",
            "    low_pain      0.667     0.842     0.744        19\n",
            "     no_pain      0.950     0.941     0.946       102\n",
            "\n",
            "    accuracy                          0.886       132\n",
            "   macro avg      0.777     0.746     0.749       132\n",
            "weighted avg      0.890     0.886     0.884       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  3  3]\n",
            " [ 1 16  2]\n",
            " [ 1  5 96]]\n",
            "Epoch 20: train loss 0.0260 f1 0.9574 acc 0.9584 | val loss 0.2627 f1 0.7485 acc 0.8864\n",
            "Epoch 21: train loss 0.0295 f1 0.9637 acc 0.9641 | val loss 0.1837 f1 0.7444 acc 0.8864\n",
            "Epoch 22: train loss 0.0295 f1 0.9682 acc 0.9679 | val loss 0.2134 f1 0.6701 acc 0.8258\n",
            "Epoch 23: train loss 0.0445 f1 0.9554 acc 0.9546 | val loss 0.2136 f1 0.7572 acc 0.9015\n",
            "Epoch 24: train loss 0.0302 f1 0.9627 acc 0.9622 | val loss 0.3321 f1 0.6911 acc 0.8485\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.545     0.545     0.545        11\n",
            "    low_pain      0.833     0.789     0.811        19\n",
            "     no_pain      0.951     0.961     0.956       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.777     0.765     0.771       132\n",
            "weighted avg      0.901     0.902     0.901       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  2  3]\n",
            " [ 2 15  2]\n",
            " [ 3  1 98]]\n",
            "Epoch 25: train loss 0.0472 f1 0.9622 acc 0.9622 | val loss 0.2025 f1 0.7708 acc 0.9015\n",
            "Epoch 26: train loss 0.0267 f1 0.9680 acc 0.9679 | val loss 0.2693 f1 0.6799 acc 0.8561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.750     0.545     0.632        11\n",
            "    low_pain      0.833     0.789     0.811        19\n",
            "     no_pain      0.943     0.980     0.962       102\n",
            "\n",
            "    accuracy                          0.917       132\n",
            "   macro avg      0.842     0.772     0.801       132\n",
            "weighted avg      0.911     0.917     0.912       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  6   2   3]\n",
            " [  1  15   3]\n",
            " [  1   1 100]]\n",
            "Epoch 27: train loss 0.0185 f1 0.9812 acc 0.9811 | val loss 0.1751 f1 0.8013 acc 0.9167\n",
            "Epoch 28: train loss 0.0378 f1 0.9600 acc 0.9603 | val loss 0.3178 f1 0.6727 acc 0.8182\n",
            "Epoch 29: train loss 0.0259 f1 0.9672 acc 0.9679 | val loss 0.2642 f1 0.6984 acc 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.462     0.545     0.500        11\n",
            "    low_pain      0.650     0.684     0.667        19\n",
            "     no_pain      0.960     0.931     0.945       102\n",
            "\n",
            "    accuracy                          0.864       132\n",
            "   macro avg      0.690     0.720     0.704       132\n",
            "weighted avg      0.874     0.864     0.868       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  3  2]\n",
            " [ 4 13  2]\n",
            " [ 3  4 95]]\n",
            "Epoch 30: train loss 0.0111 f1 0.9887 acc 0.9887 | val loss 0.2413 f1 0.7040 acc 0.8636\n",
            "Epoch 31: train loss 0.0321 f1 0.9830 acc 0.9830 | val loss 0.2301 f1 0.7757 acc 0.9015\n",
            "Epoch 32: train loss 0.0165 f1 0.9794 acc 0.9792 | val loss 0.2523 f1 0.7301 acc 0.8864\n",
            "Epoch 33: train loss 0.0145 f1 0.9755 acc 0.9754 | val loss 0.2773 f1 0.7035 acc 0.8485\n",
            "Epoch 34: train loss 0.0061 f1 0.9941 acc 0.9943 | val loss 0.3035 f1 0.7205 acc 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.556     0.455     0.500        11\n",
            "    low_pain      0.615     0.842     0.711        19\n",
            "     no_pain      0.959     0.912     0.935       102\n",
            "\n",
            "    accuracy                          0.864       132\n",
            "   macro avg      0.710     0.736     0.715       132\n",
            "weighted avg      0.876     0.864     0.866       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  3  3]\n",
            " [ 2 16  1]\n",
            " [ 2  7 93]]\n",
            "Epoch 35: train loss 0.0069 f1 0.9906 acc 0.9905 | val loss 0.3025 f1 0.7153 acc 0.8636\n",
            "Epoch 36: train loss 0.0054 f1 0.9961 acc 0.9962 | val loss 0.2525 f1 0.7412 acc 0.8788\n",
            "Epoch 37: train loss 0.0026 f1 1.0000 acc 1.0000 | val loss 0.3043 f1 0.7074 acc 0.8636\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 3/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.188     0.545     0.279        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.870     0.853     0.861       102\n",
            "\n",
            "    accuracy                          0.705       132\n",
            "   macro avg      0.353     0.466     0.380       132\n",
            "weighted avg      0.688     0.705     0.689       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  0  5]\n",
            " [11  0  8]\n",
            " [15  0 87]]\n",
            "Epoch 01: train loss 0.4877 f1 0.2955 acc 0.3781 | val loss 0.4717 f1 0.3802 acc 0.7045\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.149     0.636     0.241        11\n",
            "    low_pain      0.241     0.368     0.292        19\n",
            "     no_pain      0.893     0.490     0.633       102\n",
            "\n",
            "    accuracy                          0.485       132\n",
            "   macro avg      0.428     0.498     0.389       132\n",
            "weighted avg      0.737     0.485     0.551       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  1  3]\n",
            " [ 9  7  3]\n",
            " [31 21 50]]\n",
            "Epoch 02: train loss 0.4735 f1 0.2629 acc 0.3459 | val loss 0.4869 f1 0.3887 acc 0.4848\n",
            "Epoch 03: train loss 0.4649 f1 0.3713 acc 0.4083 | val loss 0.4837 f1 0.3589 acc 0.4242\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.182     0.545     0.273        11\n",
            "    low_pain      0.243     0.474     0.321        19\n",
            "     no_pain      0.903     0.549     0.683       102\n",
            "\n",
            "    accuracy                          0.538       132\n",
            "   macro avg      0.443     0.523     0.426       132\n",
            "weighted avg      0.748     0.538     0.597       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  2  3]\n",
            " [ 7  9  3]\n",
            " [20 26 56]]\n",
            "Epoch 04: train loss 0.4453 f1 0.4751 acc 0.5009 | val loss 0.4822 f1 0.4257 acc 0.5379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.219     0.636     0.326        11\n",
            "    low_pain      0.500     0.368     0.424        19\n",
            "     no_pain      0.895     0.755     0.819       102\n",
            "\n",
            "    accuracy                          0.689       132\n",
            "   macro avg      0.538     0.587     0.523       132\n",
            "weighted avg      0.782     0.689     0.721       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  0  4]\n",
            " [ 7  7  5]\n",
            " [18  7 77]]\n",
            "Epoch 05: train loss 0.4237 f1 0.5596 acc 0.5614 | val loss 0.4330 f1 0.5230 acc 0.6894\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.273     0.545     0.364        11\n",
            "    low_pain      0.500     0.421     0.457        19\n",
            "     no_pain      0.883     0.814     0.847       102\n",
            "\n",
            "    accuracy                          0.735       132\n",
            "   macro avg      0.552     0.593     0.556       132\n",
            "weighted avg      0.777     0.735     0.751       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  1  4]\n",
            " [ 4  8  7]\n",
            " [12  7 83]]\n",
            "Epoch 06: train loss 0.3830 f1 0.5911 acc 0.6049 | val loss 0.3436 f1 0.5559 acc 0.7348\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.280     0.636     0.389        11\n",
            "    low_pain      0.500     0.526     0.513        19\n",
            "     no_pain      0.908     0.775     0.836       102\n",
            "\n",
            "    accuracy                          0.727       132\n",
            "   macro avg      0.563     0.646     0.579       132\n",
            "weighted avg      0.797     0.727     0.752       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  1  3]\n",
            " [ 4 10  5]\n",
            " [14  9 79]]\n",
            "Epoch 07: train loss 0.3531 f1 0.5678 acc 0.5822 | val loss 0.3383 f1 0.5792 acc 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.304     0.636     0.412        11\n",
            "    low_pain      0.474     0.474     0.474        19\n",
            "     no_pain      0.922     0.814     0.865       102\n",
            "\n",
            "    accuracy                          0.750       132\n",
            "   macro avg      0.567     0.641     0.583       132\n",
            "weighted avg      0.806     0.750     0.771       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  1  3]\n",
            " [ 6  9  4]\n",
            " [10  9 83]]\n",
            "Epoch 08: train loss 0.2794 f1 0.6732 acc 0.6786 | val loss 0.3273 f1 0.5833 acc 0.7500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.455     0.476        11\n",
            "    low_pain      0.526     0.526     0.526        19\n",
            "     no_pain      0.903     0.912     0.907       102\n",
            "\n",
            "    accuracy                          0.818       132\n",
            "   macro avg      0.643     0.631     0.637       132\n",
            "weighted avg      0.815     0.818     0.817       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 3 10  6]\n",
            " [ 2  7 93]]\n",
            "Epoch 09: train loss 0.2128 f1 0.7450 acc 0.7448 | val loss 0.2440 f1 0.6366 acc 0.8182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.600     0.545     0.571        11\n",
            "    low_pain      0.571     0.632     0.600        19\n",
            "     no_pain      0.921     0.912     0.916       102\n",
            "\n",
            "    accuracy                          0.841       132\n",
            "   macro avg      0.697     0.696     0.696       132\n",
            "weighted avg      0.844     0.841     0.842       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  2  3]\n",
            " [ 2 12  5]\n",
            " [ 2  7 93]]\n",
            "Epoch 10: train loss 0.1660 f1 0.8193 acc 0.8223 | val loss 0.2343 f1 0.6959 acc 0.8409\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.800     0.727     0.762        11\n",
            "    low_pain      0.700     0.737     0.718        19\n",
            "     no_pain      0.931     0.931     0.931       102\n",
            "\n",
            "    accuracy                          0.886       132\n",
            "   macro avg      0.810     0.798     0.804       132\n",
            "weighted avg      0.887     0.886     0.887       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8  0  3]\n",
            " [ 1 14  4]\n",
            " [ 1  6 95]]\n",
            "Epoch 11: train loss 0.1153 f1 0.8455 acc 0.8469 | val loss 0.1950 f1 0.8037 acc 0.8864\n",
            "Epoch 12: train loss 0.1137 f1 0.8785 acc 0.8790 | val loss 0.2194 f1 0.7848 acc 0.8864\n",
            "Epoch 13: train loss 0.0671 f1 0.9283 acc 0.9282 | val loss 0.2325 f1 0.7858 acc 0.8864\n",
            "Epoch 14: train loss 0.0495 f1 0.9416 acc 0.9414 | val loss 0.2347 f1 0.7693 acc 0.8712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.875     0.636     0.737        11\n",
            "    low_pain      0.667     0.842     0.744        19\n",
            "     no_pain      0.960     0.941     0.950       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.834     0.807     0.811       132\n",
            "weighted avg      0.911     0.902     0.903       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 1 16  2]\n",
            " [ 0  6 96]]\n",
            "Epoch 15: train loss 0.0668 f1 0.9337 acc 0.9338 | val loss 0.2441 f1 0.8105 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.818     0.818     0.818        11\n",
            "    low_pain      0.682     0.789     0.732        19\n",
            "     no_pain      0.960     0.931     0.945       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.820     0.846     0.832       132\n",
            "weighted avg      0.908     0.902     0.904       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  1  1]\n",
            " [ 1 15  3]\n",
            " [ 1  6 95]]\n",
            "Epoch 16: train loss 0.0771 f1 0.9015 acc 0.9017 | val loss 0.2225 f1 0.8317 acc 0.9015\n",
            "Epoch 17: train loss 0.0382 f1 0.9600 acc 0.9603 | val loss 0.2670 f1 0.7819 acc 0.8864\n",
            "Epoch 18: train loss 0.0504 f1 0.9350 acc 0.9357 | val loss 0.2482 f1 0.8251 acc 0.9015\n",
            "Epoch 19: train loss 0.0283 f1 0.9653 acc 0.9660 | val loss 0.2327 f1 0.8051 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.875     0.636     0.737        11\n",
            "    low_pain      0.667     0.842     0.744        19\n",
            "     no_pain      0.960     0.941     0.950       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.834     0.807     0.811       132\n",
            "weighted avg      0.911     0.902     0.903       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 1 16  2]\n",
            " [ 0  6 96]]\n",
            "Epoch 20: train loss 0.0341 f1 0.9543 acc 0.9546 | val loss 0.2683 f1 0.8105 acc 0.9015\n",
            "Epoch 21: train loss 0.0288 f1 0.9678 acc 0.9679 | val loss 0.3005 f1 0.7634 acc 0.8788\n",
            "Epoch 22: train loss 0.0272 f1 0.9714 acc 0.9716 | val loss 0.2615 f1 0.8210 acc 0.9091\n",
            "Epoch 23: train loss 0.0262 f1 0.9719 acc 0.9716 | val loss 0.2258 f1 0.7781 acc 0.8864\n",
            "Epoch 24: train loss 0.0278 f1 0.9698 acc 0.9698 | val loss 0.2793 f1 0.7585 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.583     0.636     0.609        11\n",
            "    low_pain      0.739     0.895     0.810        19\n",
            "     no_pain      0.979     0.931     0.955       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.767     0.821     0.791       132\n",
            "weighted avg      0.912     0.902     0.905       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 2 17  0]\n",
            " [ 3  4 95]]\n",
            "Epoch 25: train loss 0.0128 f1 0.9849 acc 0.9849 | val loss 0.2560 f1 0.7910 acc 0.9015\n",
            "Epoch 26: train loss 0.0125 f1 0.9869 acc 0.9868 | val loss 0.2423 f1 0.8292 acc 0.9167\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 4/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.091     0.154        11\n",
            "    low_pain      0.138     0.947     0.242        19\n",
            "     no_pain      0.000     0.000     0.000       102\n",
            "\n",
            "    accuracy                          0.144       132\n",
            "   macro avg      0.213     0.346     0.132       132\n",
            "weighted avg      0.062     0.144     0.048       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  1  10   0]\n",
            " [  1  18   0]\n",
            " [  0 102   0]]\n",
            "Epoch 01: train loss 0.4882 f1 0.2810 acc 0.3346 | val loss 0.4995 f1 0.1318 acc 0.1439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      1.000     0.091     0.167        11\n",
            "    low_pain      0.150     1.000     0.260        19\n",
            "     no_pain      1.000     0.039     0.075       102\n",
            "\n",
            "    accuracy                          0.182       132\n",
            "   macro avg      0.717     0.377     0.167       132\n",
            "weighted avg      0.878     0.182     0.110       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 1 10  0]\n",
            " [ 0 19  0]\n",
            " [ 0 98  4]]\n",
            "Epoch 02: train loss 0.4774 f1 0.3697 acc 0.3894 | val loss 0.4850 f1 0.1675 acc 0.1818\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.250     0.091     0.133        11\n",
            "    low_pain      0.205     0.895     0.333        19\n",
            "     no_pain      0.911     0.402     0.558       102\n",
            "\n",
            "    accuracy                          0.447       132\n",
            "   macro avg      0.455     0.463     0.341       132\n",
            "weighted avg      0.754     0.447     0.490       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 1  8  2]\n",
            " [ 0 17  2]\n",
            " [ 3 58 41]]\n",
            "Epoch 03: train loss 0.4679 f1 0.4310 acc 0.4367 | val loss 0.4720 f1 0.3415 acc 0.4470\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.250     0.455     0.323        11\n",
            "    low_pain      0.350     0.368     0.359        19\n",
            "     no_pain      0.880     0.794     0.835       102\n",
            "\n",
            "    accuracy                          0.705       132\n",
            "   macro avg      0.493     0.539     0.506       132\n",
            "weighted avg      0.752     0.705     0.724       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 5  7  7]\n",
            " [10 11 81]]\n",
            "Epoch 04: train loss 0.4454 f1 0.5342 acc 0.5331 | val loss 0.4413 f1 0.5055 acc 0.7045\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.192     0.455     0.270        11\n",
            "    low_pain      0.714     0.263     0.385        19\n",
            "     no_pain      0.879     0.853     0.866       102\n",
            "\n",
            "    accuracy                          0.735       132\n",
            "   macro avg      0.595     0.524     0.507       132\n",
            "weighted avg      0.798     0.735     0.747       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  1  5]\n",
            " [ 7  5  7]\n",
            " [14  1 87]]\n",
            "Epoch 05: train loss 0.4255 f1 0.5171 acc 0.5539 | val loss 0.3956 f1 0.5069 acc 0.7348\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.222     0.364     0.276        11\n",
            "    low_pain      0.571     0.421     0.485        19\n",
            "     no_pain      0.880     0.863     0.871       102\n",
            "\n",
            "    accuracy                          0.758       132\n",
            "   macro avg      0.558     0.549     0.544       132\n",
            "weighted avg      0.781     0.758     0.766       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 4  2  5]\n",
            " [ 4  8  7]\n",
            " [10  4 88]]\n",
            "Epoch 06: train loss 0.3781 f1 0.5967 acc 0.6276 | val loss 0.3549 f1 0.5440 acc 0.7576\n",
            "Epoch 07: train loss 0.3418 f1 0.6196 acc 0.6333 | val loss 0.2740 f1 0.5163 acc 0.7727\n",
            "Epoch 08: train loss 0.3058 f1 0.6742 acc 0.6749 | val loss 0.2577 f1 0.5271 acc 0.7500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.417     0.455     0.435        11\n",
            "    low_pain      0.750     0.316     0.444        19\n",
            "     no_pain      0.866     0.951     0.907       102\n",
            "\n",
            "    accuracy                          0.818       132\n",
            "   macro avg      0.678     0.574     0.595       132\n",
            "weighted avg      0.812     0.818     0.801       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 2  6 11]\n",
            " [ 5  0 97]]\n",
            "Epoch 09: train loss 0.2406 f1 0.7374 acc 0.7372 | val loss 0.1624 f1 0.5953 acc 0.8182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.417     0.909     0.571        11\n",
            "    low_pain      0.824     0.737     0.778        19\n",
            "     no_pain      0.978     0.873     0.922       102\n",
            "\n",
            "    accuracy                          0.856       132\n",
            "   macro avg      0.739     0.839     0.757       132\n",
            "weighted avg      0.909     0.856     0.872       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[10  0  1]\n",
            " [ 4 14  1]\n",
            " [10  3 89]]\n",
            "Epoch 10: train loss 0.2075 f1 0.7371 acc 0.7372 | val loss 0.1615 f1 0.7572 acc 0.8561\n",
            "Epoch 11: train loss 0.1608 f1 0.8426 acc 0.8431 | val loss 0.1096 f1 0.7459 acc 0.8636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.583     0.636     0.609        11\n",
            "    low_pain      0.739     0.895     0.810        19\n",
            "     no_pain      0.990     0.941     0.965       102\n",
            "\n",
            "    accuracy                          0.909       132\n",
            "   macro avg      0.771     0.824     0.794       132\n",
            "weighted avg      0.920     0.909     0.913       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 1 17  1]\n",
            " [ 4  2 96]]\n",
            "Epoch 12: train loss 0.1080 f1 0.9016 acc 0.9017 | val loss 0.1085 f1 0.7943 acc 0.9091\n",
            "Epoch 13: train loss 0.1298 f1 0.8711 acc 0.8715 | val loss 0.1342 f1 0.7276 acc 0.8561\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.588     0.909     0.714        11\n",
            "    low_pain      0.708     0.895     0.791        19\n",
            "     no_pain      1.000     0.892     0.943       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.766     0.899     0.816       132\n",
            "weighted avg      0.924     0.894     0.902       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[10  1  0]\n",
            " [ 2 17  0]\n",
            " [ 5  6 91]]\n",
            "Epoch 14: train loss 0.0681 f1 0.9395 acc 0.9395 | val loss 0.1253 f1 0.8160 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.538     0.636     0.583        11\n",
            "    low_pain      0.762     0.842     0.800        19\n",
            "     no_pain      0.969     0.931     0.950       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.757     0.803     0.778       132\n",
            "weighted avg      0.904     0.894     0.898       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  4  0]\n",
            " [ 0 16  3]\n",
            " [ 6  1 95]]\n",
            "Epoch 15: train loss 0.0826 f1 0.9099 acc 0.9112 | val loss 0.1049 f1 0.7778 acc 0.8939\n",
            "Epoch 16: train loss 0.0711 f1 0.9287 acc 0.9282 | val loss 0.0768 f1 0.8022 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.636     0.636     0.636        11\n",
            "    low_pain      0.792     1.000     0.884        19\n",
            "     no_pain      0.990     0.941     0.965       102\n",
            "\n",
            "    accuracy                          0.924       132\n",
            "   macro avg      0.806     0.859     0.828       132\n",
            "weighted avg      0.932     0.924     0.926       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  3  1]\n",
            " [ 0 19  0]\n",
            " [ 4  2 96]]\n",
            "Epoch 17: train loss 0.0448 f1 0.9533 acc 0.9527 | val loss 0.0683 f1 0.8283 acc 0.9242\n",
            "Epoch 18: train loss 0.0440 f1 0.9340 acc 0.9338 | val loss 0.0981 f1 0.7692 acc 0.8939\n",
            "Epoch 19: train loss 0.0398 f1 0.9485 acc 0.9490 | val loss 0.1312 f1 0.7777 acc 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.583     0.636     0.609        11\n",
            "    low_pain      0.833     0.789     0.811        19\n",
            "     no_pain      0.961     0.961     0.961       102\n",
            "\n",
            "    accuracy                          0.909       132\n",
            "   macro avg      0.792     0.796     0.793       132\n",
            "weighted avg      0.911     0.909     0.910       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 2 15  2]\n",
            " [ 3  1 98]]\n",
            "Epoch 20: train loss 0.0434 f1 0.9650 acc 0.9660 | val loss 0.1264 f1 0.7934 acc 0.9091\n",
            "Epoch 21: train loss 0.0326 f1 0.9660 acc 0.9660 | val loss 0.1023 f1 0.8205 acc 0.9091\n",
            "Epoch 22: train loss 0.0267 f1 0.9622 acc 0.9622 | val loss 0.1234 f1 0.7812 acc 0.9091\n",
            "Epoch 23: train loss 0.0145 f1 0.9884 acc 0.9887 | val loss 0.1026 f1 0.7968 acc 0.8939\n",
            "Epoch 24: train loss 0.0304 f1 0.9754 acc 0.9754 | val loss 0.1449 f1 0.7825 acc 0.9015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.556     0.455     0.500        11\n",
            "    low_pain      0.850     0.895     0.872        19\n",
            "     no_pain      0.951     0.961     0.956       102\n",
            "\n",
            "    accuracy                          0.909       132\n",
            "   macro avg      0.786     0.770     0.776       132\n",
            "weighted avg      0.904     0.909     0.906       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  2  4]\n",
            " [ 1 17  1]\n",
            " [ 3  1 98]]\n",
            "Epoch 25: train loss 0.0198 f1 0.9681 acc 0.9679 | val loss 0.1269 f1 0.7760 acc 0.9091\n",
            "Epoch 26: train loss 0.0110 f1 0.9886 acc 0.9887 | val loss 0.1162 f1 0.7922 acc 0.9091\n",
            "Epoch 27: train loss 0.0252 f1 0.9643 acc 0.9641 | val loss 0.1294 f1 0.8060 acc 0.9091\n",
            "Early stopping.\n",
            "\n",
            "========== FOLD 5/5 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.083     1.000     0.154        11\n",
            "    low_pain      0.000     0.000     0.000        19\n",
            "     no_pain      0.000     0.000     0.000       102\n",
            "\n",
            "    accuracy                          0.083       132\n",
            "   macro avg      0.028     0.333     0.051       132\n",
            "weighted avg      0.007     0.083     0.013       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 11   0   0]\n",
            " [ 19   0   0]\n",
            " [102   0   0]]\n",
            "Epoch 01: train loss 0.4898 f1 0.2234 acc 0.3554 | val loss 0.5295 f1 0.0513 acc 0.0833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.086     0.818     0.155        11\n",
            "    low_pain      0.259     0.368     0.304        19\n",
            "     no_pain      0.000     0.000     0.000       102\n",
            "\n",
            "    accuracy                          0.121       132\n",
            "   macro avg      0.115     0.396     0.153       132\n",
            "weighted avg      0.044     0.121     0.057       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 9  2  0]\n",
            " [12  7  0]\n",
            " [84 18  0]]\n",
            "Epoch 02: train loss 0.4789 f1 0.2520 acc 0.3648 | val loss 0.5016 f1 0.1532 acc 0.1212\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.385     0.455     0.417        11\n",
            "    low_pain      0.250     0.895     0.391        19\n",
            "     no_pain      0.941     0.471     0.627       102\n",
            "\n",
            "    accuracy                          0.530       132\n",
            "   macro avg      0.525     0.607     0.478       132\n",
            "weighted avg      0.795     0.530     0.576       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  5  1]\n",
            " [ 0 17  2]\n",
            " [ 8 46 48]]\n",
            "Epoch 03: train loss 0.4714 f1 0.4315 acc 0.4386 | val loss 0.4786 f1 0.4783 acc 0.5303\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.545     0.545     0.545        11\n",
            "    low_pain      0.270     0.526     0.357        19\n",
            "     no_pain      0.917     0.755     0.828       102\n",
            "\n",
            "    accuracy                          0.705       132\n",
            "   macro avg      0.577     0.609     0.577       132\n",
            "weighted avg      0.793     0.705     0.737       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  4  1]\n",
            " [ 3 10  6]\n",
            " [ 2 23 77]]\n",
            "Epoch 04: train loss 0.4524 f1 0.5237 acc 0.5350 | val loss 0.4423 f1 0.5769 acc 0.7045\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.545     0.545     0.545        11\n",
            "    low_pain      0.303     0.526     0.385        19\n",
            "     no_pain      0.920     0.794     0.853       102\n",
            "\n",
            "    accuracy                          0.735       132\n",
            "   macro avg      0.590     0.622     0.594       132\n",
            "weighted avg      0.800     0.735     0.760       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  4  1]\n",
            " [ 3 10  6]\n",
            " [ 2 19 81]]\n",
            "Epoch 05: train loss 0.4252 f1 0.5470 acc 0.5690 | val loss 0.3985 f1 0.5942 acc 0.7348\n",
            "Epoch 06: train loss 0.3822 f1 0.5913 acc 0.5955 | val loss 0.3828 f1 0.5179 acc 0.6439\n",
            "Epoch 07: train loss 0.3152 f1 0.6781 acc 0.6786 | val loss 0.3182 f1 0.5781 acc 0.7652\n",
            "Epoch 08: train loss 0.2746 f1 0.6988 acc 0.7051 | val loss 0.2310 f1 0.5729 acc 0.8030\n",
            "Epoch 09: train loss 0.2033 f1 0.7788 acc 0.7807 | val loss 0.2353 f1 0.5260 acc 0.7424\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.412     0.636     0.500        11\n",
            "    low_pain      0.714     0.526     0.606        19\n",
            "     no_pain      0.911     0.902     0.906       102\n",
            "\n",
            "    accuracy                          0.826       132\n",
            "   macro avg      0.679     0.688     0.671       132\n",
            "weighted avg      0.841     0.826     0.829       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  2]\n",
            " [ 2 10  7]\n",
            " [ 8  2 92]]\n",
            "Epoch 10: train loss 0.1441 f1 0.8507 acc 0.8507 | val loss 0.2037 f1 0.6708 acc 0.8258\n",
            "Epoch 11: train loss 0.1131 f1 0.8920 acc 0.8922 | val loss 0.3019 f1 0.6462 acc 0.7576\n",
            "Epoch 12: train loss 0.0903 f1 0.8978 acc 0.8979 | val loss 0.2506 f1 0.6623 acc 0.8106\n",
            "Epoch 13: train loss 0.0736 f1 0.9225 acc 0.9225 | val loss 0.2858 f1 0.6639 acc 0.8333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.667     0.545     0.600        11\n",
            "    low_pain      0.778     0.737     0.757        19\n",
            "     no_pain      0.924     0.951     0.937       102\n",
            "\n",
            "    accuracy                          0.886       132\n",
            "   macro avg      0.789     0.744     0.765       132\n",
            "weighted avg      0.881     0.886     0.883       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  1  4]\n",
            " [ 1 14  4]\n",
            " [ 2  3 97]]\n",
            "Epoch 14: train loss 0.0357 f1 0.9774 acc 0.9773 | val loss 0.2209 f1 0.7647 acc 0.8864\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.833     0.455     0.588        11\n",
            "    low_pain      0.812     0.684     0.743        19\n",
            "     no_pain      0.900     0.971     0.934       102\n",
            "\n",
            "    accuracy                          0.886       132\n",
            "   macro avg      0.849     0.703     0.755       132\n",
            "weighted avg      0.882     0.886     0.878       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  1  5]\n",
            " [ 0 13  6]\n",
            " [ 1  2 99]]\n",
            "Epoch 15: train loss 0.0509 f1 0.9494 acc 0.9490 | val loss 0.2339 f1 0.7550 acc 0.8864\n",
            "Epoch 16: train loss 0.0877 f1 0.9130 acc 0.9149 | val loss 0.3201 f1 0.5979 acc 0.7121\n",
            "Epoch 17: train loss 0.0629 f1 0.9325 acc 0.9319 | val loss 0.2451 f1 0.7323 acc 0.8864\n",
            "Epoch 18: train loss 0.0564 f1 0.9355 acc 0.9357 | val loss 0.2383 f1 0.6818 acc 0.8333\n",
            "Epoch 19: train loss 0.0698 f1 0.9247 acc 0.9244 | val loss 0.2660 f1 0.6296 acc 0.7955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.444     0.364     0.400        11\n",
            "    low_pain      0.625     0.789     0.698        19\n",
            "     no_pain      0.919     0.892     0.905       102\n",
            "\n",
            "    accuracy                          0.833       132\n",
            "   macro avg      0.663     0.682     0.668       132\n",
            "weighted avg      0.837     0.833     0.833       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 4  3  4]\n",
            " [ 0 15  4]\n",
            " [ 5  6 91]]\n",
            "Epoch 20: train loss 0.0300 f1 0.9636 acc 0.9641 | val loss 0.2372 f1 0.6677 acc 0.8333\n",
            "Epoch 21: train loss 0.0459 f1 0.9527 acc 0.9527 | val loss 0.2420 f1 0.6948 acc 0.8258\n",
            "Epoch 22: train loss 0.0404 f1 0.9583 acc 0.9584 | val loss 0.2472 f1 0.6660 acc 0.7955\n",
            "Epoch 23: train loss 0.0324 f1 0.9686 acc 0.9679 | val loss 0.2199 f1 0.6961 acc 0.8333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.714     0.455     0.556        11\n",
            "    low_pain      0.762     0.842     0.800        19\n",
            "     no_pain      0.933     0.951     0.942       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.803     0.749     0.766       132\n",
            "weighted avg      0.890     0.894     0.889       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 5  1  5]\n",
            " [ 1 16  2]\n",
            " [ 1  4 97]]\n",
            "Epoch 24: train loss 0.0332 f1 0.9587 acc 0.9584 | val loss 0.1628 f1 0.7658 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.583     0.636     0.609        11\n",
            "    low_pain      0.684     0.684     0.684        19\n",
            "     no_pain      0.921     0.912     0.916       102\n",
            "\n",
            "    accuracy                          0.856       132\n",
            "   macro avg      0.729     0.744     0.736       132\n",
            "weighted avg      0.859     0.856     0.857       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  1  3]\n",
            " [ 1 13  5]\n",
            " [ 4  5 93]]\n",
            "Epoch 25: train loss 0.0307 f1 0.9549 acc 0.9584 | val loss 0.2266 f1 0.7364 acc 0.8561\n",
            "Epoch 26: train loss 0.0147 f1 0.9853 acc 0.9849 | val loss 0.2727 f1 0.6869 acc 0.8485\n",
            "Epoch 27: train loss 0.0244 f1 0.9682 acc 0.9679 | val loss 0.2399 f1 0.7400 acc 0.8864\n",
            "Epoch 28: train loss 0.0175 f1 0.9850 acc 0.9849 | val loss 0.2659 f1 0.7290 acc 0.8712\n",
            "Epoch 29: train loss 0.0071 f1 0.9923 acc 0.9924 | val loss 0.2609 f1 0.7441 acc 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.875     0.636     0.737        11\n",
            "    low_pain      0.857     0.632     0.727        19\n",
            "     no_pain      0.909     0.980     0.943       102\n",
            "\n",
            "    accuracy                          0.902       132\n",
            "   macro avg      0.880     0.749     0.803       132\n",
            "weighted avg      0.899     0.902     0.895       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[  7   1   3]\n",
            " [  0  12   7]\n",
            " [  1   1 100]]\n",
            "Epoch 30: train loss 0.0106 f1 0.9849 acc 0.9849 | val loss 0.2651 f1 0.8025 acc 0.9015\n",
            "Epoch 31: train loss 0.0084 f1 0.9924 acc 0.9924 | val loss 0.2593 f1 0.7640 acc 0.8788\n",
            "Epoch 32: train loss 0.0072 f1 0.9926 acc 0.9924 | val loss 0.2755 f1 0.7404 acc 0.8939\n",
            "Epoch 33: train loss 0.0099 f1 0.9867 acc 0.9868 | val loss 0.2975 f1 0.7436 acc 0.8788\n",
            "Epoch 34: train loss 0.0104 f1 0.9870 acc 0.9868 | val loss 0.2286 f1 0.7853 acc 0.8939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.636     0.636     0.636        11\n",
            "    low_pain      0.867     0.684     0.765        19\n",
            "     no_pain      0.925     0.961     0.942       102\n",
            "\n",
            "    accuracy                          0.894       132\n",
            "   macro avg      0.809     0.760     0.781       132\n",
            "weighted avg      0.892     0.894     0.891       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  1  3]\n",
            " [ 1 13  5]\n",
            " [ 3  1 98]]\n",
            "Epoch 35: train loss 0.0080 f1 0.9849 acc 0.9849 | val loss 0.3006 f1 0.7811 acc 0.8939\n",
            "Epoch 36: train loss 0.0130 f1 0.9812 acc 0.9811 | val loss 0.2647 f1 0.7563 acc 0.8788\n",
            "Epoch 37: train loss 0.0105 f1 0.9814 acc 0.9811 | val loss 0.2317 f1 0.7733 acc 0.8788\n",
            "Epoch 38: train loss 0.0048 f1 0.9963 acc 0.9962 | val loss 0.2657 f1 0.7497 acc 0.8636\n",
            "Epoch 39: train loss 0.0089 f1 0.9924 acc 0.9924 | val loss 0.3102 f1 0.7262 acc 0.8788\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   high_pain      0.500     0.545     0.522        11\n",
            "    low_pain      0.867     0.684     0.765        19\n",
            "     no_pain      0.924     0.951     0.937       102\n",
            "\n",
            "    accuracy                          0.879       132\n",
            "   macro avg      0.763     0.727     0.741       132\n",
            "weighted avg      0.880     0.879     0.878       132\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 6  1  4]\n",
            " [ 2 13  4]\n",
            " [ 4  1 97]]\n",
            "Epoch 40: train loss 0.0022 f1 1.0000 acc 1.0000 | val loss 0.3228 f1 0.7412 acc 0.8788\n",
            "Early stopping.\n",
            "\n",
            "OOF macro-F1: 0.8306 | OOF Acc: 0.9198\n",
            "Wrote submission.csv\n"
          ]
        }
      ],
      "source": [
        "# pirate_pain_baseline.py\n",
        "# Train-from-scratch baseline for Pirate Pain (multivariate time-series classification)\n",
        "# Requires: pandas, numpy, scikit-learn, torch, tqdm\n",
        "# Tested on CPU/MPS (Apple Silicon) and CUDA if available.\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# ---------------------------\n",
        "# Utils\n",
        "# ---------------------------\n",
        "def seed_everything(seed=42):\n",
        "    import random, os\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_device():\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "def fit_dyn_scaler_masked(X, lens, idx):\n",
        "    # X: [N,T,C], lens: [N], idx: train indices for this fold\n",
        "    C = X.shape[2]\n",
        "    chunks = [X[i, :int(lens[i]), :] for i in idx if int(lens[i]) > 0]\n",
        "    valid = np.concatenate(chunks, axis=0) if chunks else X.reshape(-1, C)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(valid.reshape(-1, C))\n",
        "    return scaler\n",
        "\n",
        "def transform_dyn_masked(X, lens, scaler):\n",
        "    # returns scaled X with padded tail set to 0.0\n",
        "    Y = np.zeros_like(X, dtype=np.float32)\n",
        "    for i in range(len(X)):\n",
        "        L = int(lens[i])\n",
        "        if L > 0:\n",
        "            Y[i, :L] = scaler.transform(X[i, :L])\n",
        "        # tail stays zeros\n",
        "    return Y\n",
        "\n",
        "# ---------------------------\n",
        "# Data shaping\n",
        "# ---------------------------\n",
        "def infer_columns(df):\n",
        "    id_col = \"sample_index\"\n",
        "    time_col = \"time\" if \"time\" in df.columns else None\n",
        "    static_candidates = [\"n_legs\",\"n_hands\",\"n_eyes\"]\n",
        "    static_cols = [c for c in static_candidates if c in df.columns]\n",
        "    ignore = set([id_col] + ([time_col] if time_col else []) + static_cols)\n",
        "    feature_cols = [c for c in df.columns if c not in ignore]\n",
        "    return id_col, time_col, static_cols, feature_cols\n",
        "\n",
        "def _numericize_features(df, cols):\n",
        "    \"\"\"Return a numeric version of df[cols], mapping common words to numbers and dropping all-NaN cols.\"\"\"\n",
        "    mapping = {\n",
        "        \"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4,\n",
        "        \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
        "        \"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0,\n",
        "        \"none\": None, \"null\": None, \"nan\": None, \"\": None\n",
        "    }\n",
        "    out = df[cols].copy()\n",
        "    for c in out.columns:\n",
        "        if out[c].dtype == object:\n",
        "            s = out[c].astype(str).str.strip().str.lower().replace(mapping)\n",
        "            out[c] = pd.to_numeric(s, errors=\"coerce\")\n",
        "        else:\n",
        "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
        "    keep = out.columns[out.notna().any()].tolist()\n",
        "    dropped = [c for c in out.columns if c not in keep]\n",
        "    if dropped:\n",
        "        print(f\"[build_sequences] Dropping non-numeric/all-NaN features: {dropped[:15]}\" + (\" ...\" if len(dropped) > 15 else \"\"))\n",
        "    return out[keep], keep\n",
        "\n",
        "def build_sequences(X_df, y_df=None, expect_T=180):\n",
        "    id_col = \"sample_index\"\n",
        "    time_col = \"time\" if \"time\" in X_df.columns else None\n",
        "    static_candidates = [\"n_legs\",\"n_hands\",\"n_eyes\"]\n",
        "    static_cols = [c for c in static_candidates if c in X_df.columns]\n",
        "    ignore = set([id_col] + ([time_col] if time_col else []) + static_cols)\n",
        "    ignore |= {\"label\",\"target\",\"class\"}\n",
        "    raw_dyn_cols = [c for c in X_df.columns if c not in ignore]\n",
        "\n",
        "    if time_col is not None:\n",
        "        X_df = X_df.sort_values([id_col, time_col])\n",
        "    else:\n",
        "        X_df = X_df.sort_values([id_col])\n",
        "\n",
        "    dyn_numeric, dyn_cols = _numericize_features(X_df, raw_dyn_cols)\n",
        "    for c in dyn_cols:\n",
        "        X_df[c] = dyn_numeric[c].values\n",
        "\n",
        "    groups = X_df.groupby(id_col)\n",
        "    sample_ids = []\n",
        "    lengths = []                     # <--- NEW\n",
        "    X_dyn_list, X_static_list = [], []\n",
        "\n",
        "    def fix_len(arr, T):\n",
        "        n = arr.shape[0]\n",
        "        if n == T: return arr, \"ok\"\n",
        "        if n > T:  return arr[-T:, :], \"trunc\"\n",
        "        pad = np.repeat(arr[-1:, :], T - n, axis=0)\n",
        "        return np.concatenate([arr, pad], axis=0), \"pad\"\n",
        "\n",
        "    n_ok = n_pad = n_trunc = 0\n",
        "\n",
        "    for s_id, g in groups:\n",
        "        g_dyn = g[dyn_cols].ffill().bfill().fillna(0.0)\n",
        "        arr0 = g_dyn.to_numpy(dtype=np.float32)\n",
        "        true_len = arr0.shape[0]           # <--- NEW (pre padding)\n",
        "        arr, tag = fix_len(arr0, expect_T)\n",
        "        if tag == \"ok\": n_ok += 1\n",
        "        elif tag == \"pad\": n_pad += 1\n",
        "        else: n_trunc += 1\n",
        "\n",
        "        if len(static_cols) > 0:\n",
        "            s0 = g[static_cols].iloc[0]\n",
        "            s0 = s0.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "            s = s0.to_numpy(dtype=np.float32)\n",
        "        else:\n",
        "            s = np.zeros(0, dtype=np.float32)\n",
        "\n",
        "        sample_ids.append(s_id)\n",
        "        lengths.append(min(true_len, expect_T))   # cap to T\n",
        "        X_dyn_list.append(arr)\n",
        "        X_static_list.append(s)\n",
        "\n",
        "    if len(X_dyn_list) == 0:\n",
        "        raise ValueError(\"No sequences assembled. Check 'sample_index' and that each sample has rows.\")\n",
        "\n",
        "    X_dyn = np.stack(X_dyn_list, axis=0)\n",
        "    X_static = np.stack(X_static_list, axis=0)\n",
        "    sample_ids = np.array(sample_ids)\n",
        "    lengths = np.array(lengths, dtype=np.int64)   # <--- NEW\n",
        "\n",
        "    print(f\"[build_sequences] Target T={expect_T} -> ok:{n_ok}  padded:{n_pad}  truncated:{n_trunc}\")\n",
        "\n",
        "    y = None\n",
        "    classes = None\n",
        "    if y_df is not None:\n",
        "        label_cols = [c for c in y_df.columns if c != \"sample_index\"]\n",
        "        assert len(label_cols) == 1, \"y_train must have one target column besides sample_index\"\n",
        "        target_col = label_cols[0]\n",
        "        y_map = y_df.set_index(\"sample_index\")[target_col].to_dict()\n",
        "        y_raw = [y_map[s] for s in sample_ids]\n",
        "        classes = sorted(list(set(y_raw)))\n",
        "        class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "        y = np.array([class_to_idx[v] for v in y_raw], dtype=np.int64)\n",
        "\n",
        "    return X_dyn, X_static, sample_ids, lengths, y, classes, dyn_cols, static_cols\n",
        "\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X_dyn, X_static, lengths, y=None, train=False, aug_p=0.0):\n",
        "        self.X_dyn = X_dyn\n",
        "        self.X_static = X_static\n",
        "        self.lengths = lengths\n",
        "        self.y = y\n",
        "        self.train = train\n",
        "        self.aug_p = aug_p\n",
        "\n",
        "    def _augment(self, x):  # x: [T,C]\n",
        "        # light, safe defaults\n",
        "        import numpy as np\n",
        "        T, C = x.shape\n",
        "        if np.random.rand() < self.aug_p:\n",
        "            x = x + np.random.normal(0, 0.01, size=x.shape)        # jitter\n",
        "        if np.random.rand() < self.aug_p:\n",
        "            scale = 1.0 + np.random.normal(0, 0.05, size=(1, C))   # channel scaling\n",
        "            x = x * scale\n",
        "        if np.random.rand() < self.aug_p:\n",
        "            w = np.random.randint(5, 20)\n",
        "            s = np.random.randint(0, T - w)\n",
        "            x[s:s+w, :] = 0                                        # time mask\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X_dyn.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_dyn = self.X_dyn[idx]      # np array [T,C]\n",
        "        if self.train and self.aug_p > 0:\n",
        "            x_dyn = self._augment(x_dyn.copy()).astype(np.float32)\n",
        "        x_dyn = torch.from_numpy(x_dyn)\n",
        "        x_static = torch.from_numpy(self.X_static[idx])\n",
        "        length = int(self.lengths[idx])\n",
        "        if self.y is None:\n",
        "            return x_dyn, x_static, length\n",
        "        return x_dyn, x_static, length, int(self.y[idx])\n",
        "\n",
        "class AttnPool(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(nn.LayerNorm(d), nn.Linear(d, d//2), nn.Tanh(), nn.Linear(d//2, 1))\n",
        "    def forward(self, x, mask):                 # x:[B,T,D], mask:[B,T] bool\n",
        "        a = self.proj(x).squeeze(-1)            # [B,T]\n",
        "        a = a.masked_fill(~mask, float('-inf'))\n",
        "        w = a.softmax(dim=1)                    # [B,T]\n",
        "        return (x * w.unsqueeze(-1)).sum(1)     # [B,D]\n",
        "\n",
        "# ---------------------------\n",
        "# Model (CNN + BiGRU head)\n",
        "# ---------------------------\n",
        "class PirateNet(nn.Module):\n",
        "    def __init__(self, c_dyn, c_static, hidden=64, rnn_layers=1, num_classes=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(c_dyn, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv1d(64, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.rnn = nn.GRU(input_size=64, hidden_size=hidden, num_layers=rnn_layers,\n",
        "                          batch_first=True, bidirectional=True)\n",
        "        self.attn = AttnPool(2*hidden)\n",
        "\n",
        "        static_out = 32 if c_static > 0 else 0\n",
        "        if c_static > 0:\n",
        "            self.static_mlp = nn.Sequential(\n",
        "                nn.LayerNorm(c_static),\n",
        "                nn.Linear(c_static, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(64, static_out),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "\n",
        "        head_in = (2*hidden)*3 + static_out  # mean + max + attn\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(head_in, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dyn, x_static, lengths):\n",
        "        # x_dyn: [B,T,C] -> conv -> [B,T,64] -> BiGRU -> [B,T,2H]\n",
        "        x = self.conv(x_dyn.transpose(1,2)).transpose(1,2)\n",
        "        out, _ = self.rnn(x)\n",
        "\n",
        "        B, T, D = out.shape\n",
        "        device = out.device\n",
        "        # mask: True on real steps, False on padding\n",
        "        lens = lengths.to(device)\n",
        "        ar = torch.arange(T, device=device).unsqueeze(0).expand(B, T)\n",
        "        mask = ar < lens.unsqueeze(1)                         # [B,T] bool\n",
        "\n",
        "        # masked pools\n",
        "        h_mean = (out * mask.unsqueeze(-1)).sum(1) / torch.clamp(lens.unsqueeze(1), min=1).to(out.dtype)\n",
        "        out_masked = out.masked_fill(~mask.unsqueeze(-1), float('-inf'))\n",
        "        h_max = out_masked.max(1).values\n",
        "        h_attn = self.attn(out, mask)\n",
        "\n",
        "        feat = torch.cat([h_mean, h_max, h_attn], dim=1)\n",
        "        if x_static is not None and x_static.shape[1] > 0:\n",
        "            s = self.static_mlp(x_static)\n",
        "            feat = torch.cat([feat, s], dim=1)\n",
        "        return self.head(feat)\n",
        "\n",
        "# ---------------------------\n",
        "# Training / Evaluation\n",
        "# ---------------------------\n",
        "def train_one_epoch(model, loader, optimizer, device, criterion, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    preds, trues = [], []\n",
        "    for batch in loader:\n",
        "        xb_dyn, xb_static, xlens, yb = batch\n",
        "        xb_dyn = xb_dyn.to(device)\n",
        "        xb_static = xb_static.to(device)\n",
        "        xlens = torch.as_tensor(xlens, device=device)\n",
        "        yb = torch.as_tensor(yb, device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb_dyn, xb_static, xlens)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item() * yb.size(0)\n",
        "        preds.append(logits.detach().softmax(dim=1).cpu().numpy())\n",
        "        trues.append(yb.detach().cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds); trues = np.concatenate(trues)\n",
        "    f1 = f1_score(trues, preds.argmax(1), average=\"macro\")\n",
        "    acc = accuracy_score(trues, preds.argmax(1))\n",
        "    return total_loss / len(loader.dataset), f1, acc\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds, trues = [], []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 3:     # test loader\n",
        "            xb_dyn, xb_static, xlens = batch\n",
        "            yb = None\n",
        "        else:\n",
        "            xb_dyn, xb_static, xlens, yb = batch\n",
        "            yb = torch.as_tensor(yb, device=device)\n",
        "        xb_dyn = xb_dyn.to(device)\n",
        "        xb_static = xb_static.to(device)\n",
        "        xlens = torch.as_tensor(xlens, device=device)\n",
        "\n",
        "        logits = model(xb_dyn, xb_static, xlens)\n",
        "        if yb is not None:\n",
        "            loss = criterion(logits, yb)\n",
        "            total_loss += loss.item() * yb.size(0)\n",
        "            trues.append(yb.detach().cpu().numpy())\n",
        "        preds.append(logits.detach().softmax(dim=1).cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    if trues:\n",
        "        trues = np.concatenate(trues)\n",
        "        f1 = f1_score(trues, preds.argmax(1), average=\"macro\")\n",
        "        acc = accuracy_score(trues, preds.argmax(1))\n",
        "        return total_loss / len(loader.dataset), f1, acc, preds\n",
        "    return None, None, None, preds\n",
        "\n",
        "\n",
        "def add_deltas(X):  # X: [N,T,C]\n",
        "    d1 = np.diff(X, axis=1, prepend=X[:, :1, :])\n",
        "    d2 = np.diff(d1, axis=1, prepend=d1[:, :1, :])\n",
        "    return np.concatenate([X, d1, d2], axis=2)\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, targets):\n",
        "        ce = nn.functional.cross_entropy(logits, targets, weight=self.alpha, reduction='none')\n",
        "        pt = torch.softmax(logits, dim=1).gather(1, targets.unsqueeze(1)).squeeze(1)\n",
        "        loss = ((1 - pt).clamp_min(1e-6) ** self.gamma) * ce\n",
        "        return loss.mean() if self.reduction=='mean' else loss.sum()\n",
        "\n",
        "# ---------------------------\n",
        "# Main\n",
        "# ---------------------------\n",
        "def main(args):\n",
        "    seed_everything(args.seed)\n",
        "    device = get_device()\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load data\n",
        "    X_train = pd.read_csv(\"pirate_pain_train.csv\")\n",
        "    y_train = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
        "    X_test  = pd.read_csv(\"pirate_pain_test.csv\")\n",
        "\n",
        "    # Build sequences\n",
        "    Xdyn_tr, Xsta_tr, ids_tr, len_tr, y, classes, dyn_cols, static_cols = build_sequences(X_train, y_train, expect_T=180)\n",
        "    Xdyn_te, Xsta_te, ids_te, len_te, _, _, _, _ = build_sequences(X_test, None, expect_T=180)\n",
        "    num_classes = len(classes)\n",
        "    Xdyn_tr = add_deltas(Xdyn_tr)\n",
        "    Xdyn_te = add_deltas(Xdyn_te)\n",
        "    print(f\"Train sequences: {len(ids_tr)}  Test sequences: {len(ids_te)}\")\n",
        "    print(f\"Dynamic channels: {Xdyn_tr.shape[-1]}  Static dims: {Xsta_tr.shape[-1]}  Classes: {classes}\")\n",
        "\n",
        "    # CV setup\n",
        "    skf = StratifiedKFold(n_splits=args.folds, shuffle=True, random_state=args.seed)\n",
        "\n",
        "    # OOF storage\n",
        "    oof_pred = np.zeros((len(ids_tr), num_classes), dtype=np.float32)\n",
        "    test_pred_folds = []\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(ids_tr, y), start=1):\n",
        "        print(f\"\\n========== FOLD {fold}/{args.folds} ==========\")\n",
        "        # Fit scalers on train fold ONLY (flatten over time for per-feature scaling)\n",
        "        T, C = Xdyn_tr.shape[1], Xdyn_tr.shape[2]\n",
        "        # --- Dynamic features: fit on real steps only; zero padded tail ---\n",
        "        dyn_scaler = fit_dyn_scaler_masked(Xdyn_tr, len_tr, tr_idx)\n",
        "        Xdyn_tr_scaled = transform_dyn_masked(Xdyn_tr, len_tr, dyn_scaler)\n",
        "        Xdyn_te_scaled = transform_dyn_masked(Xdyn_te, len_te, dyn_scaler)\n",
        "\n",
        "        if Xsta_tr.shape[1] > 0:\n",
        "            sta_scaler = StandardScaler()\n",
        "            sta_scaler.fit(Xsta_tr[tr_idx])\n",
        "            Xsta_tr_scaled = sta_scaler.transform(Xsta_tr)\n",
        "            Xsta_te_scaled = sta_scaler.transform(Xsta_te)\n",
        "        else:\n",
        "            Xsta_tr_scaled = Xsta_tr\n",
        "            Xsta_te_scaled = Xsta_te\n",
        "\n",
        "\n",
        "        # Loss (class weights if imbalance)\n",
        "        class_counts = np.bincount(y[tr_idx], minlength=num_classes) + 1\n",
        "        sample_w = (1.0 / class_counts)[y[tr_idx]]   # per-sample weight by inverse class freq\n",
        "        sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Datasets & loaders\n",
        "        ds_tr = SequenceDataset(Xdyn_tr_scaled[tr_idx], Xsta_tr_scaled[tr_idx], len_tr[tr_idx], y[tr_idx], train=True, aug_p=0.5)\n",
        "        ds_va = SequenceDataset(Xdyn_tr_scaled[va_idx], Xsta_tr_scaled[va_idx], len_tr[va_idx], y[va_idx], train=False)\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=args.batch_size, sampler=sampler, num_workers=0, drop_last=False)\n",
        "        dl_va = DataLoader(ds_va, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
        "\n",
        "        # Model\n",
        "        model = PirateNet(c_dyn=C, c_static=Xsta_tr.shape[1], hidden=args.hidden, rnn_layers=1,\n",
        "                          num_classes=num_classes, dropout=args.dropout).to(device)\n",
        "\n",
        "\n",
        "        # normalize to mean=1 so loss scale stays reasonable\n",
        "        inv = class_counts.sum() / class_counts\n",
        "        inv = inv / inv.mean()\n",
        "        class_weights = torch.tensor(inv, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "        #criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device))\n",
        "        #criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.0)  # fallback to 0 if your torch is old  (otherwise 0.05)\n",
        "        criterion = FocalLoss(alpha=None, gamma=2.0)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "        #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, epochs=args.epochs, steps_per_epoch=len(dl_tr))\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, epochs=args.epochs, steps_per_epoch=len(dl_tr),\n",
        "                                                        pct_start=0.3, div_factor=10.0, final_div_factor=100.0)\n",
        "\n",
        "        # Training loop with early stopping on macro-F1\n",
        "        best_f1, patience_left = -1.0, args.patience\n",
        "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}  # init in case no improvement\n",
        "\n",
        "\n",
        "        for epoch in range(1, args.epochs+1):\n",
        "          tr_loss, tr_f1, tr_acc = train_one_epoch(model, dl_tr, optimizer, device, criterion, scheduler)\n",
        "          va_loss, va_f1, va_acc, va_pred = evaluate(model, dl_va, device, criterion)\n",
        "\n",
        "          if (epoch % 5 == 0) or (va_f1 > best_f1 + 1e-5):\n",
        "              y_true = y[va_idx]\n",
        "              y_hat  = va_pred.argmax(1)\n",
        "              print(classification_report(y_true, y_hat, target_names=classes, digits=3))\n",
        "              print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_hat))\n",
        "\n",
        "          print(f\"Epoch {epoch:02d}: \"\n",
        "                f\"train loss {tr_loss:.4f} f1 {tr_f1:.4f} acc {tr_acc:.4f} | \"\n",
        "                f\"val loss {va_loss:.4f} f1 {va_f1:.4f} acc {va_acc:.4f}\")\n",
        "\n",
        "          if va_f1 > best_f1 + 1e-5:\n",
        "              best_f1 = va_f1\n",
        "              best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "              patience_left = args.patience\n",
        "          else:\n",
        "              patience_left -= 1\n",
        "              if patience_left <= 0:\n",
        "                  print(\"Early stopping.\")\n",
        "                  break\n",
        "\n",
        "        # Load best\n",
        "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
        "\n",
        "        # Store OOF predictions\n",
        "        _, _, _, va_pred = evaluate(model, dl_va, device, criterion)\n",
        "        oof_pred[va_idx] = va_pred\n",
        "\n",
        "        # Predict test for this fold\n",
        "        dl_te = DataLoader(SequenceDataset(Xdyn_te_scaled, Xsta_te_scaled, len_te, None), batch_size=args.batch_size, shuffle=False)\n",
        "        _, _, _, te_pred = evaluate(model, dl_te, device, criterion)\n",
        "        test_pred_folds.append(te_pred)\n",
        "\n",
        "    # Report OOF score\n",
        "    oof_labels = y\n",
        "    oof_f1 = f1_score(oof_labels, oof_pred.argmax(1), average=\"macro\")\n",
        "    oof_acc = accuracy_score(oof_labels, oof_pred.argmax(1))\n",
        "    print(f\"\\nOOF macro-F1: {oof_f1:.4f} | OOF Acc: {oof_acc:.4f}\")\n",
        "\n",
        "    # Average test predictions across folds\n",
        "    test_pred = np.mean(np.stack(test_pred_folds, axis=0), axis=0)  # [N_test, K]\n",
        "\n",
        "    # Write OOF preds (optional)\n",
        "    pd.DataFrame({\n",
        "        \"sample_index\": ids_tr,\n",
        "        **{f\"prob_{cls}\": oof_pred[:, i] for i, cls in enumerate(classes)},\n",
        "        \"oof_pred\": [classes[i] for i in oof_pred.argmax(1)],\n",
        "        \"target\": [classes[i] for i in oof_labels]\n",
        "    }).to_csv(\"oof_predictions.csv\", index=False)\n",
        "\n",
        "    # Submission: match sample_submission columns if available\n",
        "    submit_col_id = \"sample_index\"\n",
        "    # Try to read sample submission for correct column names/order\n",
        "    label_col_name = \"label\"\n",
        "    if os.path.exists(\"sample_submission.csv\"):\n",
        "        sub_template = pd.read_csv(\"sample_submission.csv\")\n",
        "        submit_col_id = [c for c in sub_template.columns if c != label_col_name][0] if label_col_name in sub_template.columns else \"sample_index\"\n",
        "        if label_col_name not in sub_template.columns:\n",
        "            # try to detect\n",
        "            non_id = [c for c in sub_template.columns if c != submit_col_id]\n",
        "            if len(non_id) == 1:\n",
        "                label_col_name = non_id[0]\n",
        "    test_pred_labels = [classes[i] for i in test_pred.argmax(1)]\n",
        "    submission = pd.DataFrame({submit_col_id: ids_te, label_col_name: test_pred_labels})\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"Wrote submission.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--epochs\", type=int, default=60)\n",
        "    p.add_argument(\"--batch_size\", type=int, default=64)\n",
        "    p.add_argument(\"--folds\", type=int, default=5)\n",
        "    p.add_argument(\"--hidden\", type=int, default=64)\n",
        "    p.add_argument(\"--dropout\", type=float, default=0.2)\n",
        "    p.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    p.add_argument(\"--weight_decay\", type=float, default=1e-2)\n",
        "    p.add_argument(\"--patience\", type=int, default=10)\n",
        "    p.add_argument(\"--seed\", type=int, default=42)\n",
        "    args, _ = p.parse_known_args()  # ignores Jupyter/Colab's extra -f argument\n",
        "    main(args)"
      ]
    }
  ]
}