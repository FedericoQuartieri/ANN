{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Setup, imports, scelta esperimento\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add local_lib to path BEFORE importing torch and other packages\n",
    "BASE_DIR = os.getcwd()\n",
    "LOCAL_LIB = os.path.join(BASE_DIR, 'local_lib')\n",
    "if os.path.exists(LOCAL_LIB) and LOCAL_LIB not in sys.path:\n",
    "    sys.path.insert(0, LOCAL_LIB)\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "    PROJECT_ROOT = \"/content/drive/MyDrive/[2025-2026] AN2DL/challenge2\"\n",
    "else:\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Working dir:\", os.getcwd())\n",
    "\n",
    "# Force reload of config module to get latest changes\n",
    "import importlib\n",
    "if 'includes.config' in sys.modules:\n",
    "    importlib.reload(sys.modules['includes.config'])\n",
    "\n",
    "from includes.config import TrainingConfig, GRID_SEARCH_SPACES\n",
    "from includes.data_utils import (\n",
    "    load_labels_and_split,\n",
    "    load_full_labels,\n",
    "    get_transforms,\n",
    "    create_dataloaders,\n",
    ")\n",
    "\n",
    "from includes.model_utils import (\n",
    "    build_model,\n",
    "    create_criterion_optimizer_scheduler,\n",
    "    train_model,\n",
    "    evaluate,\n",
    ")\n",
    "from includes.inference_utils import create_test_loader, run_inference_and_save\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Verifica che la chiave esista\n",
    "print(\"\\nAvailable experiments in GRID_SEARCH_SPACES:\")\n",
    "for exp in GRID_SEARCH_SPACES.keys():\n",
    "    print(f\"  - {exp}\")\n",
    "\n",
    "# base cfg con default (paths, val_size, ecc.)\n",
    "cfg = TrainingConfig(exp_name=EXP_NAME)\n",
    "cfg.project_root = PROJECT_ROOT\n",
    "cfg.out_dir = \"out\"\n",
    "\n",
    "# griglia associata a questo esperimento\n",
    "if EXP_NAME not in GRID_SEARCH_SPACES:\n",
    "    raise KeyError(f\"Experiment '{EXP_NAME}' not found in GRID_SEARCH_SPACES. Available: {list(GRID_SEARCH_SPACES.keys())}\")\n",
    "\n",
    "param_grid = GRID_SEARCH_SPACES[EXP_NAME]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a06ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell X - Preprocessing configuration and optional run\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "from includes.config import PREPROCESSING_KEYS\n",
    "\n",
    "# Flag \"preprocessing\": if False, do not run preprocessing and do not check pp_ params\n",
    "RUN_PREPROCESSING = True  # set to False if you already have pp_* data and want to skip\n",
    "\n",
    "def build_preprocessing_config(param_grid: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extract offline preprocessing config from param_grid.\n",
    "\n",
    "    Logical constraint: for every key in PREPROCESSING_KEYS\n",
    "    that appears in the param_grid, there MUST be exactly one value\n",
    "    (no grid search on preprocessing). If not, raise an error.\n",
    "    \"\"\"\n",
    "    preproc_cfg = {}\n",
    "    for key in PREPROCESSING_KEYS:\n",
    "        if key in param_grid:\n",
    "            values = param_grid[key]\n",
    "            if not isinstance(values, (list, tuple)) or len(values) != 1:\n",
    "                raise ValueError(\n",
    "                    f\"Preprocessing parameter '{key}' must have exactly ONE value in the grid. \"\n",
    "                    f\"Current values: {values}\"\n",
    "                )\n",
    "            preproc_cfg[key] = values[0]\n",
    "    return preproc_cfg\n",
    "\n",
    "\n",
    "if RUN_PREPROCESSING:\n",
    "    # 1) Build preprocessing config from grid search config\n",
    "    preproc_cfg = build_preprocessing_config(param_grid)\n",
    "\n",
    "    print(\"========== PREPROCESSING CONFIG ==========\")\n",
    "    for k, v in preproc_cfg.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(\"==========================================\")\n",
    "\n",
    "    # 2) Call preprocessing/preprocessing.py passing the config as JSON\n",
    "    preproc_script = os.path.join(PROJECT_ROOT, \"preprocessing\", \"preprocessing.py\")\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable,               # current Python interpreter\n",
    "        preproc_script,\n",
    "        json.dumps(preproc_cfg),      # first argument: JSON with pp_* config\n",
    "    ]\n",
    "\n",
    "    print(\"\\n>>> Running offline preprocessing...\")\n",
    "    completed = subprocess.run(cmd, check=True)\n",
    "    print(\">>> Preprocessing finished with returncode:\", completed.returncode)\n",
    "else:\n",
    "    print(\"RUN_PREPROCESSING=False: skipping preprocessing and pp_ parameter checks.\")\n",
    "\n",
    "\n",
    "if param_grid.get(\"execute\", True):\n",
    "    print(\"\\n>>> Proceeding to training phase...\")\n",
    "else:\n",
    "    print(\"\\n>>> 'execute' flag is False: skipping training phase.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# 3) Build a new param_grid for TRAINING ONLY (without preprocessing keys)\n",
    "train_param_grid = {\n",
    "    k: v for k, v in param_grid.items() \n",
    "    if k not in PREPROCESSING_KEYS and k != 'execute'\n",
    "}\n",
    "\n",
    "print(\"\\nTraining param_grid keys:\", list(train_param_grid.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Grid search with optional StratifiedKFold (TRAINING ONLY)\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "base_cfg = cfg  # base config for this experiment (already has exp_name, project_root, etc.)\n",
    "\n",
    "# IMPORTANT: use ONLY training grid (without pp_* keys)\n",
    "keys = list(train_param_grid.keys())\n",
    "values_list = [train_param_grid[k] for k in keys]\n",
    "combos = list(itertools.product(*values_list))\n",
    "n_combos = len(combos)\n",
    "\n",
    "print(\"==============================================================\")\n",
    "print(f\"GRID SEARCH for experiment '{EXP_NAME}' with {n_combos} combinations\")\n",
    "print(\"Param keys (training only):\", keys)\n",
    "print(\"==============================================================\")\n",
    "\n",
    "results = []\n",
    "best_val_f1 = -1.0\n",
    "best_cfg = None\n",
    "best_state_dict = None\n",
    "best_idx_to_label = None\n",
    "best_val_t = None\n",
    "\n",
    "for i, values in enumerate(combos, start=1):\n",
    "    params = dict(zip(keys, values))\n",
    "\n",
    "    print(\"\\n--------------------------------------------------------------\")\n",
    "    print(f\"[Grid {i}/{n_combos}] params = {params}\")\n",
    "\n",
    "    # Validation strategy from params (fallback to holdout)\n",
    "    cv_type = params.get(\"cv_type\", \"holdout\")\n",
    "    n_splits = int(params.get(\"n_splits\", 5))\n",
    "\n",
    "    # 1) Copy base cfg and attach all params as attributes\n",
    "    cfg_i = copy.deepcopy(base_cfg)\n",
    "    for k, v in params.items():\n",
    "        setattr(cfg_i, k, v)\n",
    "\n",
    "    # 2) Common: full labels + transforms\n",
    "    labels_df, unique_labels, label_to_idx, idx_to_label_i = load_full_labels(cfg_i)\n",
    "    train_t_i, val_t_i = get_transforms(cfg_i)\n",
    "    num_classes = len(unique_labels)\n",
    "\n",
    "    fold_f1s = []\n",
    "    best_state_i = None\n",
    "\n",
    "    if cv_type == \"kfold\":\n",
    "        # ----- Stratified K-Fold -----\n",
    "        print(f\"  >> Using StratifiedKFold with {n_splits} folds\")\n",
    "\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=n_splits,\n",
    "            shuffle=True,\n",
    "            random_state=cfg_i.random_seed,\n",
    "        )\n",
    "\n",
    "        best_fold_f1 = -1.0\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(\n",
    "            skf.split(labels_df, labels_df[\"label_idx\"]), start=1\n",
    "        ):\n",
    "            print(f\"    [Fold {fold}/{n_splits}]\")\n",
    "\n",
    "            train_df = labels_df.iloc[train_idx].reset_index(drop=True)\n",
    "            val_df = labels_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "            train_loader_i, val_loader_i = create_dataloaders(\n",
    "                cfg_i, train_df, val_df, train_t_i, val_t_i\n",
    "            )\n",
    "\n",
    "            model_i = build_model(cfg_i, num_classes=num_classes, device=device)\n",
    "            criterion_i, optimizer_i, scheduler_i = create_criterion_optimizer_scheduler(\n",
    "                cfg_i, model_i, train_df, device\n",
    "            )\n",
    "\n",
    "            best_state_fold, history_fold = train_model(\n",
    "                cfg_i,\n",
    "                model_i,\n",
    "                train_loader_i,\n",
    "                val_loader_i,\n",
    "                criterion_i,\n",
    "                optimizer_i,\n",
    "                scheduler_i,\n",
    "                device,\n",
    "            )\n",
    "\n",
    "            val_f1_list = history_fold.get(\"val_f1\", history_fold.get(\"val_acc\", []))\n",
    "            fold_best_f1 = max(val_f1_list) if val_f1_list else 0.0\n",
    "            fold_f1s.append(fold_best_f1)\n",
    "            print(f\"    >> Fold best F1: {fold_best_f1:.4f}\")\n",
    "\n",
    "            if fold_best_f1 > best_fold_f1:\n",
    "                best_fold_f1 = fold_best_f1\n",
    "                best_state_i = copy.deepcopy(best_state_fold)\n",
    "\n",
    "            del model_i\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        run_best_f1 = float(np.mean(fold_f1s))\n",
    "        print(f\"  >> Mean F1 over {n_splits} folds: {run_best_f1:.4f}\")\n",
    "\n",
    "    else:\n",
    "        # ----- Standard hold-out validation (current behaviour) -----\n",
    "        train_df, val_df, unique_labels, label_to_idx, idx_to_label_i = load_labels_and_split(\n",
    "            cfg_i\n",
    "        )\n",
    "        train_t_i, val_t_i = get_transforms(cfg_i)\n",
    "        train_loader_i, val_loader_i = create_dataloaders(\n",
    "            cfg_i, train_df, val_df, train_t_i, val_t_i\n",
    "        )\n",
    "\n",
    "        model_i = build_model(cfg_i, num_classes=num_classes, device=device)\n",
    "        criterion_i, optimizer_i, scheduler_i = create_criterion_optimizer_scheduler(\n",
    "            cfg_i, model_i, train_df, device\n",
    "        )\n",
    "\n",
    "        best_state_i, history_i = train_model(\n",
    "            cfg_i,\n",
    "            model_i,\n",
    "            train_loader_i,\n",
    "            val_loader_i,\n",
    "            criterion_i,\n",
    "            optimizer_i,\n",
    "            scheduler_i,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        val_f1_list = history_i.get(\"val_f1\", history_i.get(\"val_acc\", []))\n",
    "        run_best_f1 = max(val_f1_list) if val_f1_list else 0.0\n",
    "        print(f\"Best val F1 for this run: {run_best_f1:.4f}\")\n",
    "\n",
    "        del model_i\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # 3) Save result row\n",
    "    row = {\"run\": i, \"best_val_f1\": run_best_f1}\n",
    "    for k in keys:\n",
    "        row[k] = params[k]\n",
    "    results.append(row)\n",
    "\n",
    "    # 4) Update global best\n",
    "    if run_best_f1 > best_val_f1:\n",
    "        best_val_f1 = run_best_f1\n",
    "        best_cfg = copy.deepcopy(cfg_i)\n",
    "        best_state_dict = copy.deepcopy(best_state_i)\n",
    "        best_idx_to_label = idx_to_label_i\n",
    "        best_val_t = val_t_i\n",
    "\n",
    "# ---------- grid search summary ----------\n",
    "results_df = pd.DataFrame(results).sort_values(\"best_val_f1\", ascending=False)\n",
    "print(\"\\n================ GRID SEARCH SUMMARY ================\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nBest config (from grid):\")\n",
    "print(best_cfg.__dict__)\n",
    "print(\"Best val F1:\", best_val_f1)\n",
    "\n",
    "# ---------- objects for the rest of the notebook ----------\n",
    "cfg = best_cfg\n",
    "idx_to_label = best_idx_to_label\n",
    "val_t = best_val_t\n",
    "\n",
    "num_classes = len(idx_to_label)\n",
    "model = build_model(cfg, num_classes=num_classes, device=device)\n",
    "model.load_state_dict(best_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb61bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Diagnostics & Confusion Matrix for best config\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ricrea train/val split e dataloader per la best cfg\n",
    "train_df, val_df, unique_labels, label_to_idx, idx_to_label = load_labels_and_split(cfg)\n",
    "train_t_diag, val_t_diag = get_transforms(cfg)\n",
    "train_loader_diag, val_loader_diag = create_dataloaders(\n",
    "    cfg, train_df, val_df, train_t_diag, val_t_diag\n",
    ")\n",
    "\n",
    "# ---------- CLASS DISTRIBUTION ----------\n",
    "print(\"=== CLASS DISTRIBUTION ===\")\n",
    "print(\"\\nTraining set:\")\n",
    "print(train_df[\"label\"].value_counts().sort_index())\n",
    "print(f\"Total train samples: {len(train_df)}\")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "print(val_df[\"label\"].value_counts().sort_index())\n",
    "print(f\"Total val samples: {len(val_df)}\")\n",
    "\n",
    "# ---------- TRAINING CONFIG ----------\n",
    "print(\"\\n=== TRAINING CONFIG ===\")\n",
    "print(f\"Experiment name: {cfg.exp_name}\")\n",
    "print(f\"Backbone     : {cfg.backbone}\")\n",
    "print(f\"Image size   : {cfg.img_size}\")\n",
    "print(f\"Learning rate: {cfg.lr}\")\n",
    "print(f\"Epochs       : {cfg.epochs}\")\n",
    "print(f\"Batch size   : {cfg.batch_size}\")\n",
    "print(f\"Use masks    : {cfg.use_masks}\")\n",
    "print(f\"Mask mode    : {cfg.mask_mode if cfg.use_masks else 'N/A'}\")\n",
    "print(f\"Augmentation : {getattr(cfg, 'augmentation', 'strong')}\")\n",
    "\n",
    "# ---------- CLASS WEIGHTS ----------\n",
    "class_counts = train_df[\"label_idx\"].value_counts().sort_index().values.astype(float)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "\n",
    "print(\"\\n=== CLASS WEIGHTS ===\")\n",
    "for i, (label, weight) in enumerate(zip(unique_labels, class_weights)):\n",
    "    print(f\"{label}: {weight:.4f} (count: {int(class_counts[i])})\")\n",
    "\n",
    "# ---------- Confusion matrix on validation set ----------\n",
    "print(\"\\n=== CONFUSION MATRIX (validation, best model) ===\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader_diag:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=unique_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix - Best model on Validation Set\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# tieni idx_to_label aggiornato per l'inference\n",
    "idx_to_label = idx_to_label\n",
    "val_t = val_t_diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb07622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - Inference and submission (best model from grid search)\n",
    "\n",
    "test_loader, test_files = create_test_loader(cfg, val_t)\n",
    "\n",
    "submission_name = f\"submission_{cfg.exp_name}.csv\"\n",
    "\n",
    "run_inference_and_save(\n",
    "    cfg,\n",
    "    model,\n",
    "    test_loader,\n",
    "    idx_to_label,\n",
    "    device,\n",
    "    output_csv=submission_name,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
