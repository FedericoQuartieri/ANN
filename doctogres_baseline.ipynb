{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# Cell 1 - Imports and setup\n",
        "# ============================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "%matplotlib inline\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sample_index            label\n",
            "0  img_0000.png  Triple negative\n",
            "1  img_0001.png        Luminal A\n",
            "2  img_0002.png        Luminal A\n",
            "3  img_0003.png        Luminal B\n",
            "4  img_0004.png          HER2(+)\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "Luminal B          445\n",
            "Luminal A          414\n",
            "HER2(+)            397\n",
            "Triple negative    156\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Cell 2 - Paths and labels dataframe\n",
        "# =========================================\n",
        "ROOT_DIR      = \".\"\n",
        "TRAIN_IMG_DIR = os.path.join(ROOT_DIR, \"train_data\")\n",
        "TEST_IMG_DIR  = os.path.join(ROOT_DIR, \"test_data\")\n",
        "LABELS_PATH   = os.path.join(ROOT_DIR, \"train_labels.csv\")\n",
        "labels_df = pd.read_csv(LABELS_PATH)\n",
        "print(labels_df.head())\n",
        "print(\"\\nClass distribution:\")\n",
        "print(labels_df[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./train_data/img_0000.png -> True\n",
            "./train_data/img_0001.png -> True\n",
            "./train_data/img_0002.png -> True\n",
            "./train_data/img_0003.png -> True\n",
            "./train_data/img_0004.png -> True\n"
          ]
        }
      ],
      "source": [
        "# ==================================================\n",
        "# Cell 3 - Label encoding (string <-> integer)\n",
        "# ==================================================\n",
        "unique_labels = sorted(labels_df[\"label\"].unique())\n",
        "label_to_idx = {lbl: idx for idx, lbl in enumerate(unique_labels)}\n",
        "idx_to_label = {idx: lbl for lbl, idx in label_to_idx.items()}\n",
        "labels_df[\"label_idx\"] = labels_df[\"label\"].map(label_to_idx)\n",
        "def make_img_path(fname): return os.path.join(TRAIN_IMG_DIR, fname)\n",
        "labels_df[\"img_path\"] = labels_df[\"sample_index\"].apply(make_img_path)\n",
        "for p in labels_df[\"img_path\"].head(): print(p, \"->\", os.path.exists(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1129\n",
            "Val size: 283\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 4 - Train/Validation split\n",
        "# ==========================================\n",
        "train_df, val_df = train_test_split(\n",
        "    labels_df, test_size=0.2, random_state=42,\n",
        "    stratify=labels_df[\"label_idx\"]\n",
        ")\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:\", len(val_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Cell 5 - Custom PyTorch Dataset\n",
        "# ==========================================\n",
        "class DoctogresDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row[\"img_path\"]).convert(\"RGB\")\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, int(row[\"label_idx\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batches: 71\n",
            "Val batches: 18\n"
          ]
        }
      ],
      "source": [
        "# ==================================================\n",
        "# Cell 6 - Transforms and Dataloaders\n",
        "# ==================================================\n",
        "\n",
        "# ImageNet statistics (for pretrained models)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Bigger images to capture more tissue detail\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 16  # puoi abbassare a 8 se la macchina fa fatica\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(416),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "train_dataset = DoctogresDataset(train_df, transform=train_transform)\n",
        "val_dataset   = DoctogresDataset(val_df,   transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6.6%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/federico/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 7 - Model definition (ResNet50)\n",
        "# ==========================================\n",
        "\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "# ResNet50 pretrained on ImageNet\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Replace final FC layer with num_classes outputs\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train class counts: [317. 331. 356. 125.]\n",
            "Class weights: [0.74292089 0.71149825 0.66153349 1.88404737]\n"
          ]
        }
      ],
      "source": [
        "# =======================================================\n",
        "# Cell 8 - Loss, optimizer and scheduler\n",
        "# =======================================================\n",
        "\n",
        "# Compute class weights to handle class imbalance\n",
        "class_counts = train_df[\"label_idx\"].value_counts().sort_index().values.astype(float)\n",
        "print(\"Train class counts:\", class_counts)\n",
        "\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Make sure weights are float32 on the correct device\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# AdamW usually works a bit better than pure Adam per visione\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# Scheduler: se la val acc non migliora, abbassa il LR\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"max\",      # perchÃ© monitoriamo l'accuracy\n",
        "    factor=0.5,      # dimezza il LR\n",
        "    patience=2       # dopo 2 epoche senza migliorare\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Cell 9 - Train and validation loops\n",
        "# ==========================================\n",
        "def train_one_epoch(model,loader,criterion,optimizer,device):\n",
        "    model.train()\n",
        "    tot_loss=tot_corr=tot=0\n",
        "    for x,y in loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out=model(x)\n",
        "        loss=criterion(out,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _,pred=out.max(1)\n",
        "        tot_loss+=loss.item()*x.size(0)\n",
        "        tot_corr+=(pred==y).sum().item()\n",
        "        tot+=y.size(0)\n",
        "    return tot_loss/tot, tot_corr/tot\n",
        "\n",
        "def evaluate(model,loader,criterion,device):\n",
        "    model.eval()\n",
        "    tot_loss=tot_corr=tot=0\n",
        "    all_t=[]; all_p=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y=x.to(device),y.to(device)\n",
        "            out=model(x)\n",
        "            loss=criterion(out,y)\n",
        "            _,pred=out.max(1)\n",
        "            tot_loss+=loss.item()*x.size(0)\n",
        "            tot_corr+=(pred==y).sum().item()\n",
        "            tot+=y.size(0)\n",
        "            all_t+=y.cpu().numpy().tolist()\n",
        "            all_p+=pred.cpu().numpy().tolist()\n",
        "    return tot_loss/tot, tot_corr/tot, np.array(all_t), np.array(all_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/federico/Desktop/Shared/Projects/ANN/env/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 10 - Main training loop\n",
        "# ==========================================\n",
        "\n",
        "EPOCHS = 1\n",
        "best_acc = 0\n",
        "best_w = None\n",
        "\n",
        "for e in range(1, EPOCHS + 1):\n",
        "    print(f\"\\nEpoch {e}/{EPOCHS}\")\n",
        "    \n",
        "    tr_l, tr_a = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    print(\"Train:\", tr_l, tr_a)\n",
        "    \n",
        "    vl_l, vl_a, vt, vp = evaluate(model, val_loader, criterion, device)\n",
        "    print(\"Val:\", vl_l, vl_a)\n",
        "    \n",
        "    # Aggiorna lo scheduler in base alla validation accuracy\n",
        "    scheduler.step(vl_a)\n",
        "\n",
        "    if vl_a > best_acc:\n",
        "        best_acc = vl_a\n",
        "        best_w = model.state_dict().copy()\n",
        "\n",
        "print(\"Best val acc:\", best_acc)\n",
        "model.load_state_dict(best_w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 0.17314487632508835\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        HER2(+)       0.18      0.03      0.04        80\n",
            "      Luminal A       0.41      0.30      0.35        83\n",
            "      Luminal B       0.00      0.00      0.00        89\n",
            "Triple negative       0.11      0.71      0.19        31\n",
            "\n",
            "       accuracy                           0.17       283\n",
            "      macro avg       0.18      0.26      0.14       283\n",
            "   weighted avg       0.18      0.17      0.13       283\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 11 - Validation report\n",
        "# ==========================================\n",
        "vl_l,vl_a,vt,vp=evaluate(model,val_loader,criterion,device)\n",
        "print(\"Val acc:\",vl_a)\n",
        "print(classification_report(vt,vp,target_names=unique_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of test images: 954\n",
            "First 5 test files: ['img_0000.png', 'img_0001.png', 'img_0002.png', 'img_0003.png', 'img_0004.png']\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 12 - Test Dataset and DataLoader\n",
        "# (fixed: use only img_*.png, ignore masks)\n",
        "# ==========================================\n",
        "\n",
        "# Take only image files, ignore mask_*.png\n",
        "test_files = sorted([\n",
        "    f for f in os.listdir(TEST_IMG_DIR)\n",
        "    if f.lower().endswith(\".png\") and f.startswith(\"img_\")\n",
        "])\n",
        "\n",
        "print(\"Number of test images:\", len(test_files))  # should be 954\n",
        "print(\"First 5 test files:\", test_files[:5])\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    \"sample_index\": test_files,\n",
        "    \"img_path\": [os.path.join(TEST_IMG_DIR, f) for f in test_files]\n",
        "})\n",
        "\n",
        "class DoctogresTestDataset(Dataset):\n",
        "    \"\"\"Dataset for test images (no labels).\"\"\"\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row[\"img_path\"]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, row[\"sample_index\"]\n",
        "\n",
        "test_dataset = DoctogresTestDataset(test_df, transform=val_transform)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/federico/Desktop/Shared/Projects/ANN/env/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 13 - Submission\n",
        "# ==========================================\n",
        "model.eval()\n",
        "ids=[]; preds=[]\n",
        "with torch.no_grad():\n",
        "    for x,names in test_loader:\n",
        "        x=x.to(device)\n",
        "        out=model(x)\n",
        "        _,p=out.max(1)\n",
        "        ids+=list(names)\n",
        "        preds+=p.cpu().numpy().tolist()\n",
        "pred_labels=[idx_to_label[i] for i in preds]\n",
        "sub=pd.DataFrame({\"sample_index\":ids,\"label\":pred_labels}).sort_values(\"sample_index\")\n",
        "sub.to_csv(\"submission.csv\",index=False)\n",
        "print(\"Submission saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2682675",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
