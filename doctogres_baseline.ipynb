{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# Cell 1 - Imports and setup\n",
        "# ============================\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "%matplotlib inline\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sample_index            label\n",
            "0  img_0000.png  Triple negative\n",
            "1  img_0001.png        Luminal A\n",
            "2  img_0002.png        Luminal A\n",
            "3  img_0003.png        Luminal B\n",
            "4  img_0004.png          HER2(+)\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "Luminal B          445\n",
            "Luminal A          414\n",
            "HER2(+)            397\n",
            "Triple negative    156\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Cell 2 - Paths and labels dataframe\n",
        "# =========================================\n",
        "ROOT_DIR      = \".\"\n",
        "TRAIN_IMG_DIR = os.path.join(ROOT_DIR, \"train_data\")\n",
        "TEST_IMG_DIR  = os.path.join(ROOT_DIR, \"test_data\")\n",
        "LABELS_PATH   = os.path.join(ROOT_DIR, \"train_labels.csv\")\n",
        "labels_df = pd.read_csv(LABELS_PATH)\n",
        "print(labels_df.head())\n",
        "print(\"\\nClass distribution:\")\n",
        "print(labels_df[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./train_data/img_0000.png -> True\n",
            "./train_data/img_0001.png -> True\n",
            "./train_data/img_0002.png -> True\n",
            "./train_data/img_0003.png -> True\n",
            "./train_data/img_0004.png -> True\n"
          ]
        }
      ],
      "source": [
        "# ==================================================\n",
        "# Cell 3 - Label encoding (string <-> integer)\n",
        "# ==================================================\n",
        "unique_labels = sorted(labels_df[\"label\"].unique())\n",
        "label_to_idx = {lbl: idx for idx, lbl in enumerate(unique_labels)}\n",
        "idx_to_label = {idx: lbl for lbl, idx in label_to_idx.items()}\n",
        "labels_df[\"label_idx\"] = labels_df[\"label\"].map(label_to_idx)\n",
        "def make_img_path(fname): return os.path.join(TRAIN_IMG_DIR, fname)\n",
        "labels_df[\"img_path\"] = labels_df[\"sample_index\"].apply(make_img_path)\n",
        "for p in labels_df[\"img_path\"].head(): print(p, \"->\", os.path.exists(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1129\n",
            "Val size: 283\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 4 - Train/Validation split\n",
        "# ==========================================\n",
        "train_df, val_df = train_test_split(\n",
        "    labels_df, test_size=0.2, random_state=42,\n",
        "    stratify=labels_df[\"label_idx\"]\n",
        ")\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:\", len(val_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Cell 5 - Custom PyTorch Dataset\n",
        "# ==========================================\n",
        "class DoctogresDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row[\"img_path\"]).convert(\"RGB\")\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, int(row[\"label_idx\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================================================\n",
        "# Cell 6 - Transforms and Dataloaders\n",
        "# ==================================================\n",
        "IMAGENET_MEAN=[0.485,0.456,0.406]\n",
        "IMAGENET_STD=[0.229,0.224,0.225]\n",
        "IMG_SIZE=224\n",
        "train_transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE,scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(0.1,0.1,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN,IMAGENET_STD),\n",
        "])\n",
        "val_transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN,IMAGENET_STD),\n",
        "])\n",
        "train_loader=DataLoader(DoctogresDataset(train_df,train_transform),batch_size=16,shuffle=True)\n",
        "val_loader=DataLoader(DoctogresDataset(val_df,val_transform),batch_size=16,shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 7 - Model definition\n",
        "# ==========================================\n",
        "num_classes=len(unique_labels)\n",
        "model=models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc=nn.Linear(model.fc.in_features,num_classes)\n",
        "model=model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =======================================================\n",
        "# Cell 8 - Loss and optimizer\n",
        "# =======================================================\n",
        "# class_counts=train_df[\"label_idx\"].value_counts().sort_index().values.astype(float)\n",
        "# class_weights=1.0/class_counts\n",
        "# class_weights=class_weights/class_weights.sum()*len(class_counts)\n",
        "# criterion=nn.CrossEntropyLoss(weight=torch.tensor(class_weights,device=device))\n",
        "# optimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\n",
        "\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Cell 9 - Train and validation loops\n",
        "# ==========================================\n",
        "def train_one_epoch(model,loader,criterion,optimizer,device):\n",
        "    model.train()\n",
        "    tot_loss=tot_corr=tot=0\n",
        "    for x,y in loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out=model(x)\n",
        "        loss=criterion(out,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _,pred=out.max(1)\n",
        "        tot_loss+=loss.item()*x.size(0)\n",
        "        tot_corr+=(pred==y).sum().item()\n",
        "        tot+=y.size(0)\n",
        "    return tot_loss/tot, tot_corr/tot\n",
        "\n",
        "def evaluate(model,loader,criterion,device):\n",
        "    model.eval()\n",
        "    tot_loss=tot_corr=tot=0\n",
        "    all_t=[]; all_p=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y=x.to(device),y.to(device)\n",
        "            out=model(x)\n",
        "            loss=criterion(out,y)\n",
        "            _,pred=out.max(1)\n",
        "            tot_loss+=loss.item()*x.size(0)\n",
        "            tot_corr+=(pred==y).sum().item()\n",
        "            tot+=y.size(0)\n",
        "            all_t+=y.cpu().numpy().tolist()\n",
        "            all_p+=pred.cpu().numpy().tolist()\n",
        "    return tot_loss/tot, tot_corr/tot, np.array(all_t), np.array(all_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train: 1.5639608704589762 0.1691762621789194\n",
            "Val: 1.535845624684445 0.17314487632508835\n",
            "\n",
            "Epoch 2/10\n",
            "Train: 1.56078848076458 0.1629760850310009\n",
            "Val: 1.5356592285338224 0.14487632508833923\n",
            "\n",
            "Epoch 3/10\n",
            "Train: 1.553106830117975 0.16209034543844109\n",
            "Val: 1.5362763880840882 0.1625441696113074\n",
            "\n",
            "Epoch 4/10\n",
            "Train: 1.5606412435654944 0.16031886625332153\n",
            "Val: 1.5299783009943608 0.1625441696113074\n",
            "\n",
            "Epoch 5/10\n",
            "Train: 1.5613728287581115 0.15677590788308238\n",
            "Val: 1.537822554473742 0.1696113074204947\n",
            "\n",
            "Epoch 6/10\n",
            "Train: 1.5567265846118978 0.15766164747564215\n",
            "Val: 1.5342410390031633 0.16607773851590105\n",
            "\n",
            "Epoch 7/10\n",
            "Train: 1.5402332487309054 0.1612046058458813\n",
            "Val: 1.526281883775556 0.15901060070671377\n",
            "\n",
            "Epoch 8/10\n",
            "Train: 1.5456526511743915 0.1753764393268379\n",
            "Val: 1.5334717523925296 0.1696113074204947\n",
            "\n",
            "Epoch 9/10\n",
            "Train: 1.5487069269531697 0.1762621789193977\n",
            "Val: 1.5307823318474705 0.15901060070671377\n",
            "\n",
            "Epoch 10/10\n",
            "Train: 1.5511923073877583 0.17980513728963685\n",
            "Val: 1.5354390662466257 0.17314487632508835\n",
            "Best val acc: 0.17314487632508835\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 10 - Main training loop\n",
        "# ==========================================\n",
        "EPOCHS=10\n",
        "best_acc=0\n",
        "best_w=None\n",
        "for e in range(1,EPOCHS+1):\n",
        "    print(f\"\\nEpoch {e}/{EPOCHS}\")\n",
        "    tr_l,tr_a=train_one_epoch(model,train_loader,criterion,optimizer,device)\n",
        "    print(\"Train:\",tr_l,tr_a)\n",
        "    vl_l,vl_a,vt,vp=evaluate(model,val_loader,criterion,device)\n",
        "    print(\"Val:\",vl_l,vl_a)\n",
        "    if vl_a>best_acc:\n",
        "        best_acc=vl_a\n",
        "        best_w=model.state_dict().copy()\n",
        "print(\"Best val acc:\",best_acc)\n",
        "model.load_state_dict(best_w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 0.17314487632508835\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        HER2(+)       0.18      0.03      0.04        80\n",
            "      Luminal A       0.41      0.30      0.35        83\n",
            "      Luminal B       0.00      0.00      0.00        89\n",
            "Triple negative       0.11      0.71      0.19        31\n",
            "\n",
            "       accuracy                           0.17       283\n",
            "      macro avg       0.18      0.26      0.14       283\n",
            "   weighted avg       0.18      0.17      0.13       283\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 11 - Validation report\n",
        "# ==========================================\n",
        "vl_l,vl_a,vt,vp=evaluate(model,val_loader,criterion,device)\n",
        "print(\"Val acc:\",vl_a)\n",
        "print(classification_report(vt,vp,target_names=unique_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of test images: 954\n",
            "First 5 test files: ['img_0000.png', 'img_0001.png', 'img_0002.png', 'img_0003.png', 'img_0004.png']\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 12 - Test Dataset and DataLoader\n",
        "# (fixed: use only img_*.png, ignore masks)\n",
        "# ==========================================\n",
        "\n",
        "# Take only image files, ignore mask_*.png\n",
        "test_files = sorted([\n",
        "    f for f in os.listdir(TEST_IMG_DIR)\n",
        "    if f.lower().endswith(\".png\") and f.startswith(\"img_\")\n",
        "])\n",
        "\n",
        "print(\"Number of test images:\", len(test_files))  # should be 954\n",
        "print(\"First 5 test files:\", test_files[:5])\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    \"sample_index\": test_files,\n",
        "    \"img_path\": [os.path.join(TEST_IMG_DIR, f) for f in test_files]\n",
        "})\n",
        "\n",
        "class DoctogresTestDataset(Dataset):\n",
        "    \"\"\"Dataset for test images (no labels).\"\"\"\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row[\"img_path\"]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, row[\"sample_index\"]\n",
        "\n",
        "test_dataset = DoctogresTestDataset(test_df, transform=val_transform)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/federico/Desktop/Shared/Projects/ANN/env/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Cell 13 - Submission\n",
        "# ==========================================\n",
        "model.eval()\n",
        "ids=[]; preds=[]\n",
        "with torch.no_grad():\n",
        "    for x,names in test_loader:\n",
        "        x=x.to(device)\n",
        "        out=model(x)\n",
        "        _,p=out.max(1)\n",
        "        ids+=list(names)\n",
        "        preds+=p.cpu().numpy().tolist()\n",
        "pred_labels=[idx_to_label[i] for i in preds]\n",
        "sub=pd.DataFrame({\"sample_index\":ids,\"label\":pred_labels}).sort_values(\"sample_index\")\n",
        "sub.to_csv(\"submission.csv\",index=False)\n",
        "print(\"Submission saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2682675",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
