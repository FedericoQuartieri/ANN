{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef0aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (per-timestep): (105760, 40)\n",
      "Labels: (661, 2)\n",
      "Test (per-timestep): (211840, 40)\n",
      "Label counts (per series):\n",
      "label\n",
      "no_pain      511\n",
      "low_pain      94\n",
      "high_pain     56\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Pirate Pain â€” Leakage-Safe Baseline (Anti-Overfitting)\n",
    "# - Aggregate each `sample_index` time series into compact features (no mixing between series).\n",
    "# - Do **Stratified K-Fold** on the per-series table (avoids leakage across timesteps).\n",
    "# - Use **StandardScaler + LogisticRegression (multinomial)** with strong L2 regularization.\n",
    "# - Score with **macro-F1** and export `submission_baseline.csv` (columns: sample_index,label).\n",
    "\n",
    "# %%\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "DATA_DIR = Path(\".\")  # change if needed\n",
    "\n",
    "TRAIN = DATA_DIR / \"pirate_pain_train.csv\"\n",
    "TRAIN_Y = DATA_DIR / \"pirate_pain_train_labels.csv\"\n",
    "TEST  = DATA_DIR / \"pirate_pain_test.csv\"\n",
    "\n",
    "X_train = pd.read_csv(TRAIN)\n",
    "y_train = pd.read_csv(TRAIN_Y)\n",
    "X_test  = pd.read_csv(TEST)\n",
    "\n",
    "print(\"Train (per-timestep):\", X_train.shape)\n",
    "print(\"Labels:\", y_train.shape)\n",
    "print(\"Test (per-timestep):\", X_test.shape)\n",
    "\n",
    "assert {'sample_index','time'}.issubset(X_train.columns)\n",
    "assert {'sample_index','time'}.issubset(X_test.columns)\n",
    "assert set(y_train.columns) == {'sample_index','label'}\n",
    "\n",
    "print(\"Label counts (per series):\")\n",
    "print(y_train['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c444e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n numeric channels: 35\n",
      "Per-series train: (661, 318) Per-series test: (1324, 318)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Feature engineering (per series)\n",
    "# We compute robust statistics per numeric channel, plus a slope vs time and energy term.\n",
    "# This keeps the model small and reduces overfitting risk.\n",
    "\n",
    "# %%\n",
    "# numeric columns except ids\n",
    "num_cols = [c for c in X_train.columns if c not in ['sample_index', 'time']]\n",
    "num_cols = [c for c in num_cols if pd.api.types.is_numeric_dtype(X_train[c])]\n",
    "print(\"n numeric channels:\", len(num_cols))\n",
    "\n",
    "def _safe_quantile(x, q):\n",
    "    try:\n",
    "        return np.nanquantile(x, q)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def _slope_vs_time(x, t):\n",
    "    x = np.asarray(x, float); t = np.asarray(t, float)\n",
    "    m = np.isfinite(x) & np.isfinite(t)\n",
    "    if m.sum() < 3 or np.all(t[m] == t[m][0]): return 0.0\n",
    "    tt = t[m] - t[m].mean()\n",
    "    denom = np.dot(tt, tt)\n",
    "    if denom == 0: return 0.0\n",
    "    return float(np.dot(tt, x[m] - x[m].mean()) / denom)\n",
    "\n",
    "def build_series_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for sid, g in df.groupby('sample_index', sort=False):\n",
    "        row = {'sample_index': sid}\n",
    "        t = g['time'].values\n",
    "        dur = float(np.nanmax(t) - np.nanmin(t)) if len(t) else 0.0\n",
    "        row['n_steps'] = int(len(g))\n",
    "        row['duration'] = dur\n",
    "        row['rate_est'] = row['n_steps'] / dur if dur > 0 else row['n_steps']\n",
    "        for c in num_cols:\n",
    "            x = g[c].values\n",
    "            row[f'{c}_mean']   = float(np.nanmean(x))\n",
    "            row[f'{c}_std']    = float(np.nanstd(x))\n",
    "            row[f'{c}_min']    = float(np.nanmin(x))\n",
    "            row[f'{c}_max']    = float(np.nanmax(x))\n",
    "            row[f'{c}_med']    = float(np.nanmedian(x))\n",
    "            row[f'{c}_q25']    = float(_safe_quantile(x, 0.25))\n",
    "            row[f'{c}_q75']    = float(_safe_quantile(x, 0.75))\n",
    "            row[f'{c}_slope']  = _slope_vs_time(x, t)\n",
    "            row[f'{c}_energy'] = float(np.nanmean(np.square(x)))\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).set_index('sample_index')\n",
    "\n",
    "series_train = build_series_table(X_train)\n",
    "series_test  = build_series_table(X_test)\n",
    "\n",
    "# Align columns (defensive)\n",
    "missing = [c for c in series_train.columns if c not in series_test.columns]\n",
    "for c in missing: series_test[c] = 0.0\n",
    "series_train = series_train.reindex(columns=list(series_test.columns), fill_value=0.0).sort_index()\n",
    "series_test  = series_test.sort_index()\n",
    "\n",
    "print(\"Per-series train:\", series_train.shape, \"Per-series test:\", series_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ccb8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['high_pain', 'low_pain', 'no_pain']\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Labels and CV setup (per series)\n",
    "# We perform **StratifiedKFold** on the aggregated table (one row per series).\n",
    "\n",
    "# %%\n",
    "le = LabelEncoder()\n",
    "y = y_train.set_index('sample_index').loc[series_train.index, 'label']\n",
    "y_enc = le.fit_transform(y)\n",
    "print(\"Classes:\", list(le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4309ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best params: {'clf__C': 0.1}\n",
      "CV macro-F1: 0.5850041501717831\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Model: Scaler + Multinomial Logistic Regression (L2)\n",
    "# We tune only `C` on a small grid (less variance, safer on small data).\n",
    "\n",
    "# %%\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "    ('clf', LogisticRegression(\n",
    "        multi_class='multinomial', solver='lbfgs',\n",
    "        max_iter=2000, class_weight='balanced', random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {'clf__C': [0.05, 0.1, 0.2, 0.5, 1.0]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "search = GridSearchCV(pipe, param_grid, scoring='f1_macro', cv=cv, n_jobs=-1, verbose=1)\n",
    "search.fit(series_train.values, y_enc)\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"CV macro-F1:\", search.best_score_)\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69fc7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro-F1 (refit): 0.8829674503316919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_pain       0.77      1.00      0.87        56\n",
      "    low_pain       0.77      0.90      0.83        94\n",
      "     no_pain       0.99      0.92      0.95       511\n",
      "\n",
      "    accuracy                           0.92       661\n",
      "   macro avg       0.84      0.94      0.88       661\n",
      "weighted avg       0.94      0.92      0.93       661\n",
      "\n",
      "[[ 56   0   0]\n",
      " [  2  85   7]\n",
      " [ 15  26 470]]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Diagnostics on the training data (optional, just to sanity-check)\n",
    "# (Report is computed on the same data used to refit the final model returned by GridSearchCV)\n",
    "\n",
    "# %%\n",
    "pred_train = best_model.predict(series_train.values)\n",
    "print(\"Train macro-F1 (refit):\", f1_score(y_enc, pred_train, average='macro'))\n",
    "print(classification_report(y_enc, pred_train, target_names=list(le.classes_)))\n",
    "print(confusion_matrix(y_enc, pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dfb37ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>high_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>high_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>high_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>high_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>high_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_index      label\n",
       "0            0  high_pain\n",
       "1            1  high_pain\n",
       "2            2  high_pain\n",
       "3            3  high_pain\n",
       "4            4  high_pain"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Train on full data & create submission\n",
    "# The final model is trained on all per-series rows and applied to the per-series test table.\n",
    "\n",
    "# %%\n",
    "best_model.fit(series_train.values, y_enc)\n",
    "test_pred = best_model.predict(series_test.values)\n",
    "test_labels = le.inverse_transform(test_pred)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    'sample_index': series_test.index.astype(str),\n",
    "    'label': test_labels\n",
    "})\n",
    "sub.to_csv(\"submission_baseline.csv\", index=False)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ac96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
